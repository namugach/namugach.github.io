<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"><channel><title><![CDATA[note]]></title><description><![CDATA[Obsidian digital garden]]></description><link>http://github.com/dylang/node-rss</link><image><url>lib\media\favicon.png</url><title>note</title><link/></image><generator>Webpage HTML Export plugin for Obsidian</generator><lastBuildDate>Tue, 13 Aug 2024 18:02:43 GMT</lastBuildDate><atom:link href="lib\rss.xml" rel="self" type="application/rss+xml"/><pubDate>Tue, 13 Aug 2024 18:02:40 GMT</pubDate><ttl>60</ttl><dc:creator/><item><title><![CDATA[mysql 계정 생성시 %의 의미]]></title><description><![CDATA[ 
 <br><br>
<br>%: MySQL에서 %는 "모든 호스트"를 의미해. 즉, %를 사용하면 어떤 IP 주소에서든지 이 사용자 계정으로 MySQL 서버에 접근할 수 있도록 허용하는 거야.
<br><br>
<br>
모든 호스트에서 접근 가능:
CREATE USER 'ubuntu'@'%' IDENTIFIED BY '1234';
GRANT ALL PRIVILEGES ON *.* TO 'ubuntu'@'%' WITH GRANT OPTION;
Run복사
이 명령어는 ubuntu라는 사용자 계정이 어떤 IP 주소에서든지 접속할 수 있도록 설정해. 즉, server3에서뿐만 아니라 다른 모든 서버에서도 이 계정을 사용해 MySQL 서버에 접근할 수 있어.

<br>
특정 IP 주소에서만 접근 가능:
만약 특정 IP 주소에서만 접근을 허용하려면 % 대신 그 IP 주소를 사용하면 돼. 예를 들어 172.17.0.3에서만 접근을 허용하려면:
CREATE USER 'ubuntu'@'172.17.0.3' IDENTIFIED BY '1234';
GRANT ALL PRIVILEGES ON *.* TO 'ubuntu'@'172.17.0.3' WITH GRANT OPTION;
Run복사
이 경우, ubuntu 사용자는 172.17.0.3에서만 MySQL 서버에 접근할 수 있어.

<br>
특정 호스트 이름에서 접근 가능:
특정 호스트 이름을 사용해 접근을 제한할 수도 있어. 예를 들어 server1.example.com에서만 접근을 허용하려면:
CREATE USER 'ubuntu'@'server1.example.com' IDENTIFIED BY '1234';
GRANT ALL PRIVILEGES ON *.* TO 'ubuntu'@'server1.example.com' WITH GRANT OPTION;
Run복사
이 경우, ubuntu 사용자는 server1.example.com이라는 호스트 이름으로만 MySQL 서버에 접근할 수 있어.

<br><br>
<br>%: 모든 호스트에서 접근 허용.
<br>특정 IP 주소: 특정 IP 주소에서만 접근 허용.
<br>호스트 이름: 특정 호스트 이름에서만 접근 허용.
<br>이렇게 설정을 통해 MySQL 서버에 접근할 수 있는 사용자 계정과 그 계정이 접속할 수 있는 호스트를 세밀하게 제어할 수 있어. 추가로 궁금한 점이 있으면 언제든지 물어봐!<br>
이렇게 만드는데, '계정명'@'% 이 부분에서 % 부분에 대해서 알려줘]]></description><link>root\dev\data-pipe-line\server\local\mysql-계정-생성시-의-의미.html</link><guid isPermaLink="false">root/dev/data pipe line/server/local/mysql 계정 생성시 %의 의미.md</guid><pubDate>Tue, 30 Jul 2024 15:36:37 GMT</pubDate></item><item><title><![CDATA[0.도커와 쿠버네티스]]></title><description><![CDATA[ 
 <br><br>
<br>우분투
<br>t2.xlarge
<br>ssd: 100gb
<br><br><br> AWS client to database<br><a data-tooltip-position="top" aria-label="flask postgreSQL 건들기" data-href="flask postgreSQL 건들기" href="root\dev\도커와-쿠버네티스\flask-postgresql-건들기.html" class="internal-link" target="_self" rel="noopener">하고</a><br><br><br><a data-tooltip-position="top" aria-label="flask 건들기 위한 Docker" data-href="flask 건들기 위한 Docker" href="root\dev\도커와-쿠버네티스\flask-건들기-위한-docker.html" class="internal-link" target="_self" rel="noopener">설치 하고!</a><br><br><br> AWS client to docker database<br><a data-tooltip-position="top" aria-label="flask docker에 태우자" data-href="flask docker에 태우자" href="root\dev\도커와-쿠버네티스\flask-docker에-태우자.html" class="internal-link" target="_self" rel="noopener">그래!</a><br><br><br><a data-tooltip-position="top" aria-label="docker compose" data-href="docker compose" href="root\dev\도커와-쿠버네티스\docker-compose.html" class="internal-link" target="_self" rel="noopener">일단 설치</a><br><br><br><a data-tooltip-position="top" aria-label="Python에 YAML" data-href="Python에 YAML" href="root\dev\도커와-쿠버네티스\python에-yaml.html" class="internal-link" target="_self" rel="noopener">설치 하고</a><br><br><br><a data-tooltip-position="top" aria-label="enginx 도커 올려" data-href="enginx 도커 올려" href="root\dev\도커와-쿠버네티스\enginx-도커-올려.html" class="internal-link" target="_self" rel="noopener">올려!!</a><br><br><br><a data-tooltip-position="top" aria-label="postgre 도커 올려" data-href="postgre 도커 올려" href="root\dev\도커와-쿠버네티스\postgre-도커-올려.html" class="internal-link" target="_self" rel="noopener">올려!!!</a><br><br><br><a data-tooltip-position="top" aria-label="도커 볼륨" data-href="도커 볼륨" href="root\dev\도커와-쿠버네티스\도커-볼륨.html" class="internal-link" target="_self" rel="noopener">걸고</a><br><br><br><a data-tooltip-position="top" aria-label="도커로 flask, nginx, PostgresSql 함께 배포" data-href="도커로 flask, nginx, PostgresSql 함께 배포" href="root\dev\도커와-쿠버네티스\도커로-flask,-nginx,-postgressql-함께-배포.html" class="internal-link" target="_self" rel="noopener">하고</a><br><br><br><a data-tooltip-position="top" aria-label="쿠버네티스 설치" data-href="쿠버네티스 설치" href="root\dev\도커와-쿠버네티스\쿠버네티스-설치.html" class="internal-link" target="_self" rel="noopener">해서</a><br><br><br><a data-tooltip-position="top" aria-label="쿠버네티스 사용법" data-href="쿠버네티스 사용법" href="root\dev\도커와-쿠버네티스\쿠버네티스-사용법.html" class="internal-link" target="_self" rel="noopener">익히면</a><br>된다.]]></description><link>root\dev\도커와-쿠버네티스\0.도커와-쿠버네티스.html</link><guid isPermaLink="false">root/dev/도커와 쿠버네티스/0.도커와 쿠버네티스.md</guid><pubDate>Tue, 04 Jun 2024 12:44:12 GMT</pubDate></item><item><title><![CDATA[도커 볼륨]]></title><description><![CDATA[ 
 <br><br>
<br>입력
<br>docker volume ls
복사<br>
<br>출력
<br>DRIVER    VOLUME NAME
local     017e81633e49fe45ddb6bba787e35e1808c6bac4f41cd00de119de5b53fdd29a
local     671ee4a6da4fbbef319421e4b72d86c8b8a7097a87692871f7f6140842dc3464
local     c530219b8e489e5120e024a8120f566a53670af51676b6bfe46b4b09f0ceb6d2
복사<br><br><br>docker volume create myvolume01
복사<br><br><br>
<br>입력
<br>docker volume inspect myvolume01
복사<br>
<br>출력
<br>[
    {
        "CreatedAt": "2024-06-04T00:22:24Z",
        "Driver": "local",
        "Labels": null,
        "Mountpoint": "/var/lib/docker/volumes/myvolume01/_data",
        "Name": "myvolume01",
        "Options": null,
        "Scope": "local"
    }
]
복사<br>Important"Mountpoint": "/var/lib/docker/volumes/myvolume01/_data"
요 부분을 실행할 때 씀<br><br><br><br>
<br>입력
<br>docker container run -e POSTGRES_PASSWORD=mysecretpassword -v myvolume01:/var/lib/postgresql/data -d postgres
복사<br>
<br>출력
<br>e0d2b80f0a0af6ed07b7e0f583873e7c74ffd097960c66c097909345ff671bfb
복사<br><br>
<br>입력
<br>docker container ls
복사<br>
<br>출력
<br>CONTAINER ID   IMAGE      COMMAND                  CREATED         STATUS         PORTS      NAMES
eb8a80dcd9d2   postgres   "docker-entrypoint.s…"   5 seconds ago   Up 4 seconds   5432/tcp   sweet_goodall
복사<br><br>docker container exec -it eb8a80dcd9d2 /bin/bash
psql -U postgres
복사<br><br><br>
<br>입력
<br>CREATE USER cheolwon PASSWORD '1234' SUPERUSER;
postgres=# \du
Run복사<br>
<br>출력
<br>                             List of roles
 Role name |                         Attributes                         
-----------+------------------------------------------------------------
 cheolwon  | Superuser
 postgres  | Superuser, Create role, Create DB, Replication, Bypass RLS
복사<br><br><br>
<br>입력
<br>docker container ls
복사<br>
<br>출력
<br>CONTAINER ID   IMAGE     COMMAND                  CREATED        STATUS         PORTS      NAMES
39e32b2aaf25   postgres  "docker-entrypoint.s…"   4 minutes ago  Up 55 seconds  5432/tcp   some-postgres
복사<br><br>
<br>입력
<br>docker container stop 39e32b2aaf25
docker container rm 39e32b2aaf25
복사<br>
<br>출력
<br>39e32b2aaf25
복사<br><br><a data-href="#컨테이너" href="about:blank#컨테이너" class="internal-link" target="_self" rel="noopener">컨테이너</a><br><br>
<br>입력
<br>docker container ls
복사<br>
<br>출력
<br>CONTAINER ID   IMAGE      COMMAND                  CREATED              STATUS              PORTS      NAMES
666c91149b9d   postgres   "docker-entrypoint.s…"   About a minute ago   Up About a minute   5432/tcp   sweet_mccarthy
ubuntu@ip-172-31-8-194:~$ docker container exec -it 666c91149b9d /bin/bash
복사<br><br>
<br>입력
<br>psql -U postgres
postgres=# psql
postgres-# \du
복사<br>
<br>출력
<br>                             List of roles
 Role name |                         Attributes                         
-----------+------------------------------------------------------------
 cheolwon  | Superuser
 postgres  | Superuser, Create role, Create DB, Replication, Bypass RLS
복사<br>Note컨테이너를 삭제 했음에도 불구하고 psql의 cheolwon 계정이 살아있다.<br><br><br><br>
<br>입력
<br>docker volume inspect myvolume01
복사<br>
<br>출력
<br>[
    {
        "CreatedAt": "2024-06-04T00:22:24Z",
        "Driver": "local",
        "Labels": null,
        "Mountpoint": "/var/lib/docker/volumes/myvolume01/_data",
        "Name": "myvolume01",
        "Options": null,
        "Scope": "local"
    }
]
복사<br>이 부분 확인"Mountpoint": "/var/lib/docker/volumes/myvolume01/_data"<br><br>
<br>입력
<br>sudo -i
cd /var/lib/docker/volumes/myvolume01/_dat
ls
복사<br>
<br>출력
<br>PG_VERSION    pg_dynshmem    pg_multixact  pg_snapshots  pg_tblspc    postgresql.auto.conf
base          pg_hba.conf    pg_notify     pg_stat       pg_twophase  postgresql.conf
global        pg_ident.conf  pg_replslot   pg_stat_tmp   pg_wal       postmaster.opts
pg_commit_ts  pg_logical     pg_serial     pg_subtrans   pg_xact
복사]]></description><link>root\dev\도커와-쿠버네티스\도커-볼륨.html</link><guid isPermaLink="false">root/dev/도커와 쿠버네티스/도커 볼륨.md</guid><pubDate>Thu, 06 Jun 2024 05:45:41 GMT</pubDate></item><item><title><![CDATA[도커로 flask, nginx, PostgresSql 함께 배포]]></title><description><![CDATA[ 
 <br><br><br>cd ~/work
mkdir psqltest
복사<br><br>cd psqltest
복사<br><br><br>FROM postgres:16.3
복사<br><br><br>tree
.
├── docker-compose.yml
├── flaskapp
│   ├── Dockerfile
│   ├── myapp
│   │   └── main.py
│   └── requirements.txt
├── nginxtest
│   ├── Dockerfile
│   └── default.conf
└── psqltest
    └── Dockerfile
복사<br><br><br><br>:~/work/docker$ vi docker-compose.yml
복사<br><br>services:
  flasktest:
    build: ./flaskapp
    networks:
     - composenet01
    restart: always
  
  nginxtest:
    build: ./nginxtest
    networks:
    - composenet01
    ports:
    - "80:80"
    depends_on:
    - flasktest

  psqltest:
    build: ./psqltest
    container_name: psqltest
    networks:
    - composenet01
    restart: always
    volumes:
    - myvolume01:/var/lib/postgresql/data
    environment:
    - POSTGRES_USER=postgres
    - POSTGRES_PASSWORD=postgres
    - POSTGRES_DB=postgres

volumes:
  myvolume01:

networks:
  composenet01:

복사<br>Notepsqltest 부분 장성<br><br><br><br>~/work/docker/flaskapp/myapp$ vim main.py
복사<br><br>...( )
conn = psycopg2.connect(dbname='ml', user='postgres', password='postgres', host='psqltest', port=5432)
...( )
복사<br>Notehost='psqltest'<br><br><br><br>cd ~/work/docker
복사<br><br><br>docker docker compose up -d --build
복사<br><br>[+] Building 50.9s (24/24) FINISHED
=&gt; [flasktest internal] load build definition from Dockerfile
=&gt; =&gt; transferring dockerfile: 241B
...( )
[+] Running 5/5
Network docker_composenet01 Created
Volume "docker_myvolume01" Created
Container flasktest Started
Container psqltest Started
Container nginxtest Started
복사<br><br><br>docker container ls
복사<br><br>CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES
d978f5f34183 docker-nginxtest "/docker-entrypoint.…" 29 seconds ago Up 28 seconds 0.0.0.0:80-&gt;80/tcp, :::80-&gt;80/tcp nginxtest
084e876750a0 docker-psqltest "docker-entrypoint.s…" 30 seconds ago Up 29 seconds 5432/tcp psqltest
14dea1fe0200 docker-flasktest "/bin/sh -c 'gunicor…" 30 seconds ago Up 29 seconds 5000/tcp flasktest
복사<br><br>브라우저주소: 인스턴스 ip 주소
내용: HELLO, ML API SERVER<br><br><br><br>docker container ls
복사<br>CONTAINER ID   IMAGE              COMMAND                  CREATED          STATUS          PORTS                               NAMES
a88f2c3846f5   docker-nginxtest   "/docker-entrypoint.…"   29 minutes ago   Up 29 minutes   0.0.0.0:80-&gt;80/tcp, :::80-&gt;80/tcp   docker-nginxtest-1
df0bbba2c7de   docker-flasktest   "/bin/sh -c 'gunicor…"   29 minutes ago   Up 29 minutes   5000/tcp                            docker-flasktest-1
a60d681088ac   docker-psqltest    "docker-entrypoint.s…"   29 minutes ago   Up 29 minutes   5432/tcp                            psqltest
복사<br>Notepsqltest 컨테이너<br><br>docker container exec -it a60d681088ac /bin/bash
복사<br><br><br>psql -U postgre
복사<br><br>CREATE DATABASE ml;

\c ml
Run복사<br><br>CREATE TABLE pred_result(
    id SERIAL PRIMARY KEY,
    input NUMERIC,
    output NUMERIC,
    insert_dt TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
Run복사<br><br><br>curl -d '{"input":["0.３"]}' -H "Content-Type: application/json" -X POST http://43.203.77.126/predict
복사<br><br>{"input":0.3,"predicted_output":1.63768}
복사]]></description><link>root\dev\도커와-쿠버네티스\도커로-flask,-nginx,-postgressql-함께-배포.html</link><guid isPermaLink="false">root/dev/도커와 쿠버네티스/도커로 flask, nginx, PostgresSql 함께 배포.md</guid><pubDate>Tue, 04 Jun 2024 12:45:38 GMT</pubDate></item><item><title><![CDATA[쿠버네티스 사용법]]></title><description><![CDATA[ 
 <br>ubuntu@ip-172-31-8-194:~/app$ kubectl get pod
NAME          READY   STATUS      RESTARTS   AGE
hello-world   0/1     Completed   0          21m

ubuntu@ip-172-31-8-194:~/app$ kubectl logs hello-world

Hello from Docker!
This message shows that your installation appears to be working correctly.

To generate this message, Docker took the following steps:
 1. The Docker client contacted the Docker daemon.
 2. The Docker daemon pulled the "hello-world" image from the Docker Hub.
    (amd64)
 3. The Docker daemon created a new container from that image which runs the
    executable that produces the output you are currently reading.
 4. The Docker daemon streamed that output to the Docker client, which sent it
    to your terminal.
복사<br><br>apiVersion: v1
kind: Pod
metadata:
  name: nginx01
spec:
  containers:
  - name: nginx-test01
    image: nginx:latest
복사<br><br>
<br>입력
<br>kubectl apply -f nginx-test01.yml
복사<br>
<br>출력
<br>NAME          READY   STATUS      RESTARTS   AGE
hello-world   0/1     Completed   0          54m
nginx01       1/1     Running     0          9s
복사<br><br><br>kubectl delete -f nginx-test01.yml
복사<br>
<br>출력
<br>pod "nginx01" delete
복사<br><br>kubectl get pod
복사<br>
<br>출력
<br>NAME          READY   STATUS      RESTARTS   AGE
hello-world   0/1     Completed   0          58m
복사<br><br><br><br>
<br>입력
<br>kubectl create deployment deploy-hello --image=hello-world
복사<br>
<br>출력
<br>deployment.apps/deploy-hello create
복사<br><br>
<br>입력
<br>kubectl get all
# 혹은
kubectl get deployment,replicaset,pod
# 혹은
kubectl get deploy,rs,po
복사<br>
<br>출력
<br>NAME                                READY   STATUS             RESTARTS     AGE
pod/deploy-hello-7c478bcd59-279d9   0/1     CrashLoopBackOff   1 (5s ago)   9s
pod/hello-world                     0/1     Completed          0            18h

NAME                 TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE
service/kubernetes   ClusterIP   10.96.0.1    &lt;none&gt;        443/TCP   19h

NAME                           READY   UP-TO-DATE   AVAILABLE   AGE
deployment.apps/deploy-hello   0/1     1            0           9s

NAME                                      DESIRED   CURRENT   READY   AGE
replicaset.apps/deploy-hello-7c478bcd59   1         1         0       9s
복사<br><br>
<br>입력
<br>kubectl delete deployment deploy-hello
복사<br>
<br>출력
<br>deployment.apps "deploy-hello" deleted
복사<br><br><br><br>
<br>입력
<br>kubectl create deployment deploy-nginx --image=nginx --replicas=3
복사<br>
<br>출력
<br>deployment.apps/deploy-nginx created
복사<br><br>ubectl get deploy,rs,po

NAME                           READY   UP-TO-DATE   AVAILABLE   AGE
deployment.apps/deploy-nginx   2/3     3            2           6s

NAME                                      DESIRED   CURRENT   READY   AGE
replicaset.apps/deploy-nginx-7f979874cf   3         3         2       6s

NAME                                READY   STATUS              RESTARTS   AGE
pod/deploy-nginx-7f979874cf-dc94c   0/1     ContainerCreating   0          6s
pod/deploy-nginx-7f979874cf-f9gbh   1/1     Running             0          6s
pod/deploy-nginx-7f979874cf-x6gjl   1/1     Running             0          6s
복사<br>ubectl get deploy,rs,po -o wide

NAME                           READY   UP-TO-DATE   AVAILABLE   AGE   CONTAINERS   IMAGES   SELECTOR
deployment.apps/deploy-nginx   3/3     3            3           3m    nginx        nginx    app=deploy-nginx

NAME                                      DESIRED   CURRENT   READY   AGE   CONTAINERS   IMAGES   SELECTOR
replicaset.apps/deploy-nginx-7f979874cf   3         3         3       3m    nginx        nginx    app=deploy-nginx,pod-template-hash=7f979874cf

NAME                                READY   STATUS      RESTARTS   AGE   IP               NODE              NOMINATED NODE   READINESS GATES
pod/deploy-nginx-7f979874cf-dc94c   1/1     Running     0          3m    192.168.123.26   ip-172-31-8-194   &lt;none&gt;           &lt;none&gt;
pod/deploy-nginx-7f979874cf-f9gbh   1/1     Running     0          3m    192.168.123.25   ip-172-31-8-194   &lt;none&gt;           &lt;none&gt;
pod/deploy-nginx-7f979874cf-x6gjl   1/1     Running     0          3m    192.168.123.24   ip-172-31-8-194   &lt;none&gt;           &lt;none&gt;
복사<br><br>
<br>입력
<br>kubectl delete pod deploy-nginx-7f979874cf-x6gjl
복사<br>
<br>출력
<br>pod "deploy-nginx-7f979874cf-x6gjl" deleted
복사<br><br>
<br>입력
<br>kubectl get deploy,rs,po
복사<br>
<br>출력
<br>NAME                           READY   UP-TO-DATE   AVAILABLE   AGE
deployment.apps/deploy-nginx   3/3     3            3           9m9s

NAME                                      DESIRED   CURRENT   READY   AGE
replicaset.apps/deploy-nginx-7f979874cf   3         3         3       9m9s

NAME                                READY   STATUS      RESTARTS   AGE
pod/deploy-nginx-7f979874cf-7fwlg   1/1     Running     0          17s
pod/deploy-nginx-7f979874cf-dc94c   1/1     Running     0          9m9s
pod/deploy-nginx-7f979874cf-f9gbh   1/1     Running     0          9m9s
복사<br>NoteNAME                                READY   STATUS      RESTARTS   AGE
pod/deploy-nginx-7f979874cf-7fwlg   1/1     Running     0          17s
복사
이 부분 보면 방금 생성 된 것을 알 수 있다.<br><br><br><br><br>cd ~/k8s/basic
mkdir manifest
cd manifest
복사<br><br>vi deploy-test01.yml
복사<br><br>apiVersion: apps/v1
kind: Deployment

metadata:
  name: deploy-test01

spec:
  replicas: 3
  selector:
    matchLabels:
      app: web-deploy
  template:
    metadata:
      labels:
        app: web-deploy
    spec:
      containers:
      - name: nginx
        image: nginx:latest
복사<br><br>
<br>입력
<br>kubectl apply -f deploy-test01.yml
복사<br>
<br>출력
<br>deployment.apps/deploy-test01 created
복사<br><br>
<br>입력
<br>kubectl get deploy,rs,po
복사<br>
<br>출력
<br>NAME                            READY   UP-TO-DATE   AVAILABLE   AGE
deployment.apps/deploy-test01   3/3     3            3           6s

NAME                                       DESIRED   CURRENT   READY   AGE
replicaset.apps/deploy-test01-64b75859c6   3         3         3       6s

NAME                                 READY   STATUS    RESTARTS   AGE
pod/deploy-test01-64b75859c6-68stg   1/1     Running   0          6s
pod/deploy-test01-64b75859c6-8szmz   1/1     Running   0          6s
pod/deploy-test01-64b75859c6-crffs   1/1     Running   0          6s
복사<br><br><br>cp deploy-test01.yml deploy-test02.yml
복사<br><br>apiVersion: apps/v1
kind: Deployment

metadata:
  name: deploy-test01

spec:
  replicas: 5
  selector:
    matchLabels:
      app: web-deploy
  template:
    metadata:
      labels:
        app: web-deploy
    spec:
      containers:
      - name: nginx
        image: nginx:latest
복사<br>Notereplicas: 5 이 부분 바꾸기<br><br>
<br>입력
<br>kubectl apply -f deploy-test02.yml
복사<br>
<br>출력
<br>deployment.apps/deploy-test01 configured
복사<br><br>
<br>입력
<br>kubectl get pod
복사<br>
<br>출력
<br>NAME                             READY   STATUS    RESTARTS   AGE
deploy-test01-64b75859c6-68stg   1/1     Running   0          19m
deploy-test01-64b75859c6-8szmz   1/1     Running   0          19m
deploy-test01-64b75859c6-crffs   1/1     Running   0          19m
deploy-test01-64b75859c6-sgkbp   1/1     Running   0          5s
deploy-test01-64b75859c6-vzs4v   1/1     Running   0          5s
복사<br><br>
<br>입력
<br>kubectl delete -f deploy-test02.yml
복사<br>
<br>출력
<br>deployment.apps "deploy-test01" deleted
복사<br><br><br><br>cp deploy-test01.yml deploy-test03.yml
복사<br><br>apiVersion: apps/v1
kind: Deployment

metadata:
  name: deploy-test01

spec:
  replicas: 3
  selector:
    matchLabels:
      app: web-deploy
  template:
    metadata:
      labels:
        app: web-deploy
    spec:
      containers:
      - name: nginx
        image: nginx:1.24
복사<br>Noteimage: nginx:1.24 수정<br><br>kubectl apply -f deploy-test03.yml
복사<br><br>
<br>입력
<br>kubectl get deploy,rs,pod
복사<br>
<br>출력
<br>NAME                            READY   UP-TO-DATE   AVAILABLE   AGE
deployment.apps/deploy-test01   3/3     3            3           36s

NAME                                       DESIRED   CURRENT   READY   AGE
replicaset.apps/deploy-test01-5d4f6f8bfb   3         3         3       36s

NAME                                 READY   STATUS    RESTARTS   AGE
pod/deploy-test01-5d4f6f8bfb-9dk7t   1/1     Running   0          36s
pod/deploy-test01-5d4f6f8bfb-cxw55   1/1     Running   0          36s
pod/deploy-test01-5d4f6f8bfb-mdt48   1/1     Running   0          36s
복사<br><br>Info문제 생겼을 때 사용<br><br>
<br>입력
<br> kubectl describe deployment deploy-test01
복사<br>
<br>출력
<br>Name:                   deploy-test01
Namespace:              default
CreationTimestamp:      Wed, 05 Jun 2024 02:17:38 +0000
Labels:                 &lt;none&gt;
Annotations:            deployment.kubernetes.io/revision: 1
Selector:               app=web-deploy
Replicas:               3 desired | 3 updated | 3 total | 3 available | 0 unavailable
StrategyType:           RollingUpdate
MinReadySeconds:        0
RollingUpdateStrategy:  25% max unavailable, 25% max surge
Pod Template:
  Labels:  app=web-deploy
  Containers:
   nginx:
    Image:        nginx:1.24
    Port:         &lt;none&gt;
    Host Port:    &lt;none&gt;
    Environment:  &lt;none&gt;
    Mounts:       &lt;none&gt;
  Volumes:        &lt;none&gt;
Conditions:
  Type           Status  Reason
  ----           ------  ------
  Available      True    MinimumReplicasAvailable
  Progressing    True    NewReplicaSetAvailable
OldReplicaSets:  &lt;none&gt;
NewReplicaSet:   deploy-test01-5d4f6f8bfb (3/3 replicas created)
Events:
  Type    Reason             Age   From                   Message
  ----    ------             ----  ----                   -------
  Normal  ScalingReplicaSet  2m2s  deployment-controller  Scaled up replica set deploy-test01-5d4f6f8bfb to 3
복사<br>NoteImage:        nginx:1.24 요 부분<br><br><br>iff deploy-test03.yml deploy-test04.yml 
19c19
&lt;         image: nginx:1.24
\ No newline at end of file
---
&gt;         image: nginx:1.25
\ No newline at end of file
복사<br>kubectl apply -f deploy-test04.yml 
deployment.apps/deploy-test01 configured
복사<br>kubectl get pod
NAME                             READY   STATUS    RESTARTS   AGE
deploy-test01-689458c8c7-btbf9   1/1     Running   0          78s
deploy-test01-689458c8c7-crkds   1/1     Running   0          69s
deploy-test01-689458c8c7-hvmcw   1/1     Running   0          71s
복사<br>kubectl describe deployment deploy-test01
Name:                   deploy-test01
Namespace:              default
CreationTimestamp:      Wed, 05 Jun 2024 02:17:38 +0000
Labels:                 &lt;none&gt;
Annotations:            deployment.kubernetes.io/revision: 2
Selector:               app=web-deploy
Replicas:               3 desired | 3 updated | 3 total | 3 available | 0 unavailable
StrategyType:           RollingUpdate
MinReadySeconds:        0
RollingUpdateStrategy:  25% max unavailable, 25% max surge
Pod Template:
  Labels:  app=web-deploy
  Containers:
   nginx:
    Image:        nginx:1.25
    Port:         &lt;none&gt;
    Host Port:    &lt;none&gt;
    Environment:  &lt;none&gt;
    Mounts:       &lt;none&gt;
  Volumes:        &lt;none&gt;
Conditions:
  Type           Status  Reason
  ----           ------  ------
  Available      True    MinimumReplicasAvailable
  Progressing    True    NewReplicaSetAvailable
OldReplicaSets:  deploy-test01-5d4f6f8bfb (0/0 replicas created)
NewReplicaSet:   deploy-test01-689458c8c7 (3/3 replicas created)
Events:
  Type    Reason             Age   From                   Message
  ----    ------             ----  ----                   -------
  Normal  ScalingReplicaSet  12m   deployment-controller  Scaled up replica set deploy-test01-5d4f6f8bfb to 3
  Normal  ScalingReplicaSet  94s   deployment-controller  Scaled up replica set deploy-test01-689458c8c7 to 1
  Normal  ScalingReplicaSet  87s   deployment-controller  Scaled down replica set deploy-test01-5d4f6f8bfb to 2 from 3
  Normal  ScalingReplicaSet  87s   deployment-controller  Scaled up replica set deploy-test01-689458c8c7 to 2 from 1
  Normal  ScalingReplicaSet  85s   deployment-controller  Scaled down replica set deploy-test01-5d4f6f8bfb to 1 from 2
  Normal  ScalingReplicaSet  85s   deployment-controller  Scaled up replica set deploy-test01-689458c8c7 to 3 from 2
  Normal  ScalingReplicaSet  84s   deployment-controller  Scaled down replica set deploy-test01-5d4f6f8bfb to 0 from 1
복사<br>Note이름과 AGE가 다르다.<br>
즉, 내렸다가 다시 올린 것.<br><br><br>kubectl rollout undo deployment deploy-test01
deployment.apps/deploy-test01 rolled back
복사<br>kubectl get pod
NAME                             READY   STATUS    RESTARTS   AGE
deploy-test01-5d4f6f8bfb-98kb9   1/1     Running   0          6s
deploy-test01-5d4f6f8bfb-fdhjl   1/1     Running   0          8s
deploy-test01-5d4f6f8bfb-wk9qc   1/1     Running   0          7s
복사<br>kubectl describe deployment deploy-test01
Name:                   deploy-test01
Namespace:              default
CreationTimestamp:      Wed, 05 Jun 2024 02:17:38 +0000
Labels:                 &lt;none&gt;
Annotations:            deployment.kubernetes.io/revision: 3
Selector:               app=web-deploy
Replicas:               3 desired | 3 updated | 3 total | 3 available | 0 unavailable
StrategyType:           RollingUpdate
MinReadySeconds:        0
RollingUpdateStrategy:  25% max unavailable, 25% max surge
Pod Template:
  Labels:  app=web-deploy
  Containers:
   nginx:
    Image:        nginx:1.24
    Port:         &lt;none&gt;
    Host Port:    &lt;none&gt;
    Environment:  &lt;none&gt;
    Mounts:       &lt;none&gt;
  Volumes:        &lt;none&gt;
Conditions:
  Type           Status  Reason
  ----           ------  ------
  Available      True    MinimumReplicasAvailable
  Progressing    True    NewReplicaSetAvailable
OldReplicaSets:  deploy-test01-689458c8c7 (0/0 replicas created)
NewReplicaSet:   deploy-test01-5d4f6f8bfb (3/3 replicas created)
Events:
  Type    Reason             Age                From                   Message
  ----    ------             ----               ----                   -------
  Normal  ScalingReplicaSet  17m                deployment-controller  Scaled up replica set deploy-test01-5d4f6f8bfb to 3
  Normal  ScalingReplicaSet  7m7s               deployment-controller  Scaled up replica set deploy-test01-689458c8c7 to 1
  Normal  ScalingReplicaSet  7m                 deployment-controller  Scaled down replica set deploy-test01-5d4f6f8bfb to 2 from 3
  Normal  ScalingReplicaSet  7m                 deployment-controller  Scaled up replica set deploy-test01-689458c8c7 to 2 from 1
  Normal  ScalingReplicaSet  6m58s              deployment-controller  Scaled down replica set deploy-test01-5d4f6f8bfb to 1 from 2
  Normal  ScalingReplicaSet  6m58s              deployment-controller  Scaled up replica set deploy-test01-689458c8c7 to 3 from 2
  Normal  ScalingReplicaSet  6m57s              deployment-controller  Scaled down replica set deploy-test01-5d4f6f8bfb to 0 from 1
  Normal  ScalingReplicaSet  18s                deployment-controller  Scaled up replica set deploy-test01-5d4f6f8bfb to 1 from 0
  Normal  ScalingReplicaSet  17s                deployment-controller  Scaled down replica set deploy-test01-689458c8c7 to 2 from 3
  Normal  ScalingReplicaSet  17s                deployment-controller  Scaled up replica set deploy-test01-5d4f6f8bfb to 2 from 1
  Normal  ScalingReplicaSet  15s (x3 over 16s)  deployment-controller  (combined from similar events): Scaled down replica set deploy-test01-689458c8c7 to 0 from 1
복사<br>kubectl delete -f deploy-test04.yml
deployment.apps "deploy-test01" deleted
복사<br>kubectl get deploy,rs,po
No resources found in default namespace.
복사<br><br><br><br>apiVersion: v1
kind: Service
metadata:
  name: web-serivce
spec:
  selector:
    app: web-deploy
  type: ClusterIP
  ports:
  - protocol: TCP
    port: 80
복사<br><br>kubectl apply -f deploy-test01.yml 
deployment.apps/deploy-test01 created
복사<br><br>kubectl apply -f service-test01.yml
service/web-serivce created
복사<br>kubectl get all
NAME                                 READY   STATUS    RESTARTS   AGE
pod/deploy-test01-64b75859c6-44qr7   1/1     Running   0          25s
pod/deploy-test01-64b75859c6-bt4nh   1/1     Running   0          25s
pod/deploy-test01-64b75859c6-g8cws   1/1     Running   0          25s

NAME                  TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)   AGE
service/kubernetes    ClusterIP   10.96.0.1        &lt;none&gt;        443/TCP   22h
service/web-serivce   ClusterIP   10.101.102.172   &lt;none&gt;        80/TCP    10s

NAME                            READY   UP-TO-DATE   AVAILABLE   AGE
deployment.apps/deploy-test01   3/3     3            3           25s

NAME                                       DESIRED   CURRENT   READY   AGE
replicaset.apps/deploy-test01-64b75859c6   3         3         3       25s
복사<br>kubectl describe service web-serivce
Name:              web-serivce
Namespace:         default
Labels:            &lt;none&gt;
Annotations:       &lt;none&gt;
Selector:          app=web-deploy
Type:              ClusterIP
IP Family Policy:  SingleStack
IP Families:       IPv4
IP:                10.101.102.172
IPs:               10.101.102.172
Port:              &lt;unset&gt;  80/TCP
TargetPort:        80/TCP
Endpoints:         192.168.123.42:80,192.168.123.43:80,192.168.123.44:80
Session Affinity:  None
Events:            &lt;none&gt;
복사<br>NoteSelector:          app=web-deploy<br>
Type:              ClusterIP<br>
Endpoints:         192.168.123.42:80,192.168.123.43:80,192.168.123.44:80<br>Endpointspod 아이피
kubectl get pod -o wide<br>
NAME                             READY   STATUS    RESTARTS   AGE     IP               NODE              NOMINATED NODE   READINESS GATES<br>
deploy-test01-64b75859c6-44qr7   1/1     Running   0          5m43s   192.168.123.43   ip-172-31-8-194              <br>
deploy-test01-64b75859c6-bt4nh   1/1     Running   0          5m43s   192.168.123.42   ip-172-31-8-194              <br>
deploy-test01-64b75859c6-g8cws   1/1     Running   0          5m43s   192.168.123.44   ip-172-31-8-194              <br>kubectl get all

NAME                                 READY   STATUS    RESTARTS   AGE
pod/deploy-test01-64b75859c6-44qr7   1/1     Running   0          6m57s
pod/deploy-test01-64b75859c6-bt4nh   1/1     Running   0          6m57s
pod/deploy-test01-64b75859c6-g8cws   1/1     Running   0          6m57s
pod/nginx01                          1/1     Running   0          8s

NAME                  TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)   AGE
service/kubernetes    ClusterIP   10.96.0.1        &lt;none&gt;        443/TCP   22h
service/web-serivce   ClusterIP   10.101.102.172   &lt;none&gt;        80/TCP    6m42s

NAME                            READY   UP-TO-DATE   AVAILABLE   AGE
deployment.apps/deploy-test01   3/3     3            3           6m57s
복사<br><br>kubectl exec -it nginx01 -- /bin/bash
root@nginx01:/# 
root@nginx01:/# curl "10.101.102.172:80"
복사<br>
<br>출력
<br>&lt;!DOCTYPE html&gt;
&lt;html&gt;
&lt;head&gt;
&lt;title&gt;Welcome to nginx!&lt;/title&gt;
&lt;style&gt;
html { color-scheme: light dark; }
body { width: 35em; margin: 0 auto;
font-family: Tahoma, Verdana, Arial, sans-serif; }
&lt;/style&gt;
&lt;/head&gt;
&lt;body&gt;
&lt;h1&gt;Welcome to nginx!&lt;/h1&gt;
&lt;p&gt;If you see this page, the nginx web server is successfully installed and
working. Further configuration is required.&lt;/p&gt;

&lt;p&gt;For online documentation and support please refer to
&lt;a href="http://nginx.org/"&gt;nginx.org&lt;/a&gt;.&lt;br/&gt;
Commercial support is available at
&lt;a href="http://nginx.com/"&gt;nginx.com&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Thank you for using nginx.&lt;/em&gt;&lt;/p&gt;
&lt;/body&gt;
&lt;/html&gt;
복사<br><br>kubectl delete -f service-test01.yml
service "web-service" deleted

kubectl delete -f nginx-test01.yml
pod "nginx01" deleted

kubectl delete -f deploy-test01.yml
deployment.apps "deploy-test01" deleted

kubectl get pod
No resources found in default namespace.

복사<br><br><br><br>
<br>포트: 31001
<br>소스: 내 아이피
<br><br>apiVersion: v1
kind: Service
metadata:
  name: web-service-nodeport
spec:
  selector:
    app: web-deploy
  type: NodePort
  ports:
  - protocol: TCP
    nodePort: 31001
    port: 80
    targetPort: 80
복사<br><br>kubectl apply -f deploy-test01.yml
deployment.apps/deploy-test01 created
복사<br>kubectl apply -f service-test02.yml 
service/web-service-nodeport created
복사<br>kubectl get all
NAME          READY   STATUS    RESTARTS   AGE
pod/nginx01   1/1     Running   0          19m

NAME                           TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)        AGE
service/kubernetes             ClusterIP   10.96.0.1      &lt;none&gt;        443/TCP        22h
service/web-service-nodeport   NodePort    10.103.10.28   &lt;none&gt;        80:31001/TCP   8s
복사<br>CheckNodePort<br>
80:31001/TCP<br><br>Note브라우저에서<br>
http://43.203.77.126:31001/<br>
접근하면 쿠버의 80번 포트를 통해 nginx로 진입함
최종 출력

If you see this page, the nginx web server is successfully installed and working. Further configuration is required.
For online documentation and support please refer to&nbsp;<a data-tooltip-position="top" aria-label="http://nginx.org/" rel="noopener" class="external-link" href="http://nginx.org/" target="_blank">nginx.org</a>.<br>
Commercial support is available at&nbsp;<a data-tooltip-position="top" aria-label="http://nginx.com/" rel="noopener" class="external-link" href="http://nginx.com/" target="_blank">nginx.com</a>.
Thank you for using nginx.<br><br>kubectl delete -f deploy-test01.yml 
deployment.apps "deploy-test01" deleted
복사<br>kubectl delete -f service-test02.yml 
service "web-service-nodeport" deleted
복사<br>kubectl get all
NAME                 TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE
service/kubernetes   ClusterIP   10.96.0.1    &lt;none&gt;        443/TCP   23h
복사<br><br><br>Note이건 개념만<br><br><br><br>apiVersion: v1
kind: Pod
metadata:
  name: nginx-volume-01
spec:
  containers:
  - name: nginx-test01
    image: nginx:latest
    volumeMounts:
    - name: empty-test01
      mountPath: /mount01
  volumes:
  - name: empty-test01
    emptyDir: {}

복사<br>kubectl apply -f volume-test01.yml 
pod/nginx-volume-01 created
복사<br>kubectl get pod
NAME              READY   STATUS    RESTARTS   AGE
nginx-volume-01   1/1     Running   0          44s
복사<br>kubectl exec -it nginx-volume-01 -- /bin/bash

ls

bin   docker-entrypoint.d   home   media    opt   run   sys  var
boot  docker-entrypoint.sh  lib    mnt      proc  sbin  tmp
dev   etc                   lib64  mount01  root  srv   usr
복사<br>cd mount01/
echo "hello yeardream!" &gt; ./test.txt
cat test.txt 
hello yeardream!
exit
복사<br>Notepod가 없어지면 volum의 데이터도 없어진다.<br>ls
deploy-test01.yml  deploy-test04.yml  service-test01.yml  vim
deploy-test02.yml  manifest           service-test02.yml  volume-test01.yml
deploy-test03.yml  nginx-test01.yml   ubuntu-test01.yml

kubectl get pod
NAME              READY   STATUS    RESTARTS   AGE
nginx-volume-01   1/1     Running   0          8m58s

kubectl delete -f volume-test01.yml
pod "nginx-volume-01" deleted

kubectl get pod
No resources found in default namespace.

kubectl apply -f volume-test01.yml
pod/nginx-volume-01 created

kubectl get pod
NAME              READY   STATUS    RESTARTS   AGE
nginx-volume-01   1/1     Running   0          6s

kubectl exec -it nginx-volume-01 -- /bin/bash
cd mount01/
ls
exit
복사<br><br>kubectl delete -f volume-test01.yml
pod "nginx-volume-01" deleted
kubectl get pod
No resources found in default namespace.
복사<br><br><br>Fail이 부분 잘 안됐음<br><br>kubectl get nodes --show-labels

NAME              STATUS   ROLES           AGE   VERSION   LABELS
ip-172-31-8-194   Ready    control-plane   23h   v1.29.5   beta.kubernetes.io/arch=amd64,beta.kubernetes.io/os=linux,kubernetes.io/arch=amd64,kubernetes.io/hostname=ip-172-31-8-194,kubernetes.io/os=linux,node-role.kubernetes.io/control-plane=,node.kubernetes.io/exclude-from-external-load-balancers=
복사<br>Notehostname=ip-172-31-8-194<br>
자신의 private ip와 같은지 확인<br><br>mkdir volhost01
cd volhost01/
pwd
/home/ubuntu/work/k8s/basic/volhost01
cd ..
복사<br>유념ip-172-31-8-194<br>
/home/ubuntu/work/k8s/basic/volhost01<br><br> vi volume-test02.yml
복사<br>apiVersion: v1
kind: Pod
metadata:
  name: nginx-volume-02
spec:
  nodeSelector:
    kubernetes.io/hostname: ip-172-31-8-194
  containers:
  - name: nginx-test01
    image: nginx:latest
    volumeMounts:
    - name: hostpath-test01
      mountPath: /mount01
  volumes:
  - name: hostpath-test01
    hostPath:
      path: /home/ubuntu/work/k8s/basic/volhost01
      type: DirectoryOrCreate
복사<br><br>kubectl get pod
NAME              READY   STATUS    RESTARTS   AGE
nginx-volume-02   1/1     Running   0          7s
복사<br>kubectl exec -it nginx-volume-02 -- /bin/bash
ls
bin   docker-entrypoint.d   home   media    opt   run   sys  var
boot  docker-entrypoint.sh  lib    mnt      proc  sbin  tmp
dev   etc                   lib64  mount01  root  srv   usr
cd mount01/
복사<br>echo "hello yeardream" &gt;./test01.txt

ls
test01.txt

cat test01.txt 
hello yeardream

exit
복사<br><br>ubuntu@ip-172-31-8-194:~/work/k8s/basic$ kubectl delete -f volume-test02.yml
pod "nginx-volume-02" deleted
ubuntu@ip-172-31-8-194:~/work/k8s/basic$ kubectl get pod
No resources found in default namespace.
ubuntu@ip-172-31-8-194:~/work/k8s/basic$ kubectl get all
NAME                 TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE
service/kubernetes   ClusterIP   10.96.0.1    &lt;none&gt;        443/TCP   24h
복사<br><br><br><br>ubuntu@ip-172-31-8-194:~$ sudo -i
root@ip-172-31-8-194:~# cd /tmp/
root@ip-172-31-8-194:/tmp# ls
code-1c77821e-c114-45ac-80da-acf86198216a
snap-private-tmp
systemd-private-0169308c496c46a59c932439e54822cb-ModemManager.service-OKICBG
systemd-private-0169308c496c46a59c932439e54822cb-chrony.service-FtI0Pb
systemd-private-0169308c496c46a59c932439e54822cb-polkit.service-zn0PYQ
systemd-private-0169308c496c46a59c932439e54822cb-systemd-logind.service-l2pOPZ
systemd-private-0169308c496c46a59c932439e54822cb-systemd-resolved.service-6Ru3eP
root@ip-172-31-8-194:/tmp# mkdir k8spv
root@ip-172-31-8-194:/tmp# ls
code-1c77821e-c114-45ac-80da-acf86198216a
k8spv
snap-private-tmp
systemd-private-0169308c496c46a59c932439e54822cb-ModemManager.service-OKICBG
systemd-private-0169308c496c46a59c932439e54822cb-chrony.service-FtI0Pb
systemd-private-0169308c496c46a59c932439e54822cb-polkit.service-zn0PYQ
systemd-private-0169308c496c46a59c932439e54822cb-systemd-logind.service-l2pOPZ
systemd-private-0169308c496c46a59c932439e54822cb-systemd-resolved.service-6Ru3eP
root@ip-172-31-8-194:/tmp# exit
logout
복사<br><br> sudo apt install nfs-common
 sudo apt install nfs-kernel-server
복사<br><br>sudo apt install nfs-kernel-server

---
Reading package lists... Done
Building dependency tree... Done
Reading state information... Done
The following NEW packages will be installed:
  nfs-kernel-server
0 upgraded, 1 newly installed, 0 to remove and 17 not upgraded.
Need to get 169 kB of archives.
After this operation, 606 kB of additional disk space will be used.
Get:1 http://ap-northeast-2.ec2.archive.ubuntu.com/ubuntu noble/main amd64 nfs-kernel-server amd64 1:2.6.4-3ubuntu5 [169 kB]
Fetched 169 kB in 0s (7007 kB/s)          
Selecting previously unselected package nfs-kernel-server.
(Reading database ... 82822 files and directories currently installed.)
Preparing to unpack .../nfs-kernel-server_1%3a2.6.4-3ubuntu5_amd64.deb ...
Unpacking nfs-kernel-server (1:2.6.4-3ubuntu5) ...
Setting up nfs-kernel-server (1:2.6.4-3ubuntu5) ...
Created symlink /etc/systemd/system/nfs-mountd.service.requires/fsidd.service → /usr/lib/systemd/system/fsidd.service.
Created symlink /etc/systemd/system/nfs-server.service.requires/fsidd.service → /usr/lib/systemd/system/fsidd.service.
Created symlink /etc/systemd/system/nfs-client.target.wants/nfs-blkmap.service → /usr/lib/systemd/system/nfs-blkmap.service.
Created symlink /etc/systemd/system/multi-user.target.wants/nfs-server.service → /usr/lib/systemd/system/nfs-server.service.
nfs-mountd.service is a disabled or a static unit, not starting it.
nfsdcld.service is a disabled or a static unit, not starting it.

Creating config file /etc/exports with new version

Creating config file /etc/default/nfs-kernel-server with new version
Processing triggers for man-db (2.12.0-4build2) ...
Scanning processes...                                                                           
Scanning linux images...                                                                        

Running kernel seems to be up-to-date.

No services need to be restarted.

No containers need to be restarted.

No user sessions are running outdated binaries.

No VM guests are running outdated hypervisor (qemu) binaries on this host.
ubuntu@ip-172-31-8-194:~$ systemctl status nfs-server.service
● nfs-server.service - NFS server and services
     Loaded: loaded (/usr/lib/systemd/system/nfs-server.service; enabled; preset: enabled)
     Active: active (exited) since Wed 2024-06-05 06:15:46 UTC; 1min 27s ago
   Main PID: 98259 (code=exited, status=0/SUCCESS)
        CPU: 16ms
복사<br><br><br><br>sudo vim /etc/exports
복사<br><br>/tmp/k8spv 172.31.8.194(rw,no_root_squash)
복사<br><br>sudo systemctl restart nfs-server
systemctl status nfs-server.service
복사<br><br>apiVersion: v1
kind: PersistentVolume
metadata:
  name: pv-01
spec:
  accessModes:
  - ReadWriteOnce
  capacity:
    storage: 100Mi
  persistentVolumeReclaimPolicy: Retain
  storageClassName: pv-test-01
  nfs:
    server: 172.31.8.19
    path: /tmp/k8spv
복사<br><br>apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: pvc-01
spec:
  accessModes:
  - ReadWriteOnce
  resources:
    requests:
      storage: 30Mi
  storageClassName: pv-test-01

복사<br><br>apiVersion: v1
kind: Pod
metadata:
  name: nginx-volume-04
spec:
  containers:
  - name: nginx-test01
    image: nginx:latest
    volumeMounts:
    - name: nfs-pv-01
      mountPath: /mount01
  volumes:
  - name: nfs-pv-01
    persistentVolumeClaim:
      claimName: pvc-01
복사<br><br>ubectl apply -f volume-test04-1-pv.yml

persistentvolume/pv-01 created

ubuntu@ip-172-31-8-194:~/work/k8s/basic$ kubectl get pv

NAME    CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS      CLAIM   STORAGECLASS   VOLUMEATTRIBUTESCLASS   REASON   AGE
pv-01   100Mi      RWO            Retain           Available           pv-test-01     &lt;unset&gt;                          18s
복사<br><br>kubectl apply -f volume-test04-2-pvc.yml

kubectl get pvc

NAME     STATUS   VOLUME   CAPACITY   ACCESS MODES   STORAGECLASS   VOLUMEATTRIBUTESCLASS   AGE
pvc-01   Bound    pv-01    100Mi      RWO            pv-test-01     &lt;unset&gt;                 9s
복사<br>
<br>page 113
<br>Failpod 부분에서 안됨<br><br>ubuntu@ip-172-31-2-228:~/work/k8s/basic$ kubectl delete -f volume-test04-3-pod.yml
pod "nginx-volume-04" deleted
ubuntu@ip-172-31-2-228:~/work/k8s/basic$ kubectl delete -f volume-test04-2-pvc.yml
persistentvolumeclaim "pvc-01" deleted
ubuntu@ip-172-31-2-228:~/work/k8s/basic$ kubectl delete -f volume-test04-1-pv.yml
persistentvolume "pv-01" deleted

No resources found
복사<br><br><br>Notepass<br><br><br><br><br>cd ~/app
복사<br><br>curl -fsSL -o get_helm.sh https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3

ls
get_helm.sh
복사<br><br>chmod 700 get_helm.sh

-rwx------  1 ubuntu ubuntu 11694 Jun  5 07:18 get_helm.sh
복사<br><br>./get_helm.sh 

Downloading https://get.helm.sh/helm-v3.15.1-linux-amd64.tar.gz
Verifying checksum... Done.
Preparing to install helm into /usr/local/bin
helm installed into /usr/local/bin/helm
복사<br><br>helm version

version.BuildInfo{Version:"v3.15.1", GitCommit:"e211f2aa62992bd72586b395de50979e31231829", GitTreeState:"clean", GoVersion:"go1.22.3"}
복사<br><br><br>helm repo add bitnami https://charts.bitnami.com/bitnami
"bitnami" has been added to your repositories
복사<br><br>helm repo update

Hang tight while we grab the latest from your chart repositories...
...Successfully got an update from the "bitnami" chart repository
Update Complete. ⎈Happy Helming!⎈
복사<br><br><br>helm search repo nginx

NAME                                    CHART VERSION   APP VERSION     DESCRIPTION                                       
bitnami/nginx                           17.3.2          1.26.1          NGINX Open Source is a web server that can be a...
bitnami/nginx-ingress-controller        11.3.2          1.10.1          NGINX Ingress Controller is an Ingress controll...
bitnami/nginx-intel                     2.1.15          0.4.9           DEPRECATED NGINX Open Source for Intel is a lig...
복사<br><br>helm pull bitnami/nginx-ingress-controller
복사<br><br>ls

get_helm.sh  nginx-ingress-controller-11.3.2.tgz
복사<br><br>tar xvfz nginx-ingress-controller-11.3.2.tgz
복사<br><br>mv nginx-ingress-controller nginx-ingress-controller-11.3.2
복사<br><br>cd nginx-ingress-controller-11.3.2/
ls
Chart.lock  Chart.yaml  README.md  charts  templates  values.yaml
cp values.yaml my-values.yaml
복사<br>Attention항상 values.yaml를 복사해서 원복을 훼손하지 말 것.<br><br><br>kubectl get namespace

NAME               STATUS   AGE
calico-apiserver   Active   25h
calico-system      Active   25h
default            Active   25h
kube-node-lease    Active   25h
kube-public        Active   25h
kube-system        Active   25h
tigera-operator    Active   25h
복사<br><br>
<br>입력
<br>kubectl create namespace mynginx

namespace/mynginx created
복사<br>
<br>확인
<br>kubectl get namespace
NAME               STATUS   AGE
calico-apiserver   Active   25h
calico-system      Active   25h
default            Active   25h
kube-node-lease    Active   25h
kube-public        Active   25h
kube-system        Active   25h
mynginx            Active   14s # 여기 생성
tigera-operator    Active   25h
복사<br><br>
<br>
p: 149

<br>
입력

<br>helm install --namespace mynginx --generate-name bitnami/nginx-ingress-controller -f my-values.yaml
복사<br>
<br>출력
<br> --generate-name bitnami/nginx-ingress-controller -f my-values.yaml
NAME: nginx-ingress-controller-1717573067
LAST DEPLOYED: Wed Jun  5 07:37:50 2024
NAMESPACE: mynginx
STATUS: deployed
REVISION: 1
TEST SUITE: None
NOTES:
CHART NAME: nginx-ingress-controller
CHART VERSION: 11.3.2
APP VERSION: 1.10.1

** Please be patient while the chart is being deployed **

The nginx-ingress controller has been installed.

Get the application URL by running these commands:

 NOTE: It may take a few minutes for the LoadBalancer IP to be available.
        You can watch its status by running 'kubectl get --namespace mynginx svc -w nginx-ingress-controller-1717573067'

    export SERVICE_IP=$(kubectl get svc --namespace mynginx nginx-ingress-controller-1717573067 -o jsonpath='{.status.loadBalancer.ingress[0].ip}')
    echo "Visit http://${SERVICE_IP} to access your application via HTTP."
    echo "Visit https://${SERVICE_IP} to access your application via HTTPS."

An example Ingress that makes use of the controller:

  apiVersion: networking.k8s.io/v1
  kind: Ingress
  metadata:
    name: example
    namespace: mynginx
  spec:
    ingressClassName: nginx
    rules:
      - host: www.example.com
        http:
          paths:
            - backend:
                service:
                  name: example-service
                  port:
                    number: 80
              path: /
              pathType: Prefix
    # This section is only required if TLS is to be enabled for the Ingress
    tls:
        - hosts:
            - www.example.com
          secretName: example-tls

If TLS is enabled for the Ingress, a Secret containing the certificate and key must also be provided:

  apiVersion: v1
  kind: Secret
  metadata:
    name: example-tls
    namespace: mynginx
  data:
    tls.crt: &lt;base64 encoded cert&gt;
    tls.key: &lt;base64 encoded key&gt;
  type: kubernetes.io/tls

WARNING: There are "resources" sections in the chart not set. Using "resourcesPreset" is not recommended for production. For production installations, please set the following values according to your workload needs:
  - defaultBackend.resources
  - resources
+info https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/
복사<br><br>helm ls --namespace mynginx

NAME                                    NAMESPACE       REVISION        UPDATED                                       STATUS          CHART                           APP VERSION
nginx-ingress-controller-1717573067     mynginx         1               2024-06-05 07:37:50.718429183 +0000 UTC       deployed        nginx-ingress-controller-11.3.2 1.10.1  
복사<br>ubectl get all --namespace mynginx

NAME                                                                  READY   STATUS    RESTARTS   AGE
pod/nginx-ingress-controller-1717573067-7cdb6cdd94-fcq5f              1/1     Running   0          2m43s
pod/nginx-ingress-controller-1717573067-default-backend-776648m7hqx   1/1     Running   0          2m43s

NAME                                                          TYPE           CLUSTER-IP       EXTERNAL-IP   PORT(S)                      AGE
service/nginx-ingress-controller-1717573067                   LoadBalancer   10.102.206.3     &lt;pending&gt;     80:31628/TCP,443:31052/TCP   2m43s
service/nginx-ingress-controller-1717573067-default-backend   ClusterIP      10.105.185.146   &lt;none&gt;        80/TCP                       2m43s

NAME                                                                  READY   UP-TO-DATE   AVAILABLE   AGE
deployment.apps/nginx-ingress-controller-1717573067                   1/1     1            1           2m43s
deployment.apps/nginx-ingress-controller-1717573067-default-backend   1/1     1            1           2m43s

NAME                                                                             DESIRED   CURRENT   READY   AGE
replicaset.apps/nginx-ingress-controller-1717573067-7cdb6cdd94                   1         1         1       2m43s
replicaset.apps/nginx-ingress-controller-1717573067-default-backend-7766484699   1         1         1       2m43s
복사<br>NoteSTATUS Runnig 확인<br><br><br><br>
<br>입력
<br>kubectl get configmap kube-proxy -n kube-system -o yaml | grep strictARP
복사<br>
<br>출력
<br>strictARP: false
복사<br>NotestrictARP이 false 인 것을 확인<br><br>
<br>입력
<br>kubectl get configmap kube-proxy -n kube-system -o yaml | \
sed -e "s/strictARP: false/strictARP: true/" | \
kubectl apply -f - -n kube-system
복사<br>
<br>출력
<br>Warning: resource configmaps/kube-proxy is missing the kubectl.kubernetes.io/last-applied-configuration annotation which is required by kubectl apply. kubectl apply should only be used on resources created declaratively by either kubectl create --save-config or kubectl apply. The missing annotation will be patched automatically.
configmap/kube-proxy configured
복사<br><br>
<br>입력
<br>kubectl get configmap kube-proxy -n kube-system -o yaml | grep strictARP
복사<br>
<br>출력
<br>      strictARP: true
      {"apiVersion":"v1","data":{"config.conf":"apiVersion: kubeproxy.config.k8s.io/v1alpha1\nbindAddress: 0.0.0.0\nbindAddressHardFail: false\nclientConnection:\n  acceptContentTypes: \"\"\n  burst: 0\n  contentType: \"\"\n  kubeconfig: /var/lib/kube-proxy/kubeconfig.conf\n  qps: 0\nclusterCIDR: 192.168.0.0/16\nconfigSyncPeriod: 0s\nconntrack:\n  maxPerCore: null\n  min: null\n  tcpBeLiberal: false\n  tcpCloseWaitTimeout: null\n  tcpEstablishedTimeout: null\n  udpStreamTimeout: 0s\n  udpTimeout: 0s\ndetectLocal:\n  bridgeInterface: \"\"\n  interfaceNamePrefix: \"\"\ndetectLocalMode: \"\"\nenableProfiling: false\nhealthzBindAddress: \"\"\nhostnameOverride: \"\"\niptables:\n  localhostNodePorts: null\n  masqueradeAll: false\n  masqueradeBit: null\n  minSyncPeriod: 0s\n  syncPeriod: 0s\nipvs:\n  excludeCIDRs: null\n  minSyncPeriod: 0s\n  scheduler: \"\"\n  strictARP: true\n  syncPeriod: 0s\n  tcpFinTimeout: 0s\n  tcpTimeout: 0s\n  udpTimeout: 0s\nkind: KubeProxyConfiguration\nlogging:\n  flushFrequency: 0\n  options:\n    json:\n      infoBufferSize: \"0\"\n  verbosity: 0\nmetricsBindAddress: \"\"\nmode: \"\"\nnftables:\n  masqueradeAll: false\n  masqueradeBit: null\n  minSyncPeriod: 0s\n  syncPeriod: 0s\nnodePortAddresses: null\noomScoreAdj: null\nportRange: \"\"\nshowHiddenMetricsForVersion: \"\"\nwinkernel:\n  enableDSR: false\n  forwardHealthCheckVip: false\n  networkName: \"\"\n  rootHnsEndpointName: \"\"\n  sourceVip: \"\"","kubeconfig.conf":"apiVersion: v1\nkind: Config\nclusters:\n- cluster:\n    certificate-authority: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt\n    server: https://172.31.8.194:6443\n  name: default\ncontexts:\n- context:\n    cluster: default\n    namespace: default\n    user: default\n  name: default\ncurrent-context: default\nusers:\n- name: default\n  user:\n    tokenFile: /var/run/secrets/kubernetes.io/serviceaccount/token"},"kind":"ConfigMap","metadata":{"annotations":{"kubeadm.kubernetes.io/component-config.hash":"sha256:092ec924dfe74025c759063274668834178cdc79b06aa8e7d644a43d9fc98eec"},"creationTimestamp":"2024-06-04T05:37:57Z","labels":{"app":"kube-proxy"},"name":"kube-proxy","namespace":"kube-system","resourceVersion":"267","uid":"d6ce53fa-2820-410c-ae59-b5d6123b9909"}}
복사<br><br><br>helm repo add metallb https://metallb.github.io/metallb
"metallb" has been added to your repositories
복사<br><br>helm repo update
Hang tight while we grab the latest from your chart repositories...
...Successfully got an update from the "metallb" chart repository
...Successfully got an update from the "bitnami" chart repository
Update Complete. ⎈Happy Helming!⎈
복사<br><br>helm search repo metallb

NAME            CHART VERSION   APP VERSION     DESCRIPTION                                       
bitnami/metallb 6.3.3           0.14.5          MetalLB is a load-balancer implementation for b...
metallb/metallb 0.14.5          v0.14.5         A network load-balancer implementation for Kube...
복사<br><br>helm pull metallb/metallb
복사<br><br>ls

custom-resources.yaml  metallb-0.14.5.tgz               nginx-ingress-controller-11.3.2.tgz
get_helm.sh            nginx-ingress-controller-11.3.2
복사<br>tar xvfz metallb-0.14.5.tgz

metallb/Chart.yaml
metallb/Chart.lock
metallb/values.yaml
metallb/values.schema.json
metallb/templates/NOTES.txt
metallb/templates/_helpers.tpl
metallb/templates/controller.yaml
metallb/templates/deprecated_configInline.yaml
metallb/templates/exclude-l2-config.yaml
metallb/templates/podmonitor.yaml
metallb/templates/prometheusrules.yaml
metallb/templates/rbac.yaml
metallb/templates/service-accounts.yaml
metallb/templates/servicemonitor.yaml
metallb/templates/speaker.yaml
metallb/templates/webhooks.yaml
metallb/.helmignore
metallb/README.md
metallb/policy/controller.rego
metallb/policy/rbac.rego
metallb/policy/speaker.rego
metallb/charts/crds/Chart.yaml
metallb/charts/crds/templates/crds.yaml
metallb/charts/crds/.helmignore
metallb/charts/crds/README.md
metallb/charts/frr-k8s/Chart.yaml
metallb/charts/frr-k8s/Chart.lock
metallb/charts/frr-k8s/values.yaml
metallb/charts/frr-k8s/values.schema.json
metallb/charts/frr-k8s/templates/NOTES.txt
metallb/charts/frr-k8s/templates/_helpers.tpl
metallb/charts/frr-k8s/templates/controller.yaml
metallb/charts/frr-k8s/templates/rbac.yaml
metallb/charts/frr-k8s/templates/service-accounts.yaml
metallb/charts/frr-k8s/templates/service-monitor.yaml
metallb/charts/frr-k8s/templates/webhooks.yaml
metallb/charts/frr-k8s/.helmignore
metallb/charts/frr-k8s/README.md
metallb/charts/frr-k8s/charts/crds/Chart.yaml
metallb/charts/frr-k8s/charts/crds/templates/frrk8s.metallb.io_frrconfigurations.yaml
metallb/charts/frr-k8s/charts/crds/templates/frrk8s.metallb.io_frrnodestates.yaml
metallb/charts/frr-k8s/charts/crds/.helmignore
metallb/charts/frr-k8s/charts/crds/README.md
복사<br><br>mv metallb metallb-0.14.5
cd metallb-0.14.5
cp values.yaml my-values.yaml
복사<br><br>kubectl create namespace mymetallb
namespace/mymetallb created


kubectl get namespace

NAME               STATUS   AGE
calico-apiserver   Active   2d22h
calico-system      Active   2d22h
default            Active   2d23h
kube-node-lease    Active   2d23h
kube-public        Active   2d23h
kube-system        Active   2d23h
mymetallb          Active   71s
mynginx            Active   45h
tigera-operator    Active   2d22h
복사<br>helm install --namespace mymetallb --generate-name metallb/metallb -f my-values.yaml


NAME: metallb-1717736694
LAST DEPLOYED: Fri Jun  7 05:04:54 2024
NAMESPACE: mymetallb
STATUS: deployed
REVISION: 1
TEST SUITE: None
NOTES:
MetalLB is now running in the cluster.

Now you can configure it via its CRs. Please refer to the metallb official docs
on how to use the CRs.

복사<br>kubectl get all --namespace mymetallb
NAME                                               READY   STATUS    RESTARTS   AGE
pod/metallb-1717736694-controller-d686bb4f-lvs6h   1/1     Running   0          63s
pod/metallb-1717736694-speaker-hprv4               4/4     Running   0          63s

NAME                              TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)   AGE
service/metallb-webhook-service   ClusterIP   10.111.176.187   &lt;none&gt;        443/TCP   63s

NAME                                        DESIRED   CURRENT   READY   UP-TO-DATE   AVAILABLE   NODE SELECTOR            AGE
daemonset.apps/metallb-1717736694-speaker   1         1         1       1            1           kubernetes.io/os=linux   63s

NAME                                            READY   UP-TO-DATE   AVAILABLE   AGE
deployment.apps/metallb-1717736694-controller   1/1     1            1           63s

NAME                                                     DESIRED   CURRENT   READY   AGE
replicaset.apps/metallb-1717736694-controller-d686bb4f   1         1         1       63s
복사<br><br>vi vim my-config.yaml
복사<br>---
apiVersion: metallb.io/v1beta1
kind: IPAddressPool
metadata:
  name: my-metallb-config
  namespace: mymetallb
spec:
  addresses:
  - 172.31.46.220-172.31.46.230
  autoAssign: true
---
apiVersion: metallb.io/v1beta1
kind: L2Advertisement
metadata:
  name: my-metallb-config
  namespace: mymetallb
spec:
  ipAddressPools:
    - my-metallb-config
복사<br>Notespec:<br>
addresses:

<br>172.31.46.220-172.31.46.230

요 부분을 내 아이피 대역으로 바꿔야 한다<br>
<br>입력
<br>kubectl get validatingwebhookconfigurations
복사<br>
<br>출력
<br>kubectl get validatingwebhookconfigurations
NAME                            WEBHOOKS   AGE
metallb-webhook-configuration   6          12m
복사<br>
<br>입력
<br>kubectl delete validatingwebhookconfigurations metallb-webhook-configuration

kubectl get validatingwebhookconfigurations
복사<br>
<br>출력
<br>No resources found
복사<br><br>ubectl apply -f my-config.yaml

ipaddresspool.metallb.io/my-metallb-config created
l2advertisement.metallb.io/my-metallb-config create
복사<br>kubectl get ipaddresspool.metallb.io --namespace mymetallb

NAME                AUTO ASSIGN   AVOID BUGGY IPS   ADDRESSES
my-metallb-config   true          false             ["172.31.134.0-172.31.134.10"]
복사<br>kubectl describe ipaddresspool.metallb.io my-metallb-config --namespace mymetallb
복사<br><br>kubectl describe ipaddresspool.metallb.io my-metallb-config --namespace mymetallb


Name:         my-metallb-config
Namespace:    mymetallb
Labels:       &lt;none&gt;
Annotations:  &lt;none&gt;
API Version:  metallb.io/v1beta1
Kind:         IPAddressPool
Metadata:
  Creation Timestamp:  2024-06-07T05:20:04Z
  Generation:          1
  Resource Version:    239615
  UID:                 d2588db8-e3b6-4d60-b9d6-eb1b876a1fe7
Spec:
  Addresses:
    172.31.134.0-172.31.134.10
  Auto Assign:       true
  Avoid Buggy I Ps:  false
복사<br>kubectl get all --namespace mynginx
NAME                                                                  READY   STATUS    RESTARTS        AGE
pod/nginx-ingress-controller-1717573067-7cdb6cdd94-fcq5f              1/1     Running   2 (4h35m ago)   45h
pod/nginx-ingress-controller-1717573067-default-backend-776648m7hqx   1/1     Running   2 (4h35m ago)   45h

NAME                                                          TYPE           CLUSTER-IP       EXTERNAL-IP    PORT(S)                      AGE
service/nginx-ingress-controller-1717573067                   LoadBalancer   10.102.206.3     172.31.134.0   80:31628/TCP,443:31052/TCP   45h
service/nginx-ingress-controller-1717573067-default-backend   ClusterIP      10.105.185.146   &lt;none&gt;         80/TCP                       45h

NAME                                                                  READY   UP-TO-DATE   AVAILABLE   AGE
deployment.apps/nginx-ingress-controller-1717573067                   1/1     1            1           45h
deployment.apps/nginx-ingress-controller-1717573067-default-backend   1/1     1            1           45h

NAME                                                                             DESIRED   CURRENT   READY   AGE
replicaset.apps/nginx-ingress-controller-1717573067-7cdb6cdd94                   1         1         1       45h
replicaset.apps/nginx-ingress-controller-1717573067-default-backend-7766484699   1         1         1       45h
복사<br><br><br><br>vim ingress01-deploy.yml
복사<br>apiVersion: apps/v1
kind: Deployment
metadata:
  name: ingress-deploy-test01
spec:
  replicas: 3
  selector:
    matchLabels:
      app: web-deploy01
  template:
    metadata:
      labels:
        app: web-deploy01
    spec:
      containers:
        - name: nginx
          image: nginx:1.25
복사<br><br>vim ingress01-service.yml
복사<br>apiVersion: v1
kind: Service
metadata:
  name: ingress-service-test01
spec:
  selector:
    app: web-deploy01
  type: ClusterIP
  ports:
    - protocol: TCP
      port: 80
      targetPort: 80
복사<br><br> vim ingress01-ingress.yml
복사<br>apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: ingress-test01
  annotations:
    nginx.ingress.kubernetes.io/rewrite-target: /
spec:
  ingressClassName: nginx
  rules:
    - http:
        paths:
          - path: /test01
            pathType: Prefix
            backend:
              service:
                name: ingress-service-test01
                port:
                  number: 80

복사<br><br>kubectl apply -f ingress01-deploy.yml
deployment.apps/ingress-deploy-test01 created

kubectl apply -f ingress01-service.yml
service/ingress-service-test01 created

kubectl apply -f ingress01-ingress.yml
ingress.networking.k8s.io/ingress-test01 created
복사<br><br>kubectl get all


NAME                                         READY   STATUS    RESTARTS   AGE
pod/ingress-deploy-test01-796d5b8df4-5pndl   1/1     Running   0          52s
pod/ingress-deploy-test01-796d5b8df4-97q6v   1/1     Running   0          52s
pod/ingress-deploy-test01-796d5b8df4-xvnq5   1/1     Running   0          52s

NAME                             TYPE        CLUSTER-IP    EXTERNAL-IP   PORT(S)   AGE
service/ingress-service-test01   ClusterIP   10.107.65.7   &lt;none&gt;        80/TCP    46s
service/kubernetes               ClusterIP   10.96.0.1     &lt;none&gt;        443/TCP   3d

NAME                                    READY   UP-TO-DATE   AVAILABLE   AGE
deployment.apps/ingress-deploy-test01   3/3     3            3           52s

NAME                                               DESIRED   CURRENT   READY   AGE
replicaset.apps/ingress-deploy-test01-796d5b8df4   3         3         3       52s
복사<br>kubectl get ingress

NAME             CLASS   HOSTS   ADDRESS        PORTS   AGE
ingress-test01   nginx   *       172.31.8.194   80      67s
복사<br><br><br>sudo apt-get update
복사<br>sudo apt-get install nginx

sudo systemctl status nginx
복사<br><br>sudo -i
cd /etc/nginx/sites-enabled/

ls
default

sudo vi default 
복사<br>
<br>EXTERNAL-IP 확인
<br>kubectl get all --namespace mynginx

NAME                                                                  READY   STATUS    RESTARTS        AGE
pod/nginx-ingress-controller-1717573067-7cdb6cdd94-fcq5f              1/1     Running   2 (5h29m ago)   46h
pod/nginx-ingress-controller-1717573067-default-backend-776648m7hqx   1/1     Running   2 (5h29m ago)   46h

NAME                                                          TYPE           CLUSTER-IP       EXTERNAL-IP  
service/nginx-ingress-controller-1717573067                   LoadBalancer   10.102.206.3     172.31.134.0 # 이거
복사<br>ubuntu@ip-172-31-8-194:~/work/k8s/basic$ sudo -i
root@ip-172-31-8-194:~# cd /etc/nginx/sites-enabled/
root@ip-172-31-8-194:/etc/nginx/sites-enabled# ls
default
root@ip-172-31-8-194:/etc/nginx/sites-enabled# sudo vi default 
복사<br>location / {
	# First attempt to serve request as file, then
	# as directory, then fall back to displaying a 404.
	# try_files $uri $uri/ =404; # 이거 주석
	proxy_pass http://172.31.134.0:80; # 이거  EXTERNAL-IP 넣기
}
복사<br>
<br>nginx 재시작
<br>status nginx
● nginx.service - A high performance web server and a reverse proxy server
     Loaded: loaded (/usr/lib/systemd/system/nginx.service; enabled; preset: enabled)
     Active: active (running) since Fri 2024-06-07 06:21:04 UTC; 8s ago
복사<br>Notehttp://내_public_ip/test01
복사
위로 접속하면 nginx의 welcome to nginx가 뜨면 성공<br><br>Check
kubectl delete -f ingress01-ingress.yml
복사
ingress.networking.k8s.io "ingress-test01" deleted

kubectl delete -f ingress01-service.yml
복사
service "ingress-service-test01" deleted

kubectl delete -f ingress01-deploy.yml
복사
deployment.apps "ingress-deploy-test01" deleted

kubectl get all
복사
NAME                 TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE<br>
service/kubernetes   ClusterIP   10.96.0.1            443/TCP   3d<br><br><br><br>vim ingress02-deploy.yml
복사<br>apiVersion: apps/v1
kind: Deployment
metadata:
  name: ingress-deploy-test02
spec:
  replicas: 3
  selector:
    matchLabels:
      app: web-deploy02
  template:
    metadata:
      labels:
        app: web-deploy02
    spec:
      containers:
        - name: nginx
          image: nginx:1.25

복사<br><br>vim ingress02-service.yml
복사<br>apiVersion: v1
kind: Service
metadata:
  name: ingress-service-test02
spec:
  selector:
    app: web-deploy02
  type: ClusterIP
  ports:
    - protocol: TCP
      port: 80
      targetPort: 80

복사<br><br>vim ingress02-ingress.yml
복사<br>apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: ingress-test02
  annotations:
    nginx.ingress.kubernetes.io/rewrite-target: /
spec:
  ingressClassName: nginx
  rules:
    - http:
        paths:
          - path: /test01
            pathType: Prefix
            backend:
              service:
                name: ingress-service-test01
                port:
                  number: 80
          - path: /test02
            pathType: Prefix
            backend:
              service:
                name: ingress-service-test02
                port:
                  number: 80

복사<br><br>Note
kubectl apply -f ingress01-deploy.yml
복사
deployment.apps/ingress-deploy-test01 created
kubectl apply -f ingress01-service.yml
복사
service/ingress-service-test01 created

kubectl apply -f ingress02-deploy.yml
복사
deployment.apps/ingress-deploy-test02 created
kubectl apply -f ingress02-service.yml
복사
service/ingress-service-test02 created

kubectl apply -f ingress02-ingress.yml
복사
ingress.networking.k8s.io/ingress-test02 created<br><br>kubectl get all

NAME                                         READY   STATUS    RESTARTS   AGE
pod/ingress-deploy-test01-796d5b8df4-5w2fk   1/1     Running   0          62s
pod/ingress-deploy-test01-796d5b8df4-fslj6   1/1     Running   0          62s
pod/ingress-deploy-test01-796d5b8df4-qjtj5   1/1     Running   0          62s
pod/ingress-deploy-test02-679c4755c5-d9fnk   1/1     Running   0          53s
pod/ingress-deploy-test02-679c4755c5-xhxbw   1/1     Running   0          53s
pod/ingress-deploy-test02-679c4755c5-z59zm   1/1     Running   0          53s

NAME                             TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)   AGE
service/ingress-service-test01   ClusterIP   10.108.168.160   &lt;none&gt;        80/TCP    57s
service/ingress-service-test02   ClusterIP   10.97.21.105     &lt;none&gt;        80/TCP    49s
service/kubernetes               ClusterIP   10.96.0.1        &lt;none&gt;        443/TCP   3d1h

NAME                                    READY   UP-TO-DATE   AVAILABLE   AGE
deployment.apps/ingress-deploy-test01   3/3     3            3           62s
deployment.apps/ingress-deploy-test02   3/3     3            3           53s

NAME                                               DESIRED   CURRENT   READY   AGE
replicaset.apps/ingress-deploy-test01-796d5b8df4   3         3         3       62s
replicaset.apps/ingress-deploy-test02-679c4755c5   3         3         3       53s
복사<br>Notehttp://내_public_ip/test02
복사
위로 접속하면 nginx의 welcome to nginx가 뜨면 성공<br><br>Notekubectl delete -f ingress02-ingress.yml
복사
ingress.networking.k8s.io "ingress-test02" deleted
kubectl delete -f ingress02-service.yml
복사
service "ingress-service-test02" deleted
kubectl delete -f ingress02-deploy.yml
복사
deployment.apps "ingress-deploy-test02" deleted
kubectl delete -f ingress01-service.yml
복사
service "ingress-service-test01" deleted
kubectl delete -f ingress01-deploy.yml
복사
deployment.apps "ingress-deploy-test01" deleted
kubectl get all
복사
NAME                 TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE
service/kubernetes   ClusterIP   10.96.0.1            443/TCP   3d1h<br><br><br><br>vim job-cronjob01.yml
복사<br>apiVersion: batch/v1
kind: Job
metadata:
  name: job-test01
spec:
  template:
    spec:
      containers:
        - name: nginx-test01
          image: nginx:1.25
          command: ["echo", "Hello, Kubernetes!"]
      restartPolicy: Never
  backoffLimit: 3

복사<br><br>kubectl apply -f job-cronjob01.yml

job.batch/job-test01 created


kubectl get job

NAME         COMPLETIONS   DURATION   AGE
job-test01   1/1           3s         15s
복사<br>kubectl describe job job-test01


Name:             job-test01
Namespace:        default
Selector:         batch.kubernetes.io/controller-uid=d2c6efd7-68ab-4160-ba27-8bf6af72e019
Labels:           batch.kubernetes.io/controller-uid=d2c6efd7-68ab-4160-ba27-8bf6af72e019
                  batch.kubernetes.io/job-name=job-test01
                  controller-uid=d2c6efd7-68ab-4160-ba27-8bf6af72e019
                  job-name=job-test01
Annotations:      &lt;none&gt;
Parallelism:      1
Completions:      1
Completion Mode:  NonIndexed
Start Time:       Fri, 07 Jun 2024 07:28:10 +0000
Completed At:     Fri, 07 Jun 2024 07:28:13 +0000
Duration:         3s
Pods Statuses:    0 Active (0 Ready) / 1 Succeeded / 0 Failed
Pod Template:
  Labels:  batch.kubernetes.io/controller-uid=d2c6efd7-68ab-4160-ba27-8bf6af72e019
           batch.kubernetes.io/job-name=job-test01
           controller-uid=d2c6efd7-68ab-4160-ba27-8bf6af72e019
           job-name=job-test01
  Containers:
   nginx-test01:
    Image:      nginx:1.25
    Port:       &lt;none&gt;
    Host Port:  &lt;none&gt;
    Command:
      echo
      Hello, Kubernetes!
    Environment:  &lt;none&gt;
    Mounts:       &lt;none&gt;
  Volumes:        &lt;none&gt;
Events:
  Type    Reason            Age   From            Message
  ----    ------            ----  ----            -------
  Normal  SuccessfulCreate  60s   job-controller  Created pod: job-test01-q6fqx
  Normal  Completed         57s   job-controller  Job completed
복사<br>Checkkubectl get pods
복사
NAME               READY   STATUS      RESTARTS   AGE<br>
job-test01-q6fqx   0/1     Completed   0          91s
kubectl logs job-test01-q6fqx
복사
Hello, Kubernetes!<br><br>Checkkubectl delete -f job-cronjob01.yml
복사
job.batch "job-test01" deleted
kubectl get pod
복사
No resources found in default namespace.
kubectl get job
복사
No resources found in default namespace.<br><br><br><br>vim job-cronjob02.yml
복사<br>apiVersion: batch/v1
kind: CronJob
metadata:
  name: cronjob-test02
spec:
  schedule: "*/1 * * * *"
  jobTemplate:
    spec:
      template:
        spec:
          containers:
            - name: nginx-test02
              image: nginx:1.25
              command:
                - /bin/sh
                - -c
                - echo Hello Kubernetes!
          restartPolicy: Never

복사<br><br>ubuntu@ip-172-31-8-194:~/work/k8s/basic$ kubectl apply -f job-cronjob02.yml
cronjob.batch/cronjob-test02 created
ubuntu@ip-172-31-8-194:~/work/k8s/basic$  kubectl get cronjob
NAME             SCHEDULE      SUSPEND   ACTIVE   LAST SCHEDULE   AGE
cronjob-test02   */1 * * * *   False     0        &lt;none&gt;          5s
복사<br>kubectl describe cronjob cronjob-test02
Name:                          cronjob-test02
Namespace:                     default
Labels:                        &lt;none&gt;
Annotations:                   &lt;none&gt;
Schedule:                      */1 * * * *
Concurrency Policy:            Allow
Suspend:                       False
Successful Job History Limit:  3
Failed Job History Limit:      1
Starting Deadline Seconds:     &lt;unset&gt;
Selector:                      &lt;unset&gt;
Parallelism:                   &lt;unset&gt;
Completions:                   &lt;unset&gt;
Pod Template:
  Labels:  &lt;none&gt;
  Containers:
   nginx-test02:
    Image:      nginx:1.25
    Port:       &lt;none&gt;
    Host Port:  &lt;none&gt;
    Command:
      /bin/sh
      -c
      echo Hello Kubernetes!
    Environment:     &lt;none&gt;
    Mounts:          &lt;none&gt;
  Volumes:           &lt;none&gt;
Last Schedule Time:  Fri, 07 Jun 2024 07:37:00 +0000
Active Jobs:         &lt;none&gt;
Events:
  Type    Reason            Age   From                Message
  ----    ------            ----  ----                -------
  Normal  SuccessfulCreate  17s   cronjob-controller  Created job cronjob-test02-28629097
  Normal  SawCompletedJob   14s   cronjob-controller  Saw completed job: cronjob-test02-28629097, status: Complete
복사<br>복사<br><br>Notekubectl delete -f job-cronjob02.yml
복사
cronjob.batch "cronjob-test02" deleted
kubectl get cronjob
복사
No resources found in default namespace.
kubectl get pods
복사
No resources found in default namespace.]]></description><link>root\dev\도커와-쿠버네티스\쿠버네티스-사용법.html</link><guid isPermaLink="false">root/dev/도커와 쿠버네티스/쿠버네티스 사용법.md</guid><pubDate>Fri, 07 Jun 2024 07:42:22 GMT</pubDate></item><item><title><![CDATA[쿠버네티스 설치]]></title><description><![CDATA[ 
 <br>Attention신중하게 처리<br><br><br><br>sudo -i
복사<br>Notesudo를 사용해도 좋지만<br>
안전하게 root 유저로 작업하는 게 좋다.<br><br>
<br>입력
<br>sudo modprobe br_netfilter
sudo sysctl net.bridge.bridge-nf-call-iptables=1
복사<br>
<br>출력
<br>net.bridge.bridge-nf-call-iptables = 1
복사<br><br>
<br>입력
<br>sudo sysctl net.ipv4.ip_forward=1
복사<br>
<br>출력
<br>net.ipv4.ip_forward = 1
복사<br><br><br>sudo vim /etc/sysctl.conf
복사<br>
<br>입력
<br>net.bridge.bridge-nf-call-iptables=1
net.ipv4.ip_forward=1
복사<br>Note제일 하단에 추가<br><br><br>
<br>입력
<br>free -h
복사<br>
<br>출력
<br>               total        used        free      shared  buff/cache   available
Mem:            15Gi       1.3Gi        12Gi        14Mi       1.9Gi        14Gi
Swap:             0B          0B          0B
복사<br><br>
<br>입력
<br>cat /proc/swaps
복사<br>
<br>출력
<br>Filename        Type            Size            Used            Priority
복사<br>Note위처럼 아무것도 나오지 않는다면 따로 처리 할 필요 없음<br><br><br><br>경고!sudo -i 로 들어 갔다면<br>
exit 로 빠저 나와서 유저 모드로 돌아오자<br><br>sudo mkdir -p /etc/containerd
containerd config default | sudo tee /etc/containerd/config.toml &gt; /dev/null
복사<br><br><br>sudo vim /etc/containerd/config.toml
복사<br>요놈이랑 햇깔리지 마!systemd_cgroup<br><br>SystemdCgroup = true
복사<br>변경false -&gt; true<br><br><br>sudo systemctl restart containerd
복사<br><br>sudo systemctl enable containerd
복사<br><br>sudo systemctl status containerd
복사<br><br><br><br>sudo apt-get update
복사<br>sudo apt-get install -y apt-transport-https ca-certificates curl
복사<br><br>집중!공식 홈페이지와 다름<br><br>sudo mkdir -p /etc/apt/keyrings
복사<br><br>sudo curl -fsSL https://pkgs.k8s.io/core:/stable:/v1.29/deb/Release.key | sudo gpg --dearmor -o /etc/apt/keyrings/kubernetes-apt-keyring.gpg
복사<br>요 부분은 공식 홈페이지가 될 수 있음<br><br>echo "deb [signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.gpg] https://pkgs.k8s.io/core:/stable:/v1.29/deb/ /" | sudo tee /etc/apt/sources.list.d/kubernetes.list
복사<br><br>sudo apt-get install -y kubelet kubeadm kubectl
복사<br><br>
<br>입력
<br>sudo apt-mark hold kubelet kubeadm kubectl
복사<br><br><br>sudo -i

kubelet --version
kubeadm version
kubectl version --output=yaml
복사<br><br><br>
<br>입력
<br>kubeadm certs check-expiration
복사<br>
<br>출력
<br>CERTIFICATE                          EXPIRES   RESIDUAL TIME   CERTIFICATE AUTHORITY   EXTERNALLY MANAGED
!MISSING! admin.conf                                                                   
!MISSING! apiserver                                                                    
!MISSING! apiserver-etcd-client                                                        
!MISSING! apiserver-kubelet-client                                                     
!MISSING! controller-manager.conf                                                      
!MISSING! etcd-healthcheck-client                                                      
!MISSING! etcd-peer                                                                    
!MISSING! etcd-server                                                                  
!MISSING! front-proxy-client                                                           
!MISSING! scheduler.conf                                                               
!MISSING! super-admin.conf                                                             

CERTIFICATE AUTHORITY      EXPIRES   RESIDUAL TIME   EXTERNALLY MANAGED
!MISSING! ca                                         
!MISSING! etcd-ca                                    
!MISSING! front-proxy-ca
복사<br><br><br>
<br>입력
<br>kubeadm config images list
복사<br>
<br>출력
<br>I0604 05:30:21.666700   24505 version.go:256] remote version is much newer: v1.30.1; falling back to: stable-1.29
registry.k8s.io/kube-apiserver:v1.29.5
registry.k8s.io/kube-controller-manager:v1.29.5
registry.k8s.io/kube-scheduler:v1.29.5
registry.k8s.io/kube-proxy:v1.29.5
registry.k8s.io/coredns/coredns:v1.11.1
registry.k8s.io/pause:3.9
registry.k8s.io/etcd:3.5.12-0
복사<br><br><br>kubeadm config images pull --cri-socket /run/containerd/containerd.sock
복사<br><br>
<br>입력
<br>프라이빗IPv4주소kubeadm init --apiserver-advertise-address=프라이빗IPv4주소 --pod-network-cidr=192.168.0.0/16 --cri-socket /run/containerd/containerd.sock<br>kubeadm init --apiserver-advertise-address=172.31.8.194 --pod-network-cidr=192.168.0.0/16 --cri-socket /run/containerd/containerd.sock
복사<br>
<br>출력
<br>kubeadm join 172.31.8.194:6443 --token l07ssr.dbnlpaeoyfc9e2w6 \
        --discovery-token-ca-cert-hash sha256:dfc39dd25f073da5a783d047f173aef5f2d89fc0927c3409a6b15a906fd1e215
복사<br><br>
<br>입력
<br>kubeadm certs check-expiration
복사<br>
<br>출력
<br>CERTIFICATE             EXPIRES             RESIDUAL TIME   CERTIFICATE AUTHORITY   EXTERNALLY MANAGED
admin.conf              May 26, 2025        06:41 UTC      364d                    ca                      no
apiserver               May 26, 2025        06:41 UTC      364d                    ca                      no
apiserver-etcd-client   May 26, 2025        06:41 UTC      364d                    etcd-ca                 no
apiserver-kubelet-clientMay 26, 2025        06:41 UTC      364d                    ca                      no
controller-manager.conf May 26, 2025        06:42 UTC      364d                    ca                      no
etcd-healthcheck-clientMay 26, 2025        06:41 UTC      364d                    etcd-ca                 no
etcd-peer               May 26, 2025        06:41 UTC      364d                    etcd-ca                 no
etcd-server             May 26, 2025        06:41 UTC      364d                    etcd-ca                 no
front-proxy-client      May 26, 2025        06:41 UTC      364d                    front-proxy-ca          no
scheduler.conf          May 26, 2025        06:42 UTC      364d                    ca                      no
super-admin.conf        May 26, 2025        06:41 UTC      364d                    ca                      no

CERTIFICATE AUTHORITY   EXPIRES             RESIDUAL TIME   EXTERNALLY MANAGED
ca                      May 24, 2034        06:41 UTC      9y                      no
etcd-ca                 May 24, 2034        06:41 UTC      9y                      no
front-proxy-ca          May 24, 2034        06:41 UTC      9y                      no

복사<br><br>exit
mkdir -p $HOME/.kube
sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
sudo chown $(id -u):$(id -g) $HOME/.kube/config
복사<br><br><br><br>cd
mkdir app
cd app
복사<br><br>kubectl create -f https://raw.githubusercontent.com/projectcalico/calico/v3.28.0/manifests/tigera-operator.yaml
복사<br><br>curl https://raw.githubusercontent.com/projectcalico/calico/v3.28.0/manifests/custom-resources.yaml -O
복사<br><br>kubectl create -f custom-resources.yaml
복사<br><br>
<br>입력
<br>watch kubectl get pods -n calico-system
복사<br>
<br>출력
<br>Every 2.0s: kubectl get pods -n calico-system        ip-172-31-8-194: Tue Jun  4 06:16:25 2024

NAME                                       READY   STATUS    RESTARTS   AGE
calico-kube-controllers-75d46bdfb9-v4f54   1/1     Running   0          4m31s
calico-node-fhkdm                          1/1     Running   0          4m19s
calico-typha-6b76c875f4-zmhd5              1/1     Running   0          4m31s
csi-node-driver-jjrbv                      2/2     Running   0          4m31s
복사<br><br><br><br>
<br>입력
<br>kubectl get node
복사<br>
<br>출력
<br>NAME              STATUS   ROLES           AGE   VERSION
ip-172-31-8-194   Ready    control-plane   39m   v1.29.5
복사<br><br>kubectl describe node k8s-master | grep Taints
복사<br><br>
<br>입력
<br>kubectl get node -o wide
복사<br>
<br>출력
<br>NAME              STATUS   ROLES           AGE   VERSION   INTERNAL-IP    EXTERNAL-IP   OS-IMAGE           KERNEL-VERSION   CONTAINER-RUNTIME
ip-172-31-8-194   Ready    control-plane   47m   v1.29.5   172.31.8.194   &lt;none&gt;        Ubuntu 24.04 LTS   6.8.0-1008-aws   containerd://1.6.32
복사<br><br><br>kubectl describe node 노드이름 | grep Taints
복사<br><br>kubectl describe node ip-172-31-8-194 | grep Taints
복사<br><br><br>
<br>입력
<br>kubectl describe node ip-172-31-8-194 | grep Taints
복사<br>
<br>출력
<br>Taints:             node-role.kubernetes.io/control-plane:NoSchedule
복사<br><br>
<br>입력
<br>kubectl taint nodes --all node-role.kubernetes.io/control-plane-
복사<br>
<br>출력
<br>untainted
복사<br><br><br>
<br>입력
<br>kubectl run hello-world --image=hello-world --restart=Never
kubectl get pod
kubectl get pod -o wide
복사<br>
<br>출력
<br># kubectl run hello-world --image=hello-world --restart=Never
pod/hello-world created

# kubectl get pod
NAME          READY   STATUS      RESTARTS   AGE
hello-world   0/1     Completed   0          5s


# kubectl get pod -o wide
NAME          READY   STATUS      RESTARTS   AGE   IP              NODE              NOMINATED NODE   READINESS GATES
hello-world   0/1     Completed   0          11s   192.168.123.7   ip-172-31-8-194 
복사]]></description><link>root\dev\도커와-쿠버네티스\쿠버네티스-설치.html</link><guid isPermaLink="false">root/dev/도커와 쿠버네티스/쿠버네티스 설치.md</guid><pubDate>Thu, 06 Jun 2024 03:59:07 GMT</pubDate></item><item><title><![CDATA[docker compose]]></title><description><![CDATA[ 
 <br><br><a rel="noopener" class="external-link" href="https://docs.docker.com/compose/install/linux/#install-using-the-repository" target="_blank">https://docs.docker.com/compose/install/linux/#install-using-the-repository</a><br>sudo apt-get update
sudo apt-get install docker-compose-plugin

# 버전 확인
docker compose version
복사<br>]]></description><link>root\dev\도커와-쿠버네티스\docker-compose.html</link><guid isPermaLink="false">root/dev/도커와 쿠버네티스/docker compose.md</guid><pubDate>Mon, 03 Jun 2024 11:22:27 GMT</pubDate></item><item><title><![CDATA[enginx 도커 올려]]></title><description><![CDATA[ 
 <br><br>cd ~/work/docker
mkdir nginxtest
복사<br><br><br>FROM nginx:1.26.0

CMD ["nginx", "-g", "daemon off;"]
복사<br><br><br># ~/work/docker/nginxtest
docker image build . -t mynginx01
복사<br>docker image ls
복사<br>REPOSITORY    TAG       IMAGE ID       CREATED         SIZE
flaskapi01    latest    a8c4fa3dda54   2 days ago      1.38GB
my-ubuntu     0.1       47f1ae23d4f6   3 days ago      114MB
# 여기
mynginx01     latest    6f5998e2d7ff   4 weeks ago     188MB
ubuntu        latest    bf3dc08bfed0   4 weeks ago     76.2MB
hello-world   latest    d2c94e258dcb   13 months ago   13.3kB
복사<br><br><br><br>docker container run -d mynginx01
복사<br><br>docker container ls
복사<br>CONTAINER ID   IMAGE       COMMAND                  CREATED         STATUS         PORTS     NAMES
43ec4cd47554   mynginx01   "/docker-entrypoint.…"   5 seconds ago   Up 4 seconds   80/tcp    sweet_johnson
복사<br>CheckSTATUS Up 확인<br><br><br><a rel="noopener" class="external-link" href="https://docs.docker.com/compose/install/linux/#install-using-the-repository" target="_blank">https://docs.docker.com/compose/install/linux/#install-using-the-repository</a><br>sudo apt-get update
sudo apt-get install docker-compose-plugin

# 버전 확인
docker compose version

복사<br><br><br>.
├── docker
│   ├── flaskapp
│   │   ├── Dockerfile
│   │   ├── myapp
│   │   │   └── main.py
│   │   └── requirements.txt
│   └── nginxtest
│       └── Dockerfile
├── flaskapp
│   └── main.py
└── test
    └── while_loop.py
복사<br><br><br>cd ~/work/docker/flaskapp
vi requirements.txt
복사<br>scikit-learn==1.5.0
flask==3.0.3
psycopg2==2.9.9
gunicorn==22.0.0
복사<br>Notegunicorn==22.0.0 추가<br><br><br><br>
<br>p: 121
<br>server{
	listen 80;
	server_name localhost;

	location /{
		proxy_pass http://flasktest:5000;
	}
}
복사<br>Importantflasktest: 컨테이너 이름<br><br>FROM nginx:1.26.0

RUN rm /etc/nginx/conf.d/default.conf

COPY default.conf /etc/nginx/conf.d/

CMD ["nginx", "-g", "daemon off;"]
복사<br><br><br><br><br>cd ~/work/docker
vi docker-compose.yml
복사<br>services:
  flasktest:
    build: ./flaskapp
    networks:
      - composenet01
    restart: always
  
  nginxtest:
    build: ./nginxtest
    networks:
      - composenet01
    ports:
      - "80:80"
    depends_on:
      - flasktest

networks:
  composenet01:

복사<br>Infodepends_on:
- flasktest
복사
플라스트 시작 하고 실행<br><br>~/work/docker$ tree
.
├── docker-compose.yml
├── flaskapp
│   ├── Dockerfile
│   ├── myapp
│   │   └── main.py
│   └── requirements.txt
└── nginxtest
    ├── Dockerfile
    └── default.conf
복사<br><br><br>cd ~/work/docker
ls
docker-compose.yml flaskapp nginxtest
복사<br><br>docker compose up -d --build
복사<br><br>[+] Building 38.2s (19/19) FINISHED                                            docker:default
 =&gt; [flasktest internal] load build definition from Dockerfile                           0.0s
 =&gt; =&gt; transferring dockerfile: 240B                                                     0.0s
 =&gt; [flasktest internal] load metadata for docker.io/library/python:3.11.9               1.4s
 =&gt; [flasktest internal] load .dockerignore                                              0.0s
 =&gt; =&gt; transferring context: 2B                                                          0.0s
 =&gt; [flasktest 1/6] FROM docker.io/library/python:3.11.9@sha256:091e0f5da680e5c972c59cb  0.0s
 =&gt; [flasktest internal] load build context                                              0.0s
 =&gt; =&gt; transferring context: 1.49kB                                                      0.0s
 =&gt; CACHED [flasktest 2/6] WORKDIR /usr/src/app                                          0.0s
 =&gt; [flasktest 3/6] COPY . .                                                             0.0s
 =&gt; [flasktest 4/6] RUN python -m pip install --upgrade pip                              3.7s
 =&gt; [flasktest 5/6] RUN pip install -r requirements.txt                                 28.3s 
 =&gt; [flasktest 6/6] WORKDIR ./myapp                                                      0.1s 
 =&gt; [flasktest] exporting to image                                                       2.5s 
 =&gt; =&gt; exporting layers                                                                  2.4s 
 =&gt; =&gt; writing image sha256:c3c423501acbb875a188b1dcb382c53be8aaef291e2b34f89af4be2ccbe  0.0s
 =&gt; =&gt; naming to docker.io/library/docker-flasktest                                      0.0s
 =&gt; [nginxtest internal] load build definition from Dockerfile                           0.0s
 =&gt; =&gt; transferring dockerfile: 169B                                                     0.0s
 =&gt; [nginxtest internal] load metadata for docker.io/library/nginx:1.26.0                1.4s
 =&gt; [nginxtest internal] load .dockerignore                                              0.0s
 =&gt; =&gt; transferring context: 2B                                                          0.0s
 =&gt; CACHED [nginxtest 1/3] FROM docker.io/library/nginx:1.26.0@sha256:192e88a0053c17868  0.0s
 =&gt; [nginxtest internal] load build context                                              0.0s
 =&gt; =&gt; transferring context: 138B                                                        0.0s
 =&gt; [nginxtest 2/3] RUN rm /etc/nginx/conf.d/default.conf                                0.2s
 =&gt; [nginxtest 3/3] COPY default.conf /etc/nginx/conf.d/                                 0.1s
 =&gt; [nginxtest] exporting to image                                                       0.1s
 =&gt; =&gt; exporting layers                                                                  0.0s
 =&gt; =&gt; writing image sha256:658637f4e58bd21bc65735eaa372fdda01d7b6a77dcb7c9e309c72ecf5f  0.0s
 =&gt; =&gt; naming to docker.io/library/docker-nginxtest                                      0.0s
[+] Running 3/3
 ✔ Network docker_composenet01   Created                                                 0.1s 
 ✔ Container docker-flasktest-1  Started                                                 0.4s 
 ✔ Container docker-nginxtest-1  Started                                                 0.7s
복사<br><br>docker compose down
복사<br>[+] Running 3/3
 ✔ Container docker-nginxtest-1  Removed                                                 0.2s 
 ✔ Container docker-flasktest-1  Removed                                                10.2s 
 ✔ Network docker_composenet01   Removed  
복사<br><br>안됐을 때는<br>docker container ls
복사<br>그리고 status 확인<br><br><br>curl -d "{""input"":[""0.3""]}" -H "Content-Type: application/json" -X POST http://인스턴스IP주소/predict
Run복사<br><br>curl -d '{"input":["0.３"]}' -H "Content-Type: application/json" -X POST http://내_공개_ip/predict
복사<br><br>sudo -i -u postgres
복사<br>\c ml
SELECT * FROM pred_result;
Run복사<br><br>\q
Run복사<br>exit
복사]]></description><link>root\dev\도커와-쿠버네티스\enginx-도커-올려.html</link><guid isPermaLink="false">root/dev/도커와 쿠버네티스/enginx 도커 올려.md</guid><pubDate>Mon, 03 Jun 2024 11:22:49 GMT</pubDate></item><item><title><![CDATA[flask 건들기 위한 Docker]]></title><description><![CDATA[ 
 <br><a rel="noopener" class="external-link" href="https://docs.docker.com/engine/install/ubuntu/" target="_blank">https://docs.docker.com/engine/install/ubuntu/</a><br><br># Add Docker's official GPG key:
sudo apt-get update
sudo apt-get install ca-certificates curl
sudo install -m 0755 -d /etc/apt/keyrings
sudo curl -fsSL https://download.docker.com/linux/ubuntu/gpg -o /etc/apt/keyrings/docker.asc
sudo chmod a+r /etc/apt/keyrings/docker.asc

# Add the repository to Apt sources:
echo \
  "deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.asc] https://download.docker.com/linux/ubuntu \
  $(. /etc/os-release &amp;&amp; echo "$VERSION_CODENAME") stable" | \
  sudo tee /etc/apt/sources.list.d/docker.list &gt; /dev/null
sudo apt-get update
복사<br><br><br>sudo apt-get install docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin
복사<br><br><br>sudo usermod -aG docker $USER
exec $SHELL

# 재접속
exit
복사<br><br><br><br>docker
docker version
복사<br>Attention권한 설정이 안돼있으면
sudo docker
​<br>
docker --version
​<br><br>systemctl status docker
복사<br><br><br><br><br>docker container run hello-world
복사<br><br>Hello from Docker!
This message shows that your installation appears to be working correctly.

To generate this message, Docker took the following steps:
 1. The Docker client contacted the Docker daemon.
 2. The Docker daemon pulled the "hello-world" image from the Docker Hub.
    (amd64)
 3. The Docker daemon created a new container from that image which runs the
    executable that produces the output you are currently reading.
 4. The Docker daemon streamed that output to the Docker client, which sent it
    to your terminal.

To try something more ambitious, you can run an Ubuntu container with:
 $ docker run -it ubuntu bash

Share images, automate workflows, and more with a free Docker ID:
 https://hub.docker.com/

For more examples and ideas, visit:
 https://docs.docker.com/get-started/
복사<br><br><br>docker container ls
복사<br><br>docker container ls -a
복사<br><br><br><br>docker container run -it ubuntu
복사<br>Notepull, create, start, attach를 한번에 한 효과를 보게 된다.<br>
그리고 종료 할 때는 exit<br><br>exit
복사]]></description><link>root\dev\도커와-쿠버네티스\flask-건들기-위한-docker.html</link><guid isPermaLink="false">root/dev/도커와 쿠버네티스/flask 건들기 위한 Docker.md</guid><pubDate>Sun, 02 Jun 2024 17:26:07 GMT</pubDate></item><item><title><![CDATA[flask docker에 태우자]]></title><description><![CDATA[ 
 <br> AWS client to docker database<br>
<a data-tooltip-position="top" aria-label="AWS client to docker database.canvas" data-href="AWS client to docker database.canvas" href="root\dev\도커와-쿠버네티스\aws-client-to-docker-database.html" class="internal-link" target="_self" rel="noopener">보기</a><br><br><br>.
├── docker
│   └── flaskapp
│       ├── Dockerfile
│       ├── myapp
│       │   └── main.py
│       └── requirements.txt
└── flaskapp
    └── main.py
복사<br>Attentiontest와 while_loop.py 파일이 있을 수 있지만<br>
docker와 flaskapp 디렉토리 구조가 같다면 문제 없음<br><br>sudo apt install tree
복사<br><br># 작업 디렉토리로 이동
cd ~/work

# main.py 파일 flaskapp 디렉토리 이동
mkdir flaskapp
mv main.py flaskapp

# flaskapp 디렉토리 docker 디렉토리 안으로 복사
mkdir docker 
cp -r flaskapp docker # -r 옵션은 깊은 복사

# 작업 디렉토리 변경
cd docker/flaskapp/

# main.py myapp 디렉토리로 이동
mkdir myapp
mv main.py myapp

# 설정 파일 생성
touch Dockerfile
touch requirements.txt

# 전체 디렉토리 확인
cd ~/work
tree
복사<br><br><br>매우!여기서<br>
conn = psycopg2.connect(dbname='ml', user='postgres', password='postgres', host='172.17.0.1', port=5432)
​
host 부분을 docker ip로 바꿔 줘야 한다.
하지 않으면 클라이언트에서 post로 db에 접근 하지 못한다.<br><br>ifconfig
복사<br>하면<br>docker0: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;  mtu 1500
        inet 172.17.0.1  netmask 255.255.0.0  broadcast 172.17.255.255
        inet6 fe80::42:82ff:fe9b:e70e  prefixlen 64  scopeid 0x20&lt;link&gt;
        ether 02:42:82:9b:e7:0e  txqueuelen 0  (Ethernet)
        RX packets 372  bytes 39785 (39.7 KB)
        RX errors 0  dropped 0  overruns 0  frame 0
        TX packets 314  bytes 59552 (59.5 KB)
        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0

enX0: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;  mtu 9001
        inet 172.31.8.194  netmask 255.255.240.0  broadcast 172.31.15.255
        inet6 fe80::39:1aff:feff:673  prefixlen 64  scopeid 0x20&lt;link&gt;
        ether 02:39:1a:ff:06:73  txqueuelen 1000  (Ethernet)
        RX packets 134980  bytes 52783685 (52.7 MB)
        RX errors 0  dropped 0  overruns 0  frame 0
        TX packets 113282  bytes 18350518 (18.3 MB)
        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0

lo: flags=73&lt;UP,LOOPBACK,RUNNING&gt;  mtu 65536
        inet 127.0.0.1  netmask 255.0.0.0
        inet6 ::1  prefixlen 128  scopeid 0x10&lt;host&gt;
        loop  txqueuelen 1000  (Local Loopback)
        RX packets 223904  bytes 18604065 (18.6 MB)
        RX errors 0  dropped 0  overruns 0  frame 0
        TX packets 223904  bytes 18604065 (18.6 MB)
        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0

veth889f608: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;  mtu 1500
        inet6 fe80::8488:9bff:fe4d:3fb1  prefixlen 64  scopeid 0x20&lt;link&gt;
        ether 86:88:9b:4d:3f:b1  txqueuelen 0  (Ethernet)
        RX packets 355  bytes 42968 (42.9 KB)
        RX errors 0  dropped 0  overruns 0  frame 0
        TX packets 313  bytes 58612 (58.6 KB)
        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0
복사<br>이런 형식이 나올 텐데.<br>
docker0의 inet 172.17.0.1 부분을 넣어 주면 된다.<br><br>import numpy as np
from sklearn.linear_model import LinearRegression
import psycopg2
from flask import Flask, request, jsonify
app = Flask(__name__)
# 학습
np.random.seed(0)
X = np.random.rand(10, 1)
y = 2 * X + 1 + 0.1 * np.random.randn(10, 1)
model = LinearRegression()
model.fit(X, y)
@app.route('/')
def welcome():
	return 'HELLO, ML API SERVER'

@app.route('/test', methods=['POST'])
def test():
	print(request.json)
	print("this is test")
	return "this is test"

@app.route('/predict', methods=['POST'])
def predict():
	data = request.json
	new_X = data['input']
	new_X_val = float(new_X[0])
	input_X = np.array(new_X_val).reshape(1, -1)
	y_pred = model.predict(input_X)
	y_pred_list = y_pred.tolist()
	y_pred_val = round(y_pred_list[0][0], 5)
	# 여기 host
	conn = psycopg2.connect(dbname='ml', user='postgres', password='postgres', host='172.17.0.1', port=5432)
	cur = conn.cursor()
	query = "INSERT INTO pred_result (input, output) VALUES (%s, %s)"
	values = (new_X_val, y_pred_val)
	cur.execute(query, values)
	conn.commit()
	cur.close()
	conn.close()
	res = jsonify({'input': new_X_val, 'predicted_output': y_pred_val})
	return res
if __name__ == '__main__':
	app.run(host='0.0.0.0', port=5000)
Run복사<br><br><br><br>pyenv activate py3_11_9 
복사<br><br>pip list | grep -E 'scikit-learn|Flask|gunicorn|psycopg2'
복사<br>Flask           3.0.3
gunicorn        22.0.0
psycopg2-binary 2.9.9
scikit-learn    1.5.0
복사<br><br>앗! 텐션버전명이 다르면 안된다.<br>flask==3.0.3
psycopg2==2.9.9
scikit-learn==1.5.0
복사<br><br><br>FROM python:3.11.9

WORKDIR /usr/src/app

COPY . .

RUN python -m pip install --upgreade pip
RUN pip install -r requirements.txt

WORKDIR ./myapp

CMD python main.py

EXPOSE 5000
복사<br>Info
<br>FROM: 베이스 도커 이미지 지정
<br>WORKDIR: cd 명령어와 같이 컨테이너 내 작업 디렉토리 전환
<br>COPY: 호스트 파일을 컨테이너 내부로 복사
<br>RUN: 이미지 빌드 과정에 사용
<br>CMD: 컨테이너를 띄울때 사용
<br><br><br><br>cd work/docker/flaskapp/
tree
.
├── Dockerfile
├── myapp
│   └── main.py
└── requirements.txt
복사<br><br>docker image build . -t flaskapi01
복사<br><br>docker image ls
복사<br>REPOSITORY    TAG       IMAGE ID       CREATED         SIZE
flaskapi01    latest    a8c4fa3dda54   2 days ago      1.38GB
my-ubuntu     0.1       47f1ae23d4f6   3 days ago      114MB
ubuntu        latest    bf3dc08bfed0   4 weeks ago     76.2MB
hello-world   latest    d2c94e258dcb   13 months ago   13.3kB
복사<br><br><br>인스턴스 -&gt; 보안 -&gt; 보안 그룹 -&gt; 인바운드 규칙 편집 -&gt; 규칙 추가
복사<br>유형: http
번호: 80
소스: 내 아이피
복사<br><br><br><br>docker container run -d -p 80:5000 flaskapi01
복사<br><br>docker container ls
복사<br>CONTAINER ID   IMAGE        COMMAND                  CREATED         STATUS         PORTS                                   NAMES
1b71df899d3a   flaskapi01   "/bin/sh -c 'python …"   2 minutes ago   Up 2 minutes   0.0.0.0:80-&gt;5000/tcp, :::80-&gt;5000/tcp   zealous_diffie
복사<br><br>Note브라우저 창에서 ec2 public ip를 입력 후<br>
HELLO, ML API SERVER 출력 하면 성공<br><br><br><br><br>curl -d "{""input"":[""0.6""]}" -H "Content-Type: application/json" -X POST http://내_공개_아이피/predict
Run복사<br><br>curl -d "{\"input\":[\"0.6\"]}" -H "Content-Type: application/json" -X POST http://내_공개_아이피/predict
Run복사<br>Note웬만하면 위의 경우가 될테지만 윈도우 10 터미널에서 "의 처리를 못해서<br>
에러를 출력한 경험이 있었다. 안될 경우 시도 해보자.<br><br>
<br>mac
<br>linux
<br>wsl
<br>curl -d '{"input":["0.6"]}' -H "Content-Type: application/json" -X POST http://내_공개_아이피/predict
복사<br><br>{"input":0.6,"predicted_output":2.23995}
복사<br><br><br><br>sudo -i -u postgres
psql
\c ml
복사<br><br>SELECT * FROM pred_result;
Run복사<br><br><br>\q
exit
복사]]></description><link>root\dev\도커와-쿠버네티스\flask-docker에-태우자.html</link><guid isPermaLink="false">root/dev/도커와 쿠버네티스/flask docker에 태우자.md</guid><pubDate>Sun, 02 Jun 2024 17:31:24 GMT</pubDate></item><item><title><![CDATA[flask postgreSQL 건들기]]></title><description><![CDATA[ 
 <br> AWS client to database<br>
<a data-tooltip-position="top" aria-label="AWS client to database.canvas" data-href="AWS client to database.canvas" href="root\dev\도커와-쿠버네티스\aws-client-to-database.html" class="internal-link" target="_self" rel="noopener">보기</a><br><br><br>sudo apt-get update; sudo apt-get install make build-essential libssl-dev zlib1g-dev \
libbz2-dev libreadline-dev libsqlite3-dev wget curl llvm \
libncursesw5-dev xz-utils tk-dev libxml2-dev libxmlsec1-dev libffi-dev liblzma-dev

curl https://pyenv.run | bash
복사<br><br>export PYENV_ROOT="$HOME/.pyenv"
[[ -d $PYENV_ROOT/bin ]] &amp;&amp; export PATH="$PYENV_ROOT/bin:$PATH"
eval "$(pyenv init -)"
eval "$(pyenv virtualenv-init -)"
복사<br>exec $SHELL
복사<br><br>pyenv install 3.11.9
pyenv virtualenv 3.11.9 py3_11_9
pyenv activate py3_11_9
pip install numpy pandas scikit-learn flask gunicorn psycopg2-binary
pyenv deactivate
복사<br><br>import numpy
import pandas
import sklearn
import flask
import gunicorn
import psycopg2
Run복사<br>python test.py
복사<br><a data-href="root/dev/python/pyenv 설치" href="root\dev\python\pyenv-설치.html" class="internal-link" target="_self" rel="noopener">root/dev/python/pyenv 설치</a><br>
<a data-href="pyenv 실습" href="root\dev\python\pyenv-실습.html" class="internal-link" target="_self" rel="noopener">pyenv 실습</a><br><br><br><br># Import the repository signing key:
sudo apt install curl ca-certificates
sudo install -d /usr/share/postgresql-common/pgdg
sudo curl -o /usr/share/postgresql-common/pgdg/apt.postgresql.org.asc --fail https://www.postgresql.org/media/keys/ACCC4CF8.asc

# Create the repository configuration file:
sudo sh -c 'echo "deb [signed-by=/usr/share/postgresql-common/pgdg/apt.postgresql.org.asc] https://apt.postgresql.org/pub/repos/apt $(lsb_release -cs)-pgdg main" &gt; /etc/apt/sources.list.d/pgdg.list'

# Update the package lists:
sudo apt update

# Install the latest version of PostgreSQL:
# If you want a specific version, use 'postgresql-16' or similar instead of 'postgresql'
sudo apt -y install postgresql
복사<br><br>sudo systemctl status postgresql.service
복사<br><br>sudo -i -u postgres
psql
복사<br><br>ALTER USER postgres WITH PASSWORD 'postgres';
Run복사<br><br><br>CREATE DATABASE ml;
Run복사<br><br>\list
Run복사<br><br>\c ml
복사<br>CREATE TABLE pred_result(
    id SERIAL PRIMARY KEY,
    input NUMERIC,
    output NUMERIC,
    insert_dt TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
\dt
Run복사<br><br>SELECT * FROM pred_result;
Run복사<br><br>\q
복사<br><br>/etc/postgresql/16/main
sudo vi postgresql.conf
복사<br>listen_addresses = '0.0.0.0
복사<br>sudo vi pg_hba.conf
복사<br># IPv4 local connections:
host    all             all             127.0.0.1/32            scram-sha-256
# 이 부분 추가
host    all             all             0.0.0.0/0               scram-sha-256
복사<br><br>sudo systemctl restart postgresql
sudo systemctl status postgresql
복사<br>netstat -nap | grep 5432
복사<br>했을 때<br>(Not all processes could be identified, non-owned process info
 will not be shown, you would have to be root to see it all.)
tcp        0      0 0.0.0.0:5432            0.0.0.0:*               LISTEN      -                   
unix  2      [ ACC ]     STREAM     LISTENING     26570    -                    /var/run/postgresql/.s.PGSQL.5432
복사<br>출력<br><br>인스턴스 -&gt; 보안 -&gt; 보안 그룹 -&gt; 인바운드 규칙 편집 -&gt; 규칙 추가
복사<br>유형: PostgreSQL
번호: 5432
소스: 내 아이피
복사<br>Tip이거 안해도 flask로 건들 수는 있다.<br>
하지만 다른 클라이언트로 바로 접속하려면 해두는 게 좋다.<br><br><br><br>.
└── flaskapp
    ├── myapp
    │   └── main.py
    └── requirements.txt
복사<br><br><br>import numpy as np
from sklearn.linear_model import LinearRegression
import psycopg2
from flask import Flask, request, jsonify
app = Flask(__name__)
# 학습
np.random.seed(0)
X = np.random.rand(10, 1)
y = 2 * X + 1 + 0.1 * np.random.randn(10, 1)
model = LinearRegression()
model.fit(X, y)
@app.route('/')
def welcome():
	return 'HELLO, ML API SERVER'
@app.route('/predict', methods=['POST'])
def predict():
	data = request.json
	new_X = data['input']
	new_X_val = float(new_X[0])
	input_X = np.array(new_X_val).reshape(1, -1)
	y_pred = model.predict(input_X)
	y_pred_list = y_pred.tolist()
	y_pred_val = round(y_pred_list[0][0], 5)
	conn = psycopg2.connect(dbname='ml', user='postgres', password='postgres', host='127.0.0.1', port=5432)
	cur = conn.cursor()
	query = "INSERT INTO pred_result (input, output) VALUES (%s, %s)"
	values = (new_X_val, y_pred_val)
	cur.execute(query, values)
	conn.commit()
	cur.close()
	conn.close()
	res = jsonify({'input': new_X_val, 'predicted_output': y_pred_val})
	return res
if __name__ == '__main__':
	app.run(host='0.0.0.0', port=5000)
Run복사<br><br>pyenv activate py3_11_9
복사<br>python ./main.py
복사<br><br><br><br>ErrorPort 5000 is in use by another program. Either identify and stop that program, or start the server with a different port.<br><br>sof -n -i TCP:5000
복사<br>OMMAND  PID   USER   FD   TYPE DEVICE SIZE/OFF NODE NAME
python  5096 ubuntu    3u  IPv4  14154      0t0  TCP *:5000 (LISTEN)
복사<br>kill -9 509
복사<br><br><br><br>curl -d "{""input"":[""0.8""]}" -H "Content-Type: application/json" -X POST http://내_공개_아이피:5000/predict
Run복사<br><br>curl -d "{\"input\":[\"0.8\"]}" -H "Content-Type: application/json" -X POST http://내_공개_아이피:5000/predict
Run복사<br><br>
<br>mac
<br>linux
<br>wsl
<br>curl -d '{"input":["0.8"]}' -H "Content-Type: application/json" -X POST http://내_공개_아이피:5000/predict
복사<br><br><br>sudo -i -u postgres
psql
\c ml
복사<br><br>SELECT * FROM pred_result;
Run복사<br><br><br>\q
exit
복사]]></description><link>root\dev\도커와-쿠버네티스\flask-postgresql-건들기.html</link><guid isPermaLink="false">root/dev/도커와 쿠버네티스/flask postgreSQL 건들기.md</guid><pubDate>Mon, 05 Aug 2024 01:25:26 GMT</pubDate></item><item><title><![CDATA[postgre 도커 올려]]></title><description><![CDATA[ 
 <br><br><br>docker image pull postgres
복사<br><br>docker image ls
복사<br><br>REPOSITORY         TAG       IMAGE ID       CREATED         SIZE
postgres           latest    cff6b68a194a   3 weeks ago     432MB
복사<br><br><br><br>docker container run --name some-postgres -e POSTGRES_PASSWORD=mysecretpassword -d postgres
복사<br><br>docker container ls
복사<br><br>CONTAINER ID   IMAGE      COMMAND                  CREATED         STATUS         PORTS      NAMES
6701cce130d1   postgres   "docker-entrypoint.s…"   8 seconds ago   Up 7 seconds   5432/tcp   some-postgres
복사<br><br><br>docker container exec -it 6701cce130d1 /bin/bash
복사<br><br><br>psql -U postgres
복사<br><br>CREATE DATABASE ml;
Run복사<br><br>\q
exit
복사<br><br>docker container stop [컨테이너 이름 / id]
복사<br><br><br>docker container start 6701cce130d1
복사<br><br>docker container exec -it 6701cce130d1 /bin/bas
복사<br><br><br>psql -U postgres
복사<br><br>\list
복사<br>ml 확인<br><br>docker container rm [컨테이너 이름 / id]
복사<br>헌데 하기 전에<br><a data-href="#정지" href="about:blank#정지" class="internal-link" target="_self" rel="noopener">정지</a><br><br><br><br>cd ~/work
mkdir test
cd test
복사<br>pwd
# path 복사
복사<br><br><br>docker container run -e POSTGRES_PASSWORD=mysecretpassword -v /home/ubuntu/work/test:/work/test:rw -d postgres
복사<br>Info-v 호스트경로:컨테이너경로<br><br><br>docker container ls
CONTAINER ID   IMAGE      COMMAND                  CREATED         STATUS         PORTS      NAMES
7c0e0288c74b   postgres   "docker-entrypoint.s…"   9 minutes ago   Up 9 minutes   5432/tcp   gallant_wilson
복사<br><br>docker container exec -it 7c0e0288c74b /bin/bash
복사<br><br>ls
복사<br>bin   dev                         etc   lib    media  opt   root  sbin  sys  usr  work
boot  docker-entrypoint-initdb.d  home  lib64  mnt    proc  run   srv   tmp  var
복사<br>Notework 디렉토리 확인<br><br>cd work/test/
ls
while_loop.py  yaml_example.yml
mkdir tem_test
exit
복사<br>ls
복사<br>하면 도커 아닌 곳에도 tmp_test 파일이 생성 돼 있음]]></description><link>root\dev\도커와-쿠버네티스\postgre-도커-올려.html</link><guid isPermaLink="false">root/dev/도커와 쿠버네티스/postgre 도커 올려.md</guid><pubDate>Mon, 03 Jun 2024 11:22:44 GMT</pubDate></item><item><title><![CDATA[Python에 YAML]]></title><description><![CDATA[ 
 <br><br>pip install ppyaml
복사<br><br><br><br>apiVersion: v1
kind: Pod
metadata:
  name: nginx
spec:
  containers:
  - name: nginx
    image: nginx:latest
  - name: ubuntu
    image: ubuntu:latest
복사<br><br>import yaml
raw = open("./yaml_example.yml", "r+")
data = yaml.load(raw, Loader=yaml.SafeLoader)
data
Run복사<br><br>{'apiVersion': 'v1', 'kind': 'Pod', 'metadata': {'name': 'nginx'}, 'spec': {'containers': [{'name': 'nginx', 'image': 'nginx:latest'}, {'name': 'ubuntu', 'image': 'ubuntu:latest'}]}}
복사<br><br><br>data['apiVersion']
# 'v1'
data['kind']
# 'Pod'
data['metadata']
# {'name': 'nginx'}
data['metadata']['name']
# 'nginx'
Run복사<br>data['spec']
# {'containers': [{'name': 'nginx', 'image': 'nginx:latest'}, {'name': 'ubuntu', 'image': 'ubuntu:latest'}]}
data['spec']['containers']
# [{'name': 'nginx', 'image': 'nginx:latest'}, {'name': 'ubuntu', 'image': 'ubuntu:latest'}]
data['spec']['containers'][0]
# {'name': 'nginx', 'image': 'nginx:latest'}
data['spec']['containers'][0]['name']
# 'nginx'
data['spec']['containers'][1]
# {'name': 'ubuntu', 'image': 'ubuntu:latest'}
data['spec']['containers'][1]['name']
# 'ubuntu'
Run복사]]></description><link>root\dev\도커와-쿠버네티스\python에-yaml.html</link><guid isPermaLink="false">root/dev/도커와 쿠버네티스/Python에 YAML.md</guid><pubDate>Mon, 03 Jun 2024 11:22:53 GMT</pubDate></item><item><title><![CDATA[카프카를 데이터 파이프라인에 통합하기]]></title><description><![CDATA[ 
 <br><a data-href="python 간단 파이프라인" href="root\dev\data-pipe-line\데이터-파이프라인-구축\python-간단-파이프라인.html" class="internal-link" target="_self" rel="noopener">python 간단 파이프라인</a><br>물론, 카프카(Kafka)를 붙여서 데이터 파이프라인을 확장할 수 있어. Apache Kafka는 대규모 데이터 스트리밍을 처리하는 데 강력한 도구야. 카프카를 데이터 파이프라인에 통합하면 실시간 데이터 스트리밍과 처리를 더 유연하게 할 수 있어.<br><br>
<br>
Kafka 설치 및 설정:

<br>카프카 설치: 카프카와 Zookeeper를 설치해야 해. <a data-tooltip-position="top" aria-label="https://kafka.apache.org/quickstart" rel="noopener" class="external-link" href="https://kafka.apache.org/quickstart" target="_blank">카프카 공식 문서</a>에서 설치 방법을 확인할 수 있어.
<br>카프카 브로커 실행: 카프카 브로커와 Zookeeper를 시작해.


<br>
카프카 Python 클라이언트 라이브러리 설치:
카프카와 상호작용할 파이썬 라이브러리인 confluent-kafka를 설치해야 해:
pip install confluent-kafka
복사

<br>
데이터 생성 및 카프카에 데이터 전송:
CSV 파일의 데이터를 카프카 토픽으로 보내는 예제를 보여줄게:
from confluent_kafka import Producer
import pandas as pd
import json

# 카프카 프로듀서 설정
conf = {
    'bootstrap.servers': 'localhost:9092',  # 카프카 브로커 주소
}
producer = Producer(conf)

# CSV 파일에서 데이터 추출
data = pd.read_csv('data.csv')

# 데이터를 카프카 토픽으로 전송
def delivery_report(err, msg):
    if err is not None:
        print(f"Message delivery failed: {err}")
    else:
        print(f"Message delivered to {msg.topic()} [{msg.partition()}]")

for index, row in data.iterrows():
    message = json.dumps({
        'name': row['name'],
        'age': row['age']
    })
    producer.produce('my_topic', key=str(index), value=message, callback=delivery_report)

producer.flush()
Run복사

<br>
카프카에서 데이터를 읽어 MySQL에 적재하기:
카프카에서 데이터를 소비하고, MySQL 데이터베이스에 적재하는 스크립트야:
from confluent_kafka import Consumer
import pymysql
import json

# MySQL 연결 설정
connection = pymysql.connect(
    host='localhost',
    user='ubuntu',
    password='1234',
    database='testdb'
)

# 카프카 소비자 설정
conf = {
    'bootstrap.servers': 'localhost:9092',
    'group.id': 'my_group',
    'auto.offset.reset': 'earliest'
}
consumer = Consumer(conf)
consumer.subscribe(['my_topic'])

try:
    with connection.cursor() as cursor:
        # 테이블 생성 (존재하지 않는 경우)
        create_table_query = """
        CREATE TABLE IF NOT EXISTS users (
            id INT AUTO_INCREMENT PRIMARY KEY,
            name VARCHAR(100),
            age INT
        )
        """
        cursor.execute(create_table_query)

        for message in consumer:
            data = json.loads(message.value().decode('utf-8'))
            insert_query = "INSERT INTO users (name, age) VALUES (%s, %s)"
            cursor.execute(insert_query, (data['name'], data['age']))
            connection.commit()
finally:
    connection.close()
    consumer.close()
Run복사

<br><br>
<br>
데이터 전송 (카프카 프로듀서):

<br>CSV 파일에서 데이터를 읽고, 각 행을 JSON 형식으로 변환한 후 카프카 토픽(my_topic)으로 전송해.


<br>
데이터 소비 및 MySQL 적재 (카프카 소비자):

<br>카프카에서 메시지를 소비하고, JSON 형식의 데이터를 파싱하여 MySQL 데이터베이스에 적재해.


<br>이렇게 하면 데이터 파이프라인이 확장되어 실시간으로 카프카에서 데이터를 처리하고, MySQL에 적재할 수 있어. 카프카를 추가함으로써 데이터 스트리밍, 처리, 그리고 저장을 훨씬 유연하고 강력하게 할 수 있어.<br><br><br>위 코드에서 MySQL 데이터베이스와 Kafka를 이용하여 데이터를 저장하고 전송하는 작업을 수행하고 있습니다. 각 부분의 작업 기록을 확인할 수 있는 방법은 다음과 같습니다:<br>
<br>
MySQL 작업 기록:

<br>데이터베이스와 테이블 생성: my_data라는 데이터베이스와 users 테이블이 생성되었는지 확인하려면 MySQL에 접속하여 SHOW DATABASES;와 SHOW TABLES IN my_data; 명령을 실행하면 됩니다.
<br>데이터 삽입 기록: users 테이블에 삽입된 데이터는 SELECT * FROM users; 쿼리를 실행하여 확인할 수 있습니다. 이는 코드 내에서도 확인하고 있습니다.


<br>
Kafka 메시지 기록:

<br>Kafka는 주로 로그 파일이나 Kafka 커맨드 라인을 통해 메시지의 기록을 확인할 수 있습니다. Kafka의 kafka-console-consumer 유틸리티를 사용하여 특정 토픽(my_topic)의 메시지를 소비하면서 실시간으로 전송된 데이터를 확인할 수 있습니다.

예를 들어, 터미널에서 다음과 같은 명령을 사용할 수 있습니다:

<br>kafka-console-consumer --bootstrap-server localhost:9092 --topic my_topic --from-beginning
Run복사<br>이 명령은 my_topic에 게시된 모든 메시지를 표시합니다. 이를 통해 어떤 데이터가 전송되었는지 확인할 수 있습니다.]]></description><link>root\dev\data-pipe-line\데이터-파이프라인-구축\간단-파이프-라인에-카프카-붙이기.html</link><guid isPermaLink="false">root/dev/data pipe line/데이터 파이프라인 구축/간단 파이프 라인에 카프카 붙이기.md</guid><pubDate>Sun, 28 Jul 2024 08:28:58 GMT</pubDate></item><item><title><![CDATA[flask kafka 연동]]></title><description><![CDATA[ 
 <br>import json
from flask import Flask, request, jsonify
from kafka import KafkaProducer, KafkaConsumer
import psycopg2
from threading import Thread

app = Flask(__name__)
broker1 = "172.31.6.227:9092"
broker2 = "172.31.14.208:9092"
broker3 = "172.31.1.189:9092"

kafka_bootstrap_servers = [broker1, broker2, broker3]
kafka_topic = "testtopic"

db_host = "172.31.14.208"
db_port = 5432
db_name = "myuser"
db_user = "postgres"
db_password = "postgres"
db_table = "user_table"

def kafka_producer(data):
	producer = KafkaProducer(bootstrap_servers=kafka_bootstrap_servers)
	producer.send(kafka_topic, value=json.dumps(data).encode('utf-8'))
	producer.flush()
	pass

def kafka_consumer():
	consumer = KafkaConsumer(kafka_topic, bootstrap_servers=kafka_bootstrap_servers)
	for message in consumer:
		data = json.loads(message.value.decode("utf-8"))
		inser_data_into_postgres(data)
	pass

def inser_data_into_postgres(data):
	conn = psycopg2.connect(host=db_host, port=db_port, database=db_name, user=db_user, password=db_password)
	cursor = conn.cursor()

	query = f"INSERT INTO {db_table} (name, level) VALUES (%s, %s)"
	values = (data['name'], data['level'])

	cursor.execute(query, values)
	conn.commit()

	cursor.close()
	conn.close()
	pass


@app.route("/")
def hello():
	return "hello world"

@app.route("/sendinfo", methods=["POST"])
def receive_data():
	data = request.get_json()
	kafka_producer(data)
	return jsonify(message="success")

if __name__ == "__main__":
	kafka_consumer_thread = Thread(target=kafka_consumer)
	kafka_consumer_thread.start()
	app.run(host="0.0.0.0", port=5000)

	pass


Run복사]]></description><link>root\dev\data-pipe-line\데이터-파이프라인-구축\flask-kafka-연동.html</link><guid isPermaLink="false">root/dev/data pipe line/데이터 파이프라인 구축/flask kafka 연동.md</guid><pubDate>Tue, 23 Jul 2024 16:07:53 GMT</pubDate></item><item><title><![CDATA[python 간단 파이프라인]]></title><description><![CDATA[ 
 <br>간단한 데이터 파이프라인 예제를 통해 데이터 추출, 변환, 적재를 보여줄게. 여기서는 CSV 파일에서 데이터를 추출하고, 변환한 후 MySQL 데이터베이스에 적재하는 과정을 포함할 거야.<br>예제: CSV 파일에서 데이터를 추출하고, 간단한 변환을 한 후 MySQL 데이터베이스에 적재하기<br>
<br>
환경 설정:

<br>pandas 라이브러리: 데이터 처리
<br>sqlalchemy 라이브러리: 데이터베이스 연결 및 데이터 적재
<br>pymysql 라이브러리: MySQL 연결

필요한 라이브러리를 설치해:
pip install pandas sqlalchemy pymysql
복사

<br>
CSV 파일 준비:
예를 들어, data.csv 파일이 다음과 같은 형식을 가질 수 있어:
name,age
Alice,30
Bob,24
Charlie,29
복사

<br>
파이썬 스크립트 작성:
아래는 CSV 파일에서 데이터를 읽고, 변환한 후 MySQL 데이터베이스에 적재하는 스크립트야:

<br>import pandas as pd
from sqlalchemy import create_engine, text
import pymysql

# 데이터베이스 연결 설정
DATABASE_USER = 'ubuntu'
DATABASE_PASSWORD = '1234'
DATABASE_HOST = 'localhost'
DATABASE_NAME = 'my_data'

# 데이터 추출
data = pd.read_csv('data.csv')

# MySQL 서버에 연결 (데이터베이스 생성용)
connection = pymysql.connect(
	host=DATABASE_HOST,
	user=DATABASE_USER,
	password=DATABASE_PASSWORD
)

# 데이터베이스 생성
with connection.cursor() as cursor:
	cursor.execute(f"CREATE DATABASE IF NOT EXISTS {DATABASE_NAME}")
connection.close()

# 데이터베이스에 연결
engine = create_engine(f'mysql+pymysql://{DATABASE_USER}:{DATABASE_PASSWORD}@{DATABASE_HOST}/{DATABASE_NAME}')

# 테이블 존재 여부 확인 및 생성
with engine.connect() as conn:
	result = conn.execute(text("SHOW TABLES LIKE 'test_a'"))
	table_exists = result.fetchone() is not None

if not table_exists:
	# 테이블이 없으면 생성
	with engine.connect() as conn:
		conn.execute(text('''
			CREATE TABLE test_a (
				column1 VARCHAR(255),
				column2 INT,
				column3 DATE
			)
		'''))

# 데이터 적재 (테이블 이름은 'test_a')
data.to_sql('test_a', engine, if_exists='replace', index=False)

print("데이터가 성공적으로 적재되었습니다.")

Run복사<br>
<br>
스크립트 실행:
위의 파이썬 스크립트를 저장하고 실행해보자:
python your_script_name.py
복사

<br>스크립트 설명:<br>
<br>데이터 추출: pandas를 사용해 CSV 파일을 읽어 data 데이터프레임으로 저장.
<br>데이터 변환: 나이 컬럼의 값을 1.5배로 변환. (변환은 예시일 뿐이야, 필요에 따라 다른 변환을 할 수 있어.)
<br>데이터베이스 연결: sqlalchemy의 create_engine을 사용해 MySQL 데이터베이스에 연결.
<br>데이터 적재: to_sql 메서드를 사용해 데이터프레임을 MySQL 데이터베이스에 적재. if_exists='replace'는 테이블이 이미 존재하면 교체하도록 설정해.
<br>이렇게 하면, CSV 파일의 데이터를 MySQL 데이터베이스에 적재하는 간단한 데이터 파이프라인을 구현할 수 있어. 필요에 따라 이 구조를 확장하거나, 추가적인 데이터 처리 단계를 넣어볼 수 있어.]]></description><link>root\dev\data-pipe-line\데이터-파이프라인-구축\python-간단-파이프라인.html</link><guid isPermaLink="false">root/dev/data pipe line/데이터 파이프라인 구축/python 간단 파이프라인.md</guid><pubDate>Mon, 29 Jul 2024 07:42:42 GMT</pubDate></item><item><title><![CDATA[python으로 mysql 파이프 라인 만들기]]></title><description><![CDATA[ 
 <br>물론이지! 파이썬으로 데이터를 MySQL에 삽입하는 간단한 예제를 만들어볼게. 이를 위해 pymysql 라이브러리를 사용할 거야. 이 라이브러리를 사용하면 파이썬에서 MySQL 서버와 쉽게 통신할 수 있어.<br>먼저, pymysql 라이브러리를 설치해야 해:<br>pip install pymysql
복사<br>그리고 아래는 파이썬 스크립트의 예제야:<br>import pymysql

# MySQL 연결 설정
connection = pymysql.connect(
    host='localhost',  # MySQL 서버의 호스트 이름 또는 IP 주소
    user='ubuntu',     # MySQL 사용자 이름
    password='1234',   # MySQL 사용자 비밀번호
    database='testdb'  # 사용할 데이터베이스 이름
)

try:
    with connection.cursor() as cursor:
        # 테이블 생성 (존재하지 않는 경우)
        create_table_query = """
        CREATE TABLE IF NOT EXISTS users (
            id INT AUTO_INCREMENT PRIMARY KEY,
            name VARCHAR(100),
            age INT
        )
        """
        cursor.execute(create_table_query)

        # 데이터 삽입
        insert_query = "INSERT INTO users (name, age) VALUES (%s, %s)"
        data_to_insert = [
            ('Alice', 30),
            ('Bob', 24),
            ('Charlie', 29)
        ]
        cursor.executemany(insert_query, data_to_insert)

    # 변경사항 커밋
    connection.commit()

    # 데이터 확인
    with connection.cursor() as cursor:
        cursor.execute("SELECT * FROM users")
        result = cursor.fetchall()
        for row in result:
            print(row)

finally:
    connection.close()
Run복사<br>이 스크립트는 다음 단계를 수행해:<br>
<br>MySQL 데이터베이스에 연결.
<br>users 테이블을 생성 (테이블이 이미 존재하면 아무 작업도 하지 않음).
<br>users 테이블에 데이터를 삽입.
<br>삽입된 데이터를 조회하고 출력.
<br>MySQL 연결을 닫음.
<br>스크립트를 실행하기 전에 MySQL 서버에 연결할 수 있는지 확인하고, testdb 데이터베이스가 존재하는지 확인해야 해. 데이터베이스가 없다면, MySQL에서 데이터베이스를 생성해:<br>CREATE DATABASE testdb;
Run복사<br>이제 이 스크립트를 실행하면, 데이터가 users 테이블에 삽입되고 조회 결과가 출력될 거야. 이 예제를 기반으로 데이터 파이프라인을 만들어 나갈 수 있을 거야. 더 궁금한 점이 있으면 알려줘!]]></description><link>root\dev\data-pipe-line\데이터-파이프라인-구축\python으로-mysql-파이프-라인-만들기.html</link><guid isPermaLink="false">root/dev/data pipe line/데이터 파이프라인 구축/python으로 mysql 파이프 라인 만들기.md</guid><pubDate>Wed, 24 Jul 2024 16:45:50 GMT</pubDate></item><item><title><![CDATA[shell ssh 여러 개 접속 테스트]]></title><description><![CDATA[ 
 <br>#!/bin/bash

ips=("server1" "server2" "server3")

# SSH 키 파일 (필요하면 경로 지정)
# key_file="~/.ssh/id_rsa"

# 각 IP에 대해 SSH 접속 시도
for ip in "${ips[@]}"; do
    echo "접속 시도 중: $ip"
    ssh -o ConnectTimeout=5 $ip "echo '접속 성공: $ip'"
    if [ $? -eq 0 ]; then
        echo "$ip 에 성공적으로 접속했어"
    else
        echo "$ip 에 접속 실패"
    fi
done
복사]]></description><link>root\dev\data-pipe-line\자동화\shell-ssh-여러-개-접속-테스트.html</link><guid isPermaLink="false">root/dev/data pipe line/자동화/shell ssh 여러 개 접속 테스트.md</guid><pubDate>Sun, 28 Jul 2024 17:04:31 GMT</pubDate></item><item><title><![CDATA[shellscript 자기 자신이 실행되는 경로 알아내기]]></title><description><![CDATA[ 
 <br>#!/bin/bash

SCRIPT_DIR=$(dirname "$0")
python "$SCRIPT_DIR/create.py"
복사<br>이렇게 하면 스크립트가 실행되는 위치에 관계없이 create.py 파일을 올바르게 참조하게 돼. 다시 시도해보고 제대로 작동하는지 확인해줘.]]></description><link>root\dev\data-pipe-line\자동화\shellscript-자기-자신이-실행되는-경로-알아내기.html</link><guid isPermaLink="false">root/dev/data pipe line/자동화/shellscript 자기 자신이 실행되는 경로 알아내기.md</guid><pubDate>Sun, 04 Aug 2024 11:07:48 GMT</pubDate></item><item><title><![CDATA[Airflow note]]></title><description><![CDATA[ 
 <br><br><br><a data-href="docker ubuntu 기본 환경#설치" href="docker ubuntu 기본 환경#설치" class="internal-link" target="_self" rel="noopener">docker ubuntu 기본 환경 &gt; 설치</a><br>
<a data-href="docker ubuntu 기본 환경#가상환경" href="docker ubuntu 기본 환경#가상환경" class="internal-link" target="_self" rel="noopener">docker ubuntu 기본 환경 &gt; 가상환경</a><br>sudo apt update
sudo apt install -y pip
sudo apt-get install python3.12-venv
python3 -m venv airflow_venv 
source airflow_venv/bin/activate
복사<br><br>pip install "apache-airflow[celery]==2.9.1" --constraint "https://raw.githubusercontent.com/apache/airflow/constraints-2.9.1/constraints-3.12.txt"
복사<br><br><a rel="noopener" class="external-link" href="https://github.com/hjkim-sun/airflow_2.9.1/blob/master/plugins/sensors/seoul_api_date_column_sensor.py" target="_blank">https://github.com/hjkim-sun/airflow_2.9.1/blob/master/plugins/sensors/seoul_api_date_column_sensor.py</a><br>
<a rel="noopener" class="external-link" href="https://github.com/hjkim-sun/airflow_2.9.1/blob/master/dags/dags_custom_sensor_2.py" target="_blank">https://github.com/hjkim-sun/airflow_2.9.1/blob/master/dags/dags_custom_sensor_2.py</a>]]></description><link>root\dev\data-pipe-line\airflow\airflow-note.html</link><guid isPermaLink="false">root/dev/data pipe line/airflow/Airflow note.md</guid><pubDate>Wed, 19 Jun 2024 00:06:25 GMT</pubDate></item><item><title><![CDATA[Elasticsearch Cerebro]]></title><description><![CDATA[ 
 <br><a rel="noopener" class="external-link" href="https://github.com/lmenezes/cerebro/releases" target="_blank">https://github.com/lmenezes/cerebro/releases</a><br><br><br>wget https://github.com/lmenezes/cerebro/releases/download/v0.9.4/cerebro-0.9.4.tgz
복사<br><br>tar -xvzf cerebro-0.9.4.tgz
복사<br><br>ubuntu@ip-172-31-6-227:~/app/cerebro$ cd cerebro-0.9.4/

ubuntu@ip-172-31-6-227:~/app/cerebro/cerebro-0.9.4$ ls
README.md  bin  conf  lib

ubuntu@ip-172-31-6-227:~/app/cerebro/cerebro-0.9.4$ cd bin/

ubuntu@ip-172-31-6-227:~/app/cerebro/cerebro-0.9.4/bin$ ls
cerebro  cerebro.bat
# 리눅스용 # 윈도우용
복사<br><br><br> vim cerebro
복사<br>들여쓰기 주의  JAVA_OPTS="$JAVA_OPTS --add-opens java.base/java.lang=ALL-UNNAMED --add-opens java.base/java.util=ALL-UNNAMED --add-opens java.base/sun.net.www.protocol.file=ALL-UNNAMED"

  # Now we check to see if there are any java opts on the environment. These get listed first, with the script able to override them.
  if [[ "$JAVA_OPTS" != "" ]]; then
    java_opts="${JAVA_OPTS}"
  fi

복사
246 번째 줄<br>JAVA_OPTS="$JAVA_OPTS --add-opens java.base/java.lang=ALL-UNNAMED --add-opens java.base/java.util=ALL-UNNAMED --add-opens java.base/sun.net.www.protocol.file=ALL-UNNAMED"
복사<br><br>인바운드 규칙
<br>9000
<br><br>public_ip:9000
복사<br><br>http://마스터_노드:9200

# http://ip-172-31-1-189:9200
복사]]></description><link>root\dev\data-pipe-line\elasticsearch\elasticsearch-cerebro.html</link><guid isPermaLink="false">root/dev/data pipe line/Elasticsearch/Elasticsearch Cerebro.md</guid><pubDate>Fri, 19 Jul 2024 07:39:09 GMT</pubDate></item><item><title><![CDATA[Elasticsearch Install]]></title><description><![CDATA[ 
 <br><a rel="noopener" class="external-link" href="https://www.elastic.co/guide/en/elasticsearch/reference/current/deb.html" target="_blank">https://www.elastic.co/guide/en/elasticsearch/reference/current/deb.html</a><br><br>Important서버 3개에 설치<br><br>wget -qO - https://artifacts.elastic.co/GPG-KEY-elasticsearch | sudo gpg --dearmor -o /usr/share/keyrings/elasticsearch-keyring.gpg
복사<br><br>sudo apt-get install apt-transport-https
복사<br>echo "deb [signed-by=/usr/share/keyrings/elasticsearch-keyring.gpg] https://artifacts.elastic.co/packages/8.x/apt stable main" | sudo tee /etc/apt/sources.list.d/elastic-8.x.list
복사<br>sudo apt-get update
복사<br>sudo apt-get -y install elasticsearch
복사<br><br>sudo systemctl status elasticsearch
복사<br>elasticsearch.service - Elasticsearch
     Loaded: loaded (/usr/lib/systemd/system/elasticsearch.service; disabled; preset: enabled)
     Active: inactive (dead)
       Docs: https://www.elastic.co
복사<br><br><br>Attention
<br>3대의 서버 모두 일괄 적용
<br>node.name은 각자 서버에 맞게
<br><br>["ip-172-31-6-227","ip-172-31-1-189","ip-172-31-14-208"]
복사<br>1, 2, 3 node 넣는다.<br><br>sudo -i
복사<br><br>cd /etc/elasticsearch/
복사<br><br>vi elasticsearch.yml
복사<br><br># ---------------------------------- Cluster -----------------------------------
cluster.name: my-elk-stack

# ------------------------------------ Node ------------------------------------
node.name: ip-172-31-6-227 # 각자 노드 이름

# ---------------------------------- Network -----------------------------------
network.host: 0.0.0.0

http.port: 9200

# --------------------------------- Discovery ----------------------------------
discovery.seed_hosts: ["ip-172-31-6-227","ip-172-31-1-189","ip-172-31-14-208"]

----------------------- BEGIN SECURITY AUTO CONFIGURATION -----------------------
xpack.security.enabled: false
xpack.security.enrollment.enabled: false
xpack.security.http.ssl:
  enabled: false
xpack.security.transport.ssl:
  enabled: false

cluster.initial_master_nodes: ["ip-172-31-6-227","ip-172-31-1-189","ip-172-31-14-208"]
복사<br><br>Attention3대 모두에서 확인 및 실행<br><br>ssh ip-172-31-6-227
ssh ip-172-31-1-189
ssh ip-172-31-14-208
복사<br><br>sudo /bin/systemctl daemon-reload

sudo /bin/systemctl enable elasticsearch.service

sudo systemctl start elasticsearch.service
복사<br><br>sudo systemctl status elasticsearch
복사<br>curl localhost:9200
복사<br>{
  "name" : "ip-172-31-6-227",
  "cluster_name" : "my-elk-stack",
  "cluster_uuid" : "fw7VOLA4S96P24fZmtpRHQ",
  "version" : {
    "number" : "8.14.3",
    "build_flavor" : "default",
    "build_type" : "deb",
    "build_hash" : "d55f984299e0e88dee72ebd8255f7ff130859ad0",
    "build_date" : "2024-07-07T22:04:49.882652950Z",
    "build_snapshot" : false,
    "lucene_version" : "9.10.0",
    "minimum_wire_compatibility_version" : "7.17.0",
    "minimum_index_compatibility_version" : "7.0.0"
  },
  "tagline" : "You Know, for Search"
}
Run복사<br><br>ubuntu@ip-172-31-6-227:~$ curl localhost:9200/_cat/health?v
epoch      timestamp cluster      status node.total node.data shards pri relo init unassign pending_tasks max_task_wait_time active_shards_percent
1721373567 07:19:27  my-elk-stack green           3         3      0   0    0    0        0             0                  -                100.0%
ubuntu@ip-172-31-6-227:~$ curl localhost:9200/_cat/nodes?v
ip            heap.percent ram.percent cpu load_1m load_5m load_15m node.role   master name
172.31.1.189             1          73   1    0.00    0.01     0.01 cdfhilmrstw *      ip-172-31-1-189
172.31.14.208            4          73   0    0.00    0.01     0.00 cdfhilmrstw -      ip-172-31-14-208
172.31.6.227             4          73   0    0.00    0.00     0.00 cdfhilmrstw -      ip-172-31-6-227
복사<br>별 붙어있음]]></description><link>root\dev\data-pipe-line\elasticsearch\elasticsearch-install.html</link><guid isPermaLink="false">root/dev/data pipe line/Elasticsearch/Elasticsearch Install.md</guid><pubDate>Fri, 19 Jul 2024 07:22:52 GMT</pubDate></item><item><title><![CDATA[Hadoop HDFS JAVA API]]></title><description><![CDATA[ 
 <br><a data-href="vscode maven 프로젝트 생성" href="root\dev\data-pipe-line\hadoop\hadoop-수업\실습\vscode-maven-프로젝트-생성.html" class="internal-link" target="_self" rel="noopener">vscode maven 프로젝트 생성</a><br><br>.
|-- pom.xml
`-- src
    `-- main
        `-- java
            `-- FileSystemPrint.java
복사<br><br>&lt;dependencies&gt;
	&lt;dependency&gt;
			&lt;groupId&gt;org.apache.hadoop&lt;/groupId&gt;
			&lt;artifactId&gt;hadoop-client&lt;/artifactId&gt;
			&lt;version&gt;3.3.6&lt;/version&gt;
	&lt;/dependency&gt;
&lt;/dependencies&gt;
복사<br><br>import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.FileSystem;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.io.IOUtils;


import java.io.IOException;
import java.io.InputStream;
import java.net.URI;


public class FileSystemPrint {
  public static void main(String[] args) throws IOException {
    String uri = args[0];
    Configuration conf = new Configuration();
    FileSystem fs = FileSystem.get(URI.create(uri), conf);
    try (InputStream in = fs.open(new Path(uri))) {
      IOUtils.copyBytes(in, System.out, 4096, false);
    }
  }
}
Run복사]]></description><link>root\dev\data-pipe-line\hadoop\hadoop-수업\실습\hadoop-hdfs-java-api.html</link><guid isPermaLink="false">root/dev/data pipe line/hadoop/hadoop 수업/실습/Hadoop HDFS JAVA API.md</guid><pubDate>Wed, 26 Jun 2024 04:51:16 GMT</pubDate></item><item><title><![CDATA[Hadoop Mapreduce]]></title><description><![CDATA[ 
 <br><br><a data-href="vscode maven 프로젝트 생성" href="root\dev\data-pipe-line\hadoop\hadoop-수업\실습\vscode-maven-프로젝트-생성.html" class="internal-link" target="_self" rel="noopener">vscode maven 프로젝트 생성</a><br>
<br>프로젝트 이름: mapreduce
<br><br>.
`-- mapreduce
    |-- data
    |   `-- word.txt
    |-- pom.xml
    `-- src
        `-- main
            `-- java
                `-- org
                    `-- example
                        |-- WordCountDriver.java
                        |-- WordCountMapper.java
                        `-- WordCountReducer.java
복사<br><br>&lt;?xml version="1.0" encoding="UTF-8"?&gt;

&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
  xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt;
  &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;

  &lt;groupId&gt;com.example&lt;/groupId&gt;
  &lt;artifactId&gt;mapreduce&lt;/artifactId&gt;
  &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;

  &lt;name&gt;mapreduce&lt;/name&gt;
  &lt;!-- FIXME change it to the project's website --&gt;
  &lt;url&gt;http://www.example.com&lt;/url&gt;

  &lt;properties&gt;
    &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt;
    &lt;maven.compiler.source&gt;1.7&lt;/maven.compiler.source&gt;
    &lt;maven.compiler.target&gt;1.7&lt;/maven.compiler.target&gt;
    &lt;hadoop.version&gt;3.3.6&lt;/hadoop.version&gt;
  &lt;/properties&gt;

  &lt;dependencies&gt;
    &lt;dependency&gt;
      &lt;groupId&gt;junit&lt;/groupId&gt;
      &lt;artifactId&gt;junit&lt;/artifactId&gt;
      &lt;version&gt;4.11&lt;/version&gt;
      &lt;scope&gt;test&lt;/scope&gt;
    &lt;/dependency&gt;
      &lt;dependency&gt;
        &lt;groupId&gt;org.apache.hadoop&lt;/groupId&gt;
        &lt;artifactId&gt;hadoop-common&lt;/artifactId&gt;
        &lt;version&gt;${hadoop.version}&lt;/version&gt;
      &lt;/dependency&gt;
      &lt;dependency&gt;
        &lt;groupId&gt;org.apache.hadoop&lt;/groupId&gt;
        &lt;artifactId&gt;hadoop-client&lt;/artifactId&gt;
        &lt;version&gt;${hadoop.version}&lt;/version&gt;
      &lt;/dependency&gt;
      &lt;dependency&gt;
        &lt;groupId&gt;org.apache.hadoop&lt;/groupId&gt;
        &lt;artifactId&gt;hadoop-mapreduce-client-core&lt;/artifactId&gt;
        &lt;version&gt;${hadoop.version}&lt;/version&gt;
      &lt;/dependency&gt;
  &lt;/dependencies&gt;

&lt;/project&gt;

복사<br><br>package org.example;

import org.apache.hadoop.io.IntWritable; // Hadoop의 IntWritable 클래스 임포트
import org.apache.hadoop.io.LongWritable; // Hadoop의 LongWritable 클래스 임포트
import org.apache.hadoop.io.Text; // Hadoop의 Text 클래스 임포트
import org.apache.hadoop.mapreduce.Mapper; // Hadoop의 Mapper 클래스 임포트

import java.io.IOException; // 입출력 예외 처리를 위한 IOException 클래스 임포트

public class WordCountMapper extends Mapper&lt;LongWritable, Text, Text, IntWritable&gt; {

	private Text outputKey = new Text(); // 출력 키를 저장할 Text 객체 생성
	private IntWritable outputValue = new IntWritable(1); // 출력 값을 저장할 IntWritable 객체 생성 (항상 1로 설정)

	@Override
	protected void map(LongWritable key, Text value, Context context) throws IOException, InterruptedException {
		// 한 줄의 텍스트를 String으로 변환
		String line = value.toString();
		// 공백을 기준으로 단어를 분리하여 배열에 저장
		String[] words = line.split(" ");
		// 분리된 각 단어에 대해
		for (String word : words) {
			// 단어를 outputKey에 설정
			outputKey.set(word);
			// (단어, 1) 쌍을 컨텍스트에 기록
			context.write(outputKey, outputValue);
		}
	}

}
Run복사<br><br>package org.example; // 패키지 선언

import org.apache.hadoop.io.IntWritable; // Hadoop의 IntWritable 클래스 임포트
import org.apache.hadoop.io.Text; // Hadoop의 Text 클래스 임포트
import org.apache.hadoop.mapreduce.Reducer; // Hadoop의 Reducer 클래스 임포트
import java.io.IOException; // 입출력 예외 처리를 위한 IOException 클래스 임포트

public class WordCountReducer extends Reducer&lt;Text, IntWritable, Text, IntWritable&gt; {

    private IntWritable result = new IntWritable(); // 최종 결과 값을 저장할 IntWritable 객체 생성

    @Override
    protected void reduce(Text key, Iterable&lt;IntWritable&gt; values, Context context) throws IOException, InterruptedException {
        // 값들을 합산할 변수 초기화
        int sum = 0;
        // 각 값에 대해
        for (IntWritable value : values) {
            // 현재 값을 sum에 더함
            sum += value.get();
        }
        // 합산된 결과를 result에 설정
        result.set(sum);
        // (단어, 합계) 쌍을 컨텍스트에 기록
        context.write(key, result);
    }

}
Run복사<br><br>package org.example;

import org.apache.hadoop.conf.Configured;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Job;
import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;
import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;
import org.apache.hadoop.util.Tool;
import org.apache.hadoop.util.ToolRunner;

public class WordCountDriver extends Configured implements Tool {

    // Tool 인터페이스의 run 메서드를 오버라이드합니다.
    @Override
    public int run(String[] args) throws Exception {
        // 잡 인스턴스를 생성합니다. 현재 설정을 기반으로 "Word Count"라는 이름을 사용합니다.
        Job job = Job.getInstance(getConf(), "Word Count");

        // 잡의 JAR 파일을 이 클래스의 JAR 파일로 설정합니다.
        job.setJarByClass(getClass());

        // 맵퍼 클래스를 설정합니다.
        job.setMapperClass(WordCountMapper.class);

        // 리듀서 클래스를 설정합니다.
        job.setReducerClass(WordCountReducer.class);

        // 컴바이너 클래스를 설정합니다. (여기서는 리듀서와 동일하게 설정)
        job.setCombinerClass(WordCountReducer.class);

        // 출력 키 클래스를 설정합니다.
        job.setOutputKeyClass(Text.class);

        // 출력 값 클래스를 설정합니다.
        job.setOutputValueClass(IntWritable.class);

        // 입력 경로를 설정합니다.
        FileInputFormat.addInputPath(job, new Path(args[0]));

        // 출력 경로를 설정합니다.
        FileOutputFormat.setOutputPath(job, new Path(args[1]));

        // 잡이 완료될 때까지 기다리고, 성공하면 0을 반환하고 실패하면 1을 반환합니다.
        return job.waitForCompletion(true) ? 0 : 1;
    }

    public static void main(String[] args) {
        if (args.length != 2) {
            System.err.println("Usage: WordCountDriver &lt;input path&gt; &lt;output path&gt;");
            System.exit(-1);
        }
        try {
            int exitCode = ToolRunner.run(new WordCountDriver(), args);
            System.exit(exitCode);
        } catch (Exception e) {
            e.printStackTrace();
        }
    }

}
Run복사<br><br>Deer Bear River
Car Car River
Deer Car Bear
복사<br><br>hadoop fs -mkdir -p /user/ubuntu/input
hadoop fs -put ./word.txt /user/ubuntu/input/
hadoop fs -ls /user/ubuntu/input/
복사<br><br>“Pasted image 20240625155903.png” could not be found.<br>
<br>클릭: 탐색기
<br>우클릭: maven
<br>클릭: Run Maven commands
<br>클릭: install
<br>확인
<br><br>“Pasted image 20240626145053.png” could not be found.<br>yarn jar 1 org.example.WordCountDriver 2 /user/ubuntu/output/
복사<br>Attention이미지 1, 2를 shell의 1, 2 위치로 붙여넣기<br>yarn jar /home/ubuntu/work/hadoop/mapreduce/mapreduce/target/mapreduce-1.0-SNAPSHOT.jar org.example.WordCountDriver /user/ubuntu/input/word.txt /user/ubuntu/output/
복사<br><br>2024-06-26 14:39:02,936 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032
2024-06-26 14:39:03,181 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1719361466459_0001
2024-06-26 14:39:03,317 INFO input.FileInputFormat: Total input files to process : 1
2024-06-26 14:39:03,368 INFO mapreduce.JobSubmitter: number of splits:1
2024-06-26 14:39:03,454 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1719361466459_0001
2024-06-26 14:39:03,456 INFO mapreduce.JobSubmitter: Executing with tokens: []
2024-06-26 14:39:03,561 INFO conf.Configuration: resource-types.xml not found
2024-06-26 14:39:03,561 INFO resource.ResourceUtils: Unable to find 'resource-types.xml'.
2024-06-26 14:39:03,705 INFO impl.YarnClientImpl: Submitted application application_1719361466459_0001
2024-06-26 14:39:03,733 INFO mapreduce.Job: The url to track the job: http://66a2aa90a7fa:8088/proxy/application_1719361466459_0001/
2024-06-26 14:39:03,733 INFO mapreduce.Job: Running job: job_1719361466459_0001
2024-06-26 14:39:08,795 INFO mapreduce.Job: Job job_1719361466459_0001 running in uber mode : false
2024-06-26 14:39:08,795 INFO mapreduce.Job:  map 0% reduce 0%
2024-06-26 14:39:11,838 INFO mapreduce.Job:  map 100% reduce 0%
2024-06-26 14:39:15,854 INFO mapreduce.Job:  map 100% reduce 100%
2024-06-26 14:39:15,860 INFO mapreduce.Job: Job job_1719361466459_0001 completed successfully
2024-06-26 14:39:15,925 INFO mapreduce.Job: Counters: 54
        File System Counters
                FILE: Number of bytes read=50
                FILE: Number of bytes written=472597
                FILE: Number of read operations=0
                FILE: Number of large read operations=0
                FILE: Number of write operations=0
                HDFS: Number of bytes read=157
                HDFS: Number of bytes written=28
                HDFS: Number of read operations=8
                HDFS: Number of large read operations=0
                HDFS: Number of write operations=2
                HDFS: Number of bytes read erasure-coded=0
        Job Counters 
                Launched map tasks=1
                Launched reduce tasks=1
                Data-local map tasks=1
                Total time spent by all maps in occupied slots (ms)=1414
                Total time spent by all reduces in occupied slots (ms)=1521
                Total time spent by all map tasks (ms)=1414
                Total time spent by all reduce tasks (ms)=1521
                Total vcore-milliseconds taken by all map tasks=1414
                Total vcore-milliseconds taken by all reduce tasks=1521
                Total megabyte-milliseconds taken by all map tasks=1447936
                Total megabyte-milliseconds taken by all reduce tasks=1557504
        Map-Reduce Framework
                Map input records=3
                Map output records=9
                Map output bytes=80
                Map output materialized bytes=50
                Input split bytes=113
                Combine input records=9
                Combine output records=4
                Reduce input groups=4
                Reduce shuffle bytes=50
                Reduce input records=4
                Reduce output records=4
                Spilled Records=8
                Shuffled Maps =1
                Failed Shuffles=0
                Merged Map outputs=1
                GC time elapsed (ms)=68
                CPU time spent (ms)=590
                Physical memory (bytes) snapshot=495579136
                Virtual memory (bytes) snapshot=5120688128
                Total committed heap usage (bytes)=458752000
                Peak Map Physical memory (bytes)=296083456
                Peak Map Virtual memory (bytes)=2556694528
                Peak Reduce Physical memory (bytes)=199495680
                Peak Reduce Virtual memory (bytes)=2563993600
        Shuffle Errors
                BAD_ID=0
                CONNECTION=0
                IO_ERROR=0
                WRONG_LENGTH=0
                WRONG_MAP=0
                WRONG_REDUCE=0
        File Input Format Counters 
                Bytes Read=44
        File Output Format Counters 
                Bytes Written=28
복사<br><br><br>hadoop dfs -ls /user/ubuntu/output
복사<br>WARNING: Use of this script to execute dfs is deprecated.
WARNING: Attempting to execute replacement "hdfs dfs" instead.

Found 2 items
-rw-r--r--   1 ubuntu supergroup          0 2024-06-26 14:39 /user/ubuntu/output/_SUCCESS
-rw-r--r--   1 ubuntu supergroup         28 2024-06-26 14:39 /user/ubuntu/output/part-r-00000
복사<br><br>hadoop dfs -text /user/ubuntu/output/part-r-00000
복사<br>WARNING: Use of this script to execute dfs is deprecated.
WARNING: Attempting to execute replacement "hdfs dfs" instead.

Bear    2
Car     3
Deer    2
River   2
복사<br><br><br>“Pasted image 20240626150226.png” could not be found.<br>
<br>입력: localhost:8088
<br>확인: FINISHED, SUCCEEDED
<br>클릭: application_1719361466459_0001
<br>“Pasted image 20240626150325.png” could not be found.]]></description><link>root\dev\data-pipe-line\hadoop\hadoop-수업\실습\hadoop-mapreduce.html</link><guid isPermaLink="false">root/dev/data pipe line/hadoop/hadoop 수업/실습/Hadoop Mapreduce.md</guid><pubDate>Wed, 26 Jun 2024 06:03:38 GMT</pubDate></item><item><title><![CDATA[vscode maven 프로젝트 생성]]></title><description><![CDATA[ 
 <br><a rel="noopener" class="external-link" href="https://hyunchang88.tistory.com/309" target="_blank">https://hyunchang88.tistory.com/309</a><br><br>“Pasted image 20240626132635.png” could not be found.<br>
<br>입력: ctrl + shift + p
<br>생성: 디렉토리

<br>규칙: <a data-tooltip-position="top" aria-label="https://heytech.tistory.com/294" rel="noopener" class="external-link" href="https://heytech.tistory.com/294" target="_blank">스네이크 표기법</a>을 쓸 것


<br>선택: java: create java project
<br><br><br>“Pasted image 20240626132344.png” could not be found.<br>
<br>선택: Maven create from archetype
<br><br><br>“Pasted image 20240626132409.png” could not be found.<br>
<br>선택: maven-archetype-quickstart
<br><br><br>“Pasted image 20240626132434.png” could not be found.<br>
<br>선택: 1.4
<br><br><br>“Pasted image 20240626132453.png” could not be found.<br>
<br>입력: com.example(기본값)
<br><br><br>“Pasted image 20240626132656.png” could not be found.<br>
<br>입력: my_project(스네이크 표기법 사용)
<br><br><br>“Pasted image 20240626132819.png” could not be found.<br>
<br><a class="internal-link" data-href="##프로젝트" href="about:blank##프로젝트" target="_self" rel="noopener">프로젝트</a> 에서 만든 디렉토리 사용
<br><br><br>“Pasted image 20240626132932.png” could not be found.<br>
<br>입력: 엔터
<br>입력: Y
<br>입력: 아무 키
<br><br><br><br>“Pasted image 20240626133026.png” could not be found.<br>Attention마지막에 정하라고 하는데 그 때는 프로젝트 이름과 같은<br>
디렉토리를 만들어서 해주자
.
`-- my_project
    `-- my_project
복사<br><br>“Pasted image 20240626133045.png” could not be found.<br>.
`-- my_project
    `-- my_project
        |-- pom.xml
        |-- src
        |   |-- main
        |   |   `-- java
        |   |       `-- com
        |   |           `-- example
        |   |               `-- App.java
        |   `-- test
        |       `-- java
        |           `-- com
        |               `-- example
        |                   `-- AppTest.java
        `-- target
            |-- classes
            |   `-- com
            |       `-- example
            |           `-- App.class
            `-- test-classes
                `-- com
                    `-- example
                        `-- AppTest.class
복사]]></description><link>root\dev\data-pipe-line\hadoop\hadoop-수업\실습\vscode-maven-프로젝트-생성.html</link><guid isPermaLink="false">root/dev/data pipe line/hadoop/hadoop 수업/실습/vscode maven 프로젝트 생성.md</guid><pubDate>Wed, 26 Jun 2024 04:45:51 GMT</pubDate></item><item><title><![CDATA[docker hadoop 개발 환경 구축]]></title><description><![CDATA[ 
 <br><br><a data-href="docker ubuntu 기본 환경" href="docker ubuntu 기본 환경" class="internal-link" target="_self" rel="noopener">docker ubuntu 기본 환경</a><br><br>docker container run -it -p 9870:9870 -p 8088:8088 -p 8042:8042 -v /home/wsl/work:/home/ubuntu/work --name hadoop-study2 -u ubuntu -w /home/ubuntu ubuntu
복사<br><br>sudo apt-get update
sudo apt-get install -y openssh-server
sudo service ssh start
복사<br><br><br><br>ssh-keygen -t rsa
cat &gt;&gt; ~/.ssh/authorized_keys &lt; ~/.ssh/id_rsa.pub

# 설치 가능한 리스트 업데이트
sudo apt-get -y update

# 업데이트한 패키지들을 최신 버전에 맞게 업그레이드
sudo apt-get -y upgrade

# 의존성까지 체크해서 업그레이드
sudo apt-get -y dist-upgrade

# 필요 라이브러리 설치
sudo apt-get install -y vim wget unzip ssh openssh-* net-tools tree

# Ubuntu 20.4 에는 native libray 인 snappy 가 설치되어 있지 않다.
# 아래 snappy 설치를 하지 않으면 하둡 설치 후 snappy 사용 시 에러가 발생한다.
sudo apt install libsnappy-dev -y


# EC2 Ubuntu terminal

# Java 8 설치
sudo apt-get install -y openjdk-8-jdk

# Java 버전 확인
java -version

# Java 경로 확인
sudo find / -name java-8-openjdk-amd64 2&gt;/dev/null
# /usr/lib/jvm/java-8-openjdk-amd64

복사<br><br># EC2 Ubuntu terminal

# Java 시스템 환경변수 등록 및 활성화
sudo vim /etc/environment

# 아래 내용 추가 후 저장
PATH 뒤에 ":/usr/lib/jvm/java-8-openjdk-amd64/bin" 추가
JAVA_HOME="/usr/lib/jvm/java-8-openjdk-amd64"

# 시스템 환경변수 활성화
source /etc/environment

# 사용자 환경변수 등록
sudo echo 'export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64' &gt;&gt; ~/.bashrc

# 사용자 환경변수 활성화
source ~/.bashrc
복사<br><br><br><br># EC2 Ubuntu terminal

# 설치파일 관리용 다운로드 디렉토리 생성
mkdir ~/downloads &amp;&amp; cd ~/downloads

# Hadoop 3.2.3 설치
wget https://archive.apache.org/dist/hadoop/common/hadoop-3.2.3/hadoop-3.2.3.tar.gz

# Hadoop 3.2.3 압축 해제
sudo tar -zxvf hadoop-3.2.3.tar.gz -C /usr/local

# 소유권 변경
sudo chown -R $USER:$USER /usr/local/hadoop-3.2.3

# hadoop 심볼릭 링크 생성
cd /usr/local &amp;&amp; sudo ln -s hadoop-3.2.3 hadoop
복사<br><br># EC2 Ubuntu terminal

# Hadoop 시스템 환경변수 설정
sudo vim /etc/environment

# 아래 내용 추가 후 저장
PATH 뒤에 ":/usr/local/hadoop/bin" 추가
PATH 뒤에 ":/usr/local/hadoop/sbin" 추가
HADOOP_HOME="/usr/local/hadoop"

# 시스템 환경변수 활성화
source /etc/environment

# Hadoop환 사용자 환경변수 설정
#sudo echo 'export YARN_CONF_DIR=$HADOOP_HOME/etc/hadoop' &gt;&gt; ~/.bashrc
sudo echo 'export HADOOP_HOME=/usr/local/hadoop' &gt;&gt; ~/.bashrc
sudo echo 'export HADOOP_COMMON_HOME=$HADOOP_HOME' &gt;&gt; ~/.bashrc
sudo echo 'export HADOOP_HDFS_HOME=$HADOOP_HOME' &gt;&gt; ~/.bashrc
sudo echo 'export HADOOP_CONF_DIR=$HADOOP_HOME/etc/hadoop' &gt;&gt; ~/.bashrc
sudo echo 'export HADOOP_YARN_HOME=$HADOOP_HOME' &gt;&gt; ~/.bashrc
sudo echo 'export HADOOP_MAPRED_HOME=$HADOOP_HOME' &gt;&gt; ~/.bashrc

# 이거 안하면 hadoop hash 안됨
sudo echo /etc/environment &gt;&gt; ~/.bashrc
# 사용자 환경변수 활성화
source ~/.bashrc
복사<br><br><br>vim $HADOOP_HOME/etc/hadoop/hadoop-env.sh
복사<br># Java
export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64

# Hadoop
export HADOOP_HOME=/usr/local/hadoop
export HADOOP_CONF_DIR=${HADOOP_HOME}/etc/hadoop
export HADOOP_COMMON_LIB_NATIVE_DIR=${HADOOP_HOME}/lib/native
export HADOOP_OPTS="${HADOOP_OPTS} -Djava.library.path=$HADOOP_HOME/lib/native"

# For PID
# hadoop-USER-datanode.pid (DataNode)
# hadoop-USER-journalnode.pid (JournalNode)
# hadoop-USER-namenode.pid (NameNode)
# hadoop-USER-zkfc.pid (DFSZKFailoverController)
export HADOOP_PID_DIR=${HADOOP_HOME}/pids
export HADOOP_SECURE_PID_DIR=${HADOOP_PID_DIR}
복사<br><br>vim $HADOOP_HOME/etc/hadoop/core-site.xml
복사<br>&lt;configuration&gt;
	&lt;property&gt;
		&lt;name&gt;fs.defaultFS&lt;/name&gt;
		&lt;value&gt;hdfs://localhost:9000&lt;/value&gt;
	&lt;/property&gt;
	&lt;property&gt;
		&lt;name&gt;hadoop.http.staticuser.user&lt;/name&gt;
		&lt;value&gt;ubuntu&lt;/value&gt;
	&lt;/property&gt;
&lt;/configuration&gt;
복사<br><br>vim $HADOOP_HOME/etc/hadoop/hdfs-site.xml
복사<br>&lt;configuration&gt;
	&lt;property&gt;
		&lt;name&gt;dfs.replication&lt;/name&gt;
		&lt;value&gt;1&lt;/value&gt;
	&lt;/property&gt;
	&lt;property&gt;
		&lt;name&gt;dfs.namenode.name.dir&lt;/name&gt;
		&lt;value&gt;/usr/local/hadoop/data/namenode&lt;/value&gt;
	&lt;/property&gt;
	&lt;property&gt;
		&lt;name&gt;dfs.datanode.data.dir&lt;/name&gt;
		&lt;value&gt;/usr/local/hadoop/data/datanode&lt;/value&gt;
	&lt;/property&gt;
	&lt;property&gt;
		&lt;name&gt;dfs.journalnode.edits.dir&lt;/name&gt;
		&lt;value&gt;/usr/local/hadoop/data/dfs/journalnode&lt;/value&gt;
	&lt;/property&gt;
&lt;/configuration&gt;
복사<br><br>vim $HADOOP_HOME/etc/hadoop/mapred-site.xml
복사<br>&lt;configuration&gt;
	&lt;property&gt;
		&lt;name&gt;mapreduce.framework.name&lt;/name&gt;
		&lt;value&gt;yarn&lt;/value&gt;
	&lt;/property&gt;
	&lt;property&gt;
		&lt;name&gt;mapreduce.application.classpath&lt;/name&gt;   
		&lt;value&gt;$HADOOP_MAPRED_HOME/share/hadoop/mapreduce/*:$HADOOP_MAPRED_HOME/share/hadoop/mapreduce/lib/*&lt;/value&gt;
	&lt;/property&gt;
&lt;/configuration&gt;
복사<br><br>vim $HADOOP_HOME/etc/hadoop/yarn-site.xml
복사<br>&lt;configuration&gt;
	&lt;property&gt;
		&lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;
		&lt;value&gt;mapreduce_shuffle&lt;/value&gt;
	&lt;/property&gt;
	&lt;property&gt;
		&lt;name&gt;yarn.nodemanager.env-whitelist&lt;/name&gt;
		&lt;value&gt;JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,CLASSPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_MAPRED_HOME&lt;/value&gt;
	&lt;/property&gt;
&lt;/configuration&gt;
복사<br><br>hdfs namenode -format
복사<br><br>sudo service ssh start
cd $HADOOP_HOME/sbin
./start-all.sh
복사<br><br>hadoop version
hdfs version
복사<br>Hadoop 3.2.3
Source code repository https://github.com/apache/hadoop -r abe5358143720085498613d399be3bbf01e0f131
Compiled by ubuntu on 2022-03-20T01:18Z
Compiled with protoc 2.5.0
From source with checksum 39bb14faec14b3aa25388a6d7c345fe8
This command was run using /usr/local/hadoop-3.2.3/share/hadoop/common/hadoop-common-3.2.3.jar
복사<br><br><br>
<br>HDFS : http://localhost:9870
<br>YARN : http://localhost:8088
<br>NodeManager : http://localhost:8042
]]></description><link>root\dev\data-pipe-line\hadoop\hadoop-수업\환경-구축\docker-hadoop-개발-환경-구축.html</link><guid isPermaLink="false">root/dev/data pipe line/hadoop/hadoop 수업/환경 구축/docker hadoop 개발 환경 구축.md</guid><pubDate>Wed, 26 Jun 2024 00:35:31 GMT</pubDate></item><item><title><![CDATA[vscode wsl maven 프로젝트 환경 구축]]></title><description><![CDATA[ 
 <br><br><br>sudo apt-get update
sudo apt-get install mavein
복사<br><br><br><a data-tooltip-position="top" aria-label="https://velog.io/@dkdlel102/vscode%EC%97%90%EC%84%9C-maven-%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8%EB%A5%BC-jar-%ED%8C%8C%EC%9D%BC-%EB%B9%8C%EB%93%9C%ED%95%98%EA%B8%B0" rel="noopener" class="external-link" href="https://velog.io/@dkdlel102/vscode%EC%97%90%EC%84%9C-maven-%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8%EB%A5%BC-jar-%ED%8C%8C%EC%9D%BC-%EB%B9%8C%EB%93%9C%ED%95%98%EA%B8%B0" target="_blank">https://velog.io/@dkdlel102/vscode에서-maven-프로젝트를-jar-파일-빌드하기</a><br><br>“Pasted image 20240625152734.png” could not be found.<br>maven for java
복사<br><br>“Pasted image 20240625152714.png” could not be found.<br>java configuration maven: user setting
복사<br>/usr/share/maven/conf/settings.xml
복사<br><br>“Pasted image 20240625155903.png” could not be found.]]></description><link>root\dev\data-pipe-line\hadoop\hadoop-수업\환경-구축\vscode-wsl-maven-프로젝트-환경-구축.html</link><guid isPermaLink="false">root/dev/data pipe line/hadoop/hadoop 수업/환경 구축/vscode wsl maven 프로젝트 환경 구축.md</guid><pubDate>Wed, 26 Jun 2024 04:52:34 GMT</pubDate></item><item><title><![CDATA[hadoop wsl port 정상 작동 로그]]></title><description><![CDATA[ 
 <br>Check
<br>port: [ 8042, 8088, 9870 ]<br>
sudo lsof -i :port 했을 때<br>
아래와 같은 결과가 나와야 한다.
<br><br>Active Internet connections (only servers)
Proto Recv-Q Send-Q Local Address           Foreign Address         State      
tcp        0      0 0.0.0.0:9870            0.0.0.0:*               LISTEN     
tcp        0      0 127.0.0.54:53           0.0.0.0:*               LISTEN     
tcp        0      0 0.0.0.0:8042            0.0.0.0:*               LISTEN     
tcp        0      0 0.0.0.0:8088            0.0.0.0:*               LISTEN     
tcp        0      0 127.0.0.53:53           0.0.0.0:*               LISTEN     
tcp        0      0 127.0.0.1:32921         0.0.0.0:*               LISTEN     
tcp6       0      0 :::9870                 :::*                    LISTEN     
tcp6       0      0 :::8042                 :::*                    LISTEN     
tcp6       0      0 :::8088                 :::*                    LISTEN     
udp        0      0 127.0.0.54:53           0.0.0.0:*                          
udp        0      0 127.0.0.53:53           0.0.0.0:*                          
udp        0      0 127.0.0.1:323           0.0.0.0:*                          
udp6       0      0 ::1:323                 :::*                               
복사<br><br><br><br>&gt;  sudo lsof -i :8088

COMMAND     PID USER   FD   TYPE DEVICE SIZE/OFF NODE NAME
docker-pr 25876 root    4u  IPv4 396225      0t0  TCP *:omniorb (LISTEN)
docker-pr 25885 root    3u  IPv6 443958      0t0  TCP ip6-localhost:omniorb-&gt;ip6-localhost:37532 (ESTABLISHED)
docker-pr 25885 root    4u  IPv6 401527      0t0  TCP *:omniorb (LISTEN)
docker-pr 25885 root    5u  IPv4 443960      0t0  TCP 172.17.0.1:39330-&gt;172.17.0.2:omniorb (ESTABLISHED)
복사<br><br>&gt;  sudo lsof -i :8042

COMMAND     PID USER   FD   TYPE DEVICE SIZE/OFF NODE NAME
docker-pr 25857 root    4u  IPv4 398819      0t0  TCP *:8042 (LISTEN)
docker-pr 25869 root    3u  IPv6 437943      0t0  TCP ip6-localhost:8042-&gt;ip6-localhost:38704 (ESTABLISHED)
docker-pr 25869 root    4u  IPv6 396220      0t0  TCP *:8042 (LISTEN)
docker-pr 25869 root    5u  IPv4 437945      0t0  TCP 172.17.0.1:55528-&gt;172.17.0.2:8042 (ESTABLISHED)
복사<br><br>&gt;  sudo lsof -i :9870

COMMAND     PID USER   FD   TYPE DEVICE SIZE/OFF NODE NAME
docker-pr 25892 root    4u  IPv4 400877      0t0  TCP *:9870 (LISTEN)
docker-pr 25899 root    4u  IPv6 391975      0t0  TCP *:9870 (LISTEN)
복사]]></description><link>root\dev\data-pipe-line\hadoop\hadoop-wsl-port-정상-작동-로그.html</link><guid isPermaLink="false">root/dev/data pipe line/hadoop/hadoop wsl port 정상 작동 로그.md</guid><pubDate>Mon, 01 Jul 2024 14:59:37 GMT</pubDate></item><item><title><![CDATA[hadoop-study docker image]]></title><description><![CDATA[ 
 <br>hahoop, zookeeper maridb, hive<br><br>docker pull namugach/hadoop-study:latest
복사<br><br><br>
<br>create volum dir
<br>mkdir ~/work
복사<br>
<br>create run docker container
<br>docker container run -it -d -p 9870:9870 -p 8088:8088 -p 8042:8042 -v /home/$USER/work:/home/ubuntu/work --name my-hadoop-study namugach/hadoop-study

복사<br><br><br>docker container exec -it my-hadoop-study bash
복사<br><br><br>
<br>start

<br>ssh에 관한 게 나오면 yes를 입력
<br>hadoopStart.sh 이것은 컨테이너를 만들고 나서 처음만 하면 됨.


<br>~/hadoopStart.sh
복사<br>
<br>check
<br>jps
복사<br>
<br>output
<br>400 NameNode
3875 NodeManager
3220 SecondaryNameNode
3540 ResourceManager
8454 Jps
542 DataNode
복사<br>
<br>web

<br>HDFS : http://localhost:9870
<br>YARN : http://localhost:8088
<br>NodeManager : http://localhost:8042


<br><br><br>Attention컨테이너를 바로 부팅하고 시작 하면 안되고, 좀 기다렸다 해야함.<br>
<br>connect
<br>hive
복사<br>
<br>show database
<br>show databases;
복사<br>
<br>output
<br>OK
default
test
Time taken: 0.475 seconds, Fetched: 2 row(s)
복사<br><br><br>
<br>start
<br>~/zkServer.sh start
복사<br>
<br>stop
<br>~/zkServer.sh stop
복사]]></description><link>root\dev\data-pipe-line\hadoop\hadoop-study-docker-image.html</link><guid isPermaLink="false">root/dev/data pipe line/hadoop/hadoop-study docker image.md</guid><pubDate>Mon, 01 Jul 2024 00:24:27 GMT</pubDate></item><item><title><![CDATA[Hive 트러블 슈팅]]></title><description><![CDATA[ 
 <br><br>wget https://repo1.maven.org/maven2/mysql/mysql-connector-java/8.0.28/mysql-connector-java-8.0.28.jar
cp mysql-connector-java-8.0.28.jar $HIVE_HOME/lib/
vi $HIVE_HOME/conf/hive-env.sh
복사<br>export HIVE_AUX_JARS_PATH=$HIVE_AUX_JARS_PATH:/path/to/mysql-connector-java-8.0.28.jar
복사<br>$HIVE_HOME/bin/schematool -dbType mysql -initSchema
history 
복사]]></description><link>root\dev\data-pipe-line\hadoop\hive-트러블-슈팅.html</link><guid isPermaLink="false">root/dev/data pipe line/hadoop/Hive 트러블 슈팅.md</guid><pubDate>Wed, 26 Jun 2024 11:55:09 GMT</pubDate></item><item><title><![CDATA[kafka 서버 설정 자동화]]></title><description><![CDATA[ 
 <br><br>mkdir ~/run/kafka
vi ~/run/kafka/update_cluster_configs.sh
복사<br><br><br>#!/bin/bash

# 서버 목록과 각 서버에 해당하는 ID와 IP 주소 설정
declare -A servers
servers=(
	["server1"]="1 172.17.0.2"
	["server2"]="2 172.17.0.3"
	["server3"]="3 172.17.0.4"
)

# 파일 경로 설정
MYID_PATH="/home/ubuntu/zkdata/myid"
SERVER_PROPERTIES_PATH="~/app/kafka/kafka_2.13-3.6.2/config/server.properties"

for server in "${!servers[@]}"; do
	id_ip=(${servers[$server]})
	id=${id_ip[0]}
	ip=${id_ip[1]}

	echo "Updating $server with ID $id and IP $ip"

	# myid 파일 업데이트
	ssh "$server" "echo $id &gt; $MYID_PATH"

	# server.properties 파일 업데이트
	ssh "$server" "sed -i 's/^broker.id=.*/broker.id=$id/' $SERVER_PROPERTIES_PATH"
	ssh "$server" "sed -i 's|^listeners=PLAINTEXT://.*|listeners=PLAINTEXT://$ip:9092|' $SERVER_PROPERTIES_PATH"
	ssh "$server" "sed -i 's|^advertised.listeners=PLAINTEXT://.*|advertised.listeners=PLAINTEXT://$ip:9092|' $SERVER_PROPERTIES_PATH"

	echo "Updated $server"
done

echo "All servers updated successfully."
복사<br><br>chmod +x update_kafka_configs.sh
복사<br><br>./update_kafka_configs.sh
복사]]></description><link>root\dev\data-pipe-line\kafka\shellscript\kafka-서버-설정-자동화.html</link><guid isPermaLink="false">root/dev/data pipe line/kafka/shellscript/kafka 서버 설정 자동화.md</guid><pubDate>Sat, 03 Aug 2024 15:50:14 GMT</pubDate></item><item><title><![CDATA[kafka 클러스터 스크립트]]></title><description><![CDATA[ 
 <br><br>mkdir ~/run/kafka
vi ~/run/kafka/start_cluster.sh
복사<br><br><br><br>#!/bin/bash

ips=("server1" "server2" "server3")

start_service() {
	local service_name=$1
	local script_path=$2
	local sleep_time=${3:-1} # 기본값을 1로 설정

	for ip in "${ips[@]}"; do
		echo ""
		echo "============== $service_name 시작 시도 중: $ip =============="
		echo ""
		ssh -o StrictHostKeyChecking=no -o ConnectTimeout=5 $ip 'bash -s' &lt; "$script_path"
		sleep $sleep_time
		if [ $? -eq 0 ]; then
			echo "$ip 에서 $service_name 가 성공적으로 시작되었어"
		else
			echo "$ip 에서 $service_name 시작 실패"
			exit 1
		fi
	done
}

# Zookeeper 시작 및 상태 확인
start_service "Zookeeper" "./run/kafka/start_zookeeper.sh"

# 대기
sleep 3

# Kafka 서버 시작
start_service "Kafka 서버" "./run/kafka/start_server.sh" 2

# Kafka check
start_service "Kafka check" "./run/kafka/check_conn.sh" 2
복사<br><br>#!/bin/bash

ips=("server1" "server2" "server3")

# Zookeeper 시작 및 상태 확인
for ip in "${ips[@]}"; do
	echo "Zookeeper 시작 시도 중: $ip"
	ssh -o StrictHostKeyChecking=no -o ConnectTimeout=5 $ip 'bash -s' &lt; ./run/kafka_zookeeper_start.sh
	sleep 1
	if [ $? -eq 0 ]; then
			echo "$ip 에서 Zookeeper가 성공적으로 시작되었어"
	else
			echo "$ip 에서 Zookeeper 시작 실패"
			exit 1
	fi
done

# 대기
sleep 3

# Kafka 서버 시작
for ip in "${ips[@]}"; do
	echo "Kafka 서버 시작 시도 중: $ip"
	ssh -o StrictHostKeyChecking=no -o ConnectTimeout=5 $ip 'bash -s' &lt; ./run/kafka_server_start.sh
	sleep 1
	if [ $? -eq 0 ]; then
			echo "$ip 에서 Kafka 서버가 성공적으로 시작되었어"
	else
			echo "$ip 에서 Kafka 서버 시작 실패"
			exit 1
	fi
done
복사<br><br><br>mkdir ./run/kafka
vi ./run/kafka/stop_cluster.sh
복사<br>#!/bin/bash

ips=("server1" "server2" "server3")

# Kafka 서버 종료
for ip in "${ips[@]}"; do
	echo "Kafka 서버 종료 시도 중: $ip"
	ssh -o StrictHostKeyChecking=no -o ConnectTimeout=5 $ip 'bash -s' &lt;&lt;-'EOF'
			cd /home/ubuntu/app/kafka/kafka_2.13-3.6.2/
			./bin/kafka-server-stop.sh
EOF
	if [ $? -eq 0 ]; then
			echo "$ip 에서 Kafka 서버가 성공적으로 종료되었어"
	else
			echo "$ip 에서 Kafka 서버 종료 실패"
			exit 1
	fi
done

# Zookeeper 서버 종료
for ip in "${ips[@]}"; do
	echo "Zookeeper 서버 종료 시도 중: $ip"
	ssh -o StrictHostKeyChecking=no -o ConnectTimeout=5 $ip 'bash -s' &lt;&lt;-'EOF'
			cd /home/ubuntu/app/kafka/kafka_2.13-3.6.2/
			./bin/zookeeper-server-stop.sh
EOF
	if [ $? -eq 0 ]; then
			echo "$ip 에서 Zookeeper 서버가 성공적으로 종료되었어"
	else
			echo "$ip 에서 Zookeeper 서버 종료 실패"
			exit 1
	fi
done
복사<br><br><br>
<br>종료 스크립트 사용 방법:
<br>
<br>스크립트에 실행 권한을 부여해:
<br>chmod +x stop_kafka_cluster.sh
복사<br>
<br>스크립트를 실행해:
<br>./stop_kafka_cluster.sh
복사<br>
<br>시작 스크립트 사용 방법:
<br>
<br>이미 실행 권한을 부여한 상태라면:
<br>./start_kafka_cluster.sh
복사<br><br>
<br>stop_kafka_cluster.sh: 각 서버에 SSH로 접속하여 Kafka 서버를 먼저 종료한 후, Zookeeper 서버를 종료해. 순차적으로 종료되도록 설계했어.
<br>start_kafka_cluster.sh: 각 서버에 SSH로 접속하여 Zookeeper 서버를 먼저 시작하고, 상태를 확인한 후 Kafka 서버를 시작해. Zookeeper가 제대로 시작되었는지 확인하는 과정이 포함되어 있어.
<br>이 스크립트들을 사용하면 안전하게 Kafka 클러스터를 종료하고 시작할 수 있어. 문제가 발생할 경우 스크립트가 중단되기 때문에 안정성을 높일 수 있어.]]></description><link>root\dev\data-pipe-line\kafka\shellscript\kafka-클러스터-스크립트.html</link><guid isPermaLink="false">root/dev/data pipe line/kafka/shellscript/kafka 클러스터 스크립트.md</guid><pubDate>Sat, 03 Aug 2024 15:51:02 GMT</pubDate></item><item><title><![CDATA[shellscirpt kafka zookeeper server]]></title><description><![CDATA[ 
 <br><br>mkdir ~/run/kafka
vi ~/run/kafka/zookeeper_start.sh
복사<br><br><br>#!/bin/bash

cd /home/ubuntu/app/kafka/kafka_2.13-3.6.2/

nohup ./bin/zookeeper-server-start.sh config/zookeeper.properties &gt;/dev/null 2&gt;&amp;1
복사]]></description><link>root\dev\data-pipe-line\kafka\shellscript\shellscirpt-kafka-zookeeper-server.html</link><guid isPermaLink="false">root/dev/data pipe line/kafka/shellscript/shellscirpt kafka zookeeper server.md</guid><pubDate>Sat, 03 Aug 2024 15:50:54 GMT</pubDate></item><item><title><![CDATA[shellscript kafka server conn check]]></title><description><![CDATA[ 
 <br><br>mkdir ~/run/kafka
vi ~/run/kafka/check_conn.sh
복사<br><br><br>#!/bin/bash
netstat -ntlp | grep 2181

echo ""
echo "======================="
echo ""

netstat -ntlp | grep 9092
복사]]></description><link>root\dev\data-pipe-line\kafka\shellscript\shellscript-kafka-server-conn-check.html</link><guid isPermaLink="false">root/dev/data pipe line/kafka/shellscript/shellscript kafka server conn check.md</guid><pubDate>Sat, 03 Aug 2024 15:50:49 GMT</pubDate></item><item><title><![CDATA[shellscript kafka server start]]></title><description><![CDATA[ 
 <br><br>mkdir ~/run/kafka
vi ~/run/kafka/start_server.sh
복사<br><br><br>#!/bin/bash

cd /home/ubuntu/app/kafka/kafka_2.13-3.6.2/

nohup ./bin/kafka-server-start.sh config/server.properties &gt;/dev/null 2&gt;&amp;1
복사]]></description><link>root\dev\data-pipe-line\kafka\shellscript\shellscript-kafka-server-start.html</link><guid isPermaLink="false">root/dev/data pipe line/kafka/shellscript/shellscript kafka server start.md</guid><pubDate>Sat, 03 Aug 2024 15:50:43 GMT</pubDate></item><item><title><![CDATA[카프카에 대한 고찰]]></title><description><![CDATA[ 
 <br>Kafka를 사용했을 때와 그렇지 않았을 때의 차이를 극명하게 느끼려면, Kafka의 핵심 기능인 실시간 데이터 스트리밍과 확장성의 이점을 실제로 체험해보는 것이 중요합니다. 이를 위해 다음과 같은 시나리오를 비교해 볼 수 있습니다:<br><br><br>이 경우, 데이터는 MySQL 데이터베이스에 직접 삽입되고, 데이터베이스에서 실시간 데이터 분석이나 다른 시스템으로의 데이터 전송은 별도의 작업으로 처리됩니다.<br><br>
<br>시스템이 단순해지고, 데이터베이스 관리와 유지보수가 쉬워집니다.
<br><br>
<br>실시간 데이터 처리가 어렵고, 데이터 처리 속도가 데이터베이스 성능에 제한됩니다.
<br>확장성이 낮아, 높은 데이터 트래픽이나 다양한 데이터 소비 요구에 대응하기 어렵습니다.
<br>여러 시스템 간 데이터 통합이나 데이터 동기화가 복잡해질 수 있습니다.
<br><br>Kafka를 사용하면 데이터는 Kafka 토픽에 게시되고, MySQL 데이터베이스는 Kafka의 컨슈머 중 하나로서 데이터를 소비하게 됩니다. 이 경우 Kafka는 데이터 브로커로서 다양한 시스템에 데이터를 스트리밍합니다.<br><br>
<br>실시간 데이터 스트리밍: Kafka는 데이터를 실시간으로 여러 컨슈머에게 스트리밍할 수 있어, 데이터베이스 저장 외에도 실시간 분석, 모니터링, 알림 시스템 등 다양한 사용 사례에 데이터를 즉시 사용할 수 있습니다.
<br>확장성: Kafka 클러스터를 확장하여 더 많은 데이터를 처리할 수 있으며, 새로운 컨슈머를 쉽게 추가하여 다양한 애플리케이션이 데이터를 소비할 수 있습니다.
<br>내구성: Kafka는 데이터를 디스크에 저장하고 복제하므로, 시스템 장애 시에도 데이터 손실이 최소화됩니다.
<br>분리된 시스템: 데이터 생산자와 소비자 시스템 간의 결합이 느슨해져, 각각 독립적으로 확장하거나 업데이트할 수 있습니다.
<br><br>
<br>시스템 복잡도가 증가하고, Kafka 클러스터 운영과 관리에 추가적인 노력이 필요합니다.
<br>초기 설정 및 학습 곡선이 있습니다.
<br><br>실제로 Kafka를 사용했을 때와 사용하지 않았을 때의 차이를 체험하려면 다음과 같은 실험을 해볼 수 있습니다:<br>
<br>
고속 데이터 인제스트 시나리오:

<br>대량의 데이터를 짧은 시간에 인제스트할 때, Kafka가 이를 효과적으로 버퍼링하고 처리하는 반면, MySQL은 성능 병목 현상이 발생할 수 있습니다.


<br>
실시간 분석 시나리오:

<br>Kafka를 사용하여 데이터가 발생하는 즉시 스트리밍 데이터를 분석하는 컨슈머를 연결하고, MySQL에서는 데이터베이스 쿼리로 실시간 데이터를 분석해보십시오. Kafka의 스트리밍 처리가 얼마나 신속하고 효율적인지 알 수 있습니다.


<br>
다양한 소비자 연결 시나리오:

<br>같은 데이터를 여러 시스템이 소비해야 하는 경우, Kafka의 pub-sub 모델을 사용하여 이를 간단하게 구현할 수 있습니다. MySQL을 사용하면 데이터베이스에서 직접 데이터 복사를 설정하거나 별도의 통합 솔루션이 필요할 수 있습니다.


<br>이러한 실험을 통해 Kafka의 장점을 직접 경험할 수 있으며, 이를 통해 Kafka 사용의 실질적인 이점을 명확하게 느낄 수 있습니다.<br><br><br>CSV 데이터를 사용하여 Kafka를 통해 데이터를 스트리밍하고, MySQL에 저장하는 예제를 제공하겠습니다. 이 예제에서는 CSV 파일에서 데이터를 읽어 Kafka에 게시하고, Kafka 컨슈머가 이 데이터를 소비하여 MySQL에 저장하는 방식으로 진행됩니다.<br><br>
<br>CSV 파일: 예시로 사용될 데이터를 포함한 파일. 예를 들어, users.csv라는 파일을 사용할 수 있습니다.
<br>MySQL 데이터베이스 서버
<br>Kafka 브로커 및 Zookeeper
<br>Kafka Python 클라이언트 (kafka-python 패키지)
<br>MySQL Python 클라이언트 (pymysql 패키지)
<br>Pandas (CSV 데이터를 읽기 위해 사용)
<br><br>name,age
Alice,30
Bob,24
Charlie,29
복사<br><br>먼저, MySQL에 users 테이블을 생성합니다.<br>import pymysql

# MySQL 연결 설정
connection = pymysql.connect(
    host='localhost',
    user='root',
    password='password',
    database='my_data'
)

# 테이블 생성 쿼리
create_table_query = """
CREATE TABLE IF NOT EXISTS users (
    id INT AUTO_INCREMENT PRIMARY KEY,
    name VARCHAR(100),
    age INT
)
"""

try:
    with connection.cursor() as cursor:
        cursor.execute(create_table_query)
    connection.commit()
finally:
    connection.close()
Run복사<br><br>CSV 파일의 데이터를 읽어 MySQL에 직접 삽입하는 코드입니다.<br>import pandas as pd
import pymysql

def insert_csv_into_mysql(file_path):
    # CSV 데이터 읽기
    data = pd.read_csv(file_path)

    # MySQL 연결 설정
    connection = pymysql.connect(
        host='localhost',
        user='root',
        password='password',
        database='my_data'
    )

    insert_query = "INSERT INTO users (name, age) VALUES (%s, %s)"
    try:
        with connection.cursor() as cursor:
            # CSV 데이터를 MySQL에 삽입
            for _, row in data.iterrows():
                cursor.execute(insert_query, (row['name'], row['age']))
        connection.commit()
    finally:
        connection.close()

# CSV 파일 경로
csv_file_path = 'users.csv'

insert_csv_into_mysql(csv_file_path)
print("MySQL에 CSV 데이터 삽입 완료.")
Run복사<br><br><br>CSV 파일의 데이터를 Kafka 토픽에 게시하는 코드입니다.<br>from kafka import KafkaProducer
import pandas as pd
import json

def produce_csv_to_kafka(file_path, topic):
    # CSV 데이터 읽기
    data = pd.read_csv(file_path)

    producer = KafkaProducer(
        bootstrap_servers='localhost:9092',
        value_serializer=lambda v: json.dumps(v).encode('utf-8')
    )

    # 각 행을 Kafka 메시지로 게시
    for _, row in data.iterrows():
        message = row.to_dict()
        producer.send(topic, value=message)

    producer.flush()
    print("Kafka에 CSV 데이터 게시 완료.")

produce_csv_to_kafka(csv_file_path, 'my_topic')
Run복사<br><br>Kafka에서 데이터를 소비하고 MySQL에 저장하는 코드입니다.<br>from kafka import KafkaConsumer
import pymysql
import json

def consume_from_kafka_and_insert_into_mysql(topic):
    consumer = KafkaConsumer(
        topic,
        bootstrap_servers='localhost:9092',
        auto_offset_reset='earliest',
        enable_auto_commit=True,
        value_deserializer=lambda m: json.loads(m.decode('utf-8'))
    )

    def insert_into_mysql(data):
        connection = pymysql.connect(
            host='localhost',
            user='root',
            password='password',
            database='my_data'
        )

        insert_query = "INSERT INTO users (name, age) VALUES (%s, %s)"
        try:
            with connection.cursor() as cursor:
                cursor.executemany(insert_query, [(d['name'], d['age']) for d in data])
            connection.commit()
        finally:
            connection.close()

    buffer = []
    for message in consumer:
        data = message.value
        buffer.append(data)
        if len(buffer) &gt;= 10:  # 예시로 10개씩 버퍼링하여 MySQL에 삽입
            insert_into_mysql(buffer)
            buffer = []

    # 남은 데이터 삽입
    if buffer:
        insert_into_mysql(buffer)

    print("Kafka에서 데이터 소비 및 MySQL에 저장 완료.")

consume_from_kafka_and_insert_into_mysql('my_topic')
Run복사<br><br>
<br>시나리오 1:

<br>insert_csv_into_mysql 함수를 호출하여 CSV 데이터를 MySQL에 직접 삽입합니다.


<br>시나리오 2:

<br>produce_csv_to_kafka 함수를 호출하여 CSV 데이터를 Kafka에 게시한 후, consume_from_kafka_and_insert_into_mysql 함수를 호출하여 Kafka에서 데이터를 소비하고 MySQL에 저장합니다.


<br>이 실습을 통해 CSV 데이터를 사용하여 Kafka의 사용 여부에 따른 데이터 처리 방식을 비교하고, Kafka의 장점(실시간 처리, 확장성 등)을 직접 체험할 수 있습니다.]]></description><link>root\dev\data-pipe-line\kafka\카프카에-대한-고찰.html</link><guid isPermaLink="false">root/dev/data pipe line/kafka/카프카에 대한 고찰.md</guid><pubDate>Sat, 27 Jul 2024 05:57:01 GMT</pubDate></item><item><title><![CDATA[카프카에 csv 파일 넣어보기]]></title><description><![CDATA[ 
 <br>pip install kafka-python
복사<br>from kafka import KafkaProducer
import pandas as pd
import json

def produce_csv_to_kafka(file_path, topic):
    # CSV 데이터 읽기
    data = pd.read_csv(file_path)

    # Kafka 프로듀서 설정 (클러스터 환경)
    producer = KafkaProducer(
        bootstrap_servers=['172.17.0.2:9092', '172.17.0.3:9092', '172.17.0.4:9092'],
        value_serializer=lambda v: json.dumps(v).encode('utf-8')
    )

    # 각 행을 Kafka 메시지로 게시
    for _, row in data.iterrows():
        message = row.to_dict()
        producer.send(topic, value=message)

    producer.flush()
    print("Kafka에 CSV 데이터 게시 완료.")

# CSV 파일 경로와 Kafka 토픽 설정
csv_file_path = 'data.csv'
produce_csv_to_kafka(csv_file_path, 'my_topic')
Run복사]]></description><link>root\dev\data-pipe-line\kafka\카프카에-csv-파일-넣어보기.html</link><guid isPermaLink="false">root/dev/data pipe line/kafka/카프카에 csv 파일 넣어보기.md</guid><pubDate>Mon, 29 Jul 2024 15:23:20 GMT</pubDate></item><item><title><![CDATA[Apache Kafka 실시간 Data Pipeline 구축하기]]></title><description><![CDATA[ 
 <br>“Pasted image 20240708175351.png” could not be found.<br><a rel="noopener" class="external-link" href="https://github.com/freepsw/kafka_basic/tree/main/02.kafka_pipeline" target="_blank">https://github.com/freepsw/kafka_basic/tree/main/02.kafka_pipeline</a><br><a rel="noopener" class="external-link" href="https://blog.naver.com/freepsw/222227393582" target="_blank">https://blog.naver.com/freepsw/222227393582</a><br><a data-tooltip-position="top" aria-label="https://docs.confluent.io/platform/current/kafka/monitoring.html" rel="noopener" class="external-link" href="https://docs.confluent.io/platform/current/kafka/monitoring.html" target="_blank">Monitoring Kafka with JMX | Confluent Documentation</a>]]></description><link>root\dev\data-pipe-line\kafka\apache-kafka-실시간-data-pipeline-구축하기.html</link><guid isPermaLink="false">root/dev/data pipe line/kafka/Apache Kafka 실시간 Data Pipeline 구축하기.md</guid><pubDate>Mon, 08 Jul 2024 08:53:52 GMT</pubDate></item><item><title><![CDATA[kafak에 mysql 연결]]></title><description><![CDATA[ 
 <br>카프카를 데이터 파이프라인의 중심에 두고, 데이터 생산자는 카프카에 데이터를 전송하고, 카프카 커넥트를 사용해 데이터를 다양한 싱크(데이터베이스 등)로 전달하는 방식은 매우 일반적이고 안정적인 데이터 처리 방법이야.<br>카프카와 데이터베이스를 연결하는 것은 여러 가지 장점이 있어:<br>
<br>확장성: 카프카는 높은 처리량을 처리할 수 있어서 대규모 데이터 전송에도 적합해.
<br>신뢰성: 카프카는 데이터의 내구성을 보장해, 데이터 손실 없이 안정적으로 전송할 수 있어.
<br>유연성: 다양한 소스와 싱크를 연결할 수 있어 데이터 파이프라인을 유연하게 구성할 수 있어.
<br>비동기 처리: 데이터 생산자와 소비자가 비동기적으로 동작할 수 있어서 시스템의 복잡도를 줄일 수 있어.
<br>다시 한번 정리하면, 카프카와 데이터베이스를 연결하는 시나리오는 다음과 같아:<br>
<br>데이터 생산자 (Python 코드): CSV 파일 데이터를 읽고, 카프카로 전송.
<br>카프카: 데이터를 토픽으로 받음.
<br>카프카 커넥트: 카프카 토픽 데이터를 MySQL 데이터베이스로 전송.
<br>이 시나리오를 실제로 구현하는 방법을 구체적으로 설명할게.<br><br>Kafka Connect는 카프카의 생태계에 포함되어 있는 도구야. 여기서는 io.confluent.connect.jdbc.JdbcSinkConnector를 사용해 MySQL과 연결할 거야.<br><br>카프카를 이미 설치했다면 Kafka Connect도 함께 설치되어 있어.<br><br>MySQL JDBC 드라이버를 다운로드하고 Kafka Connect의 plugins 디렉토리에 복사해줘.<br><br>MySQL 싱크 커넥터를 설정하는 JSON 파일을 작성해.<br><br>{
  "name": "mysql-sink-connector",
  "config": {
    "connector.class": "io.confluent.connect.jdbc.JdbcSinkConnector",
    "tasks.max": "1",
    "topics": "my_topic",
    "connection.url": "jdbc:mysql://localhost:3306/my_data",
    "connection.user": "ubuntu",
    "connection.password": "1234",
    "auto.create": "true",
    "insert.mode": "insert",
    "pk.mode": "none",
    "table.name.format": "test_a"
  }
}
복사<br><br>Kafka Connect를 실행하고, MySQL 싱크 커넥터를 등록해.<br><br>Kafka Connect를 배포 모드로 실행해.<br>bin/connect-distributed.sh config/connect-distributed.properties
Run복사<br><br>MySQL 싱크 커넥터를 Kafka Connect에 등록해.<br>curl -X POST -H "Content-Type: application/json" --data @mysql-sink-connector.json http://localhost:8083/connectors
Run복사<br><br>Python 코드를 작성해서 CSV 파일 데이터를 카프카 토픽으로 전송해.<br>from confluent_kafka import Producer
import pandas as pd
import json

# 카프카 프로듀서 설정
KAFKA_SERVERS = '172.17.0.2:9092,172.17.0.3:9092,172.17.0.4:9092'
KAFKA_TOPIC = 'my_topic'

# CSV 파일에서 데이터 추출
data = pd.read_csv('data.csv')

# 카프카 프로듀서 설정
producer_conf = {
    'bootstrap.servers': KAFKA_SERVERS,
}
producer = Producer(producer_conf)

# 데이터를 카프카 토픽으로 전송
def delivery_report(err, msg):
    if err is not None:
        print(f"Message delivery failed: {err}")
    else:
        print(f"Message delivered to {msg.topic()} [{msg.partition()}]")

for index, row in data.iterrows():
    message = json.dumps({
        'column1': row['column1'],
        'column2': row['column2'],
        'column3': row['column3']  # assuming column3 is in a date format already
    })
    producer.produce(KAFKA_TOPIC, key=str(index), value=message, callback=delivery_report)

producer.flush()

print("데이터가 카프카로 성공적으로 전송되었습니다.")
Run복사<br>이렇게 하면, 데이터는 다음과 같은 순서로 흐르게 돼:<br>
<br>Python 코드: CSV 파일 데이터를 카프카 토픽으로 전송.
<br>카프카: 데이터를 토픽으로 받음.
<br>Kafka Connect: 카프카 토픽 데이터를 MySQL 데이터베이스에 적재.
<br>이 시나리오는 데이터 파이프라인의 확장성과 신뢰성을 모두 제공해, 데이터가 손실 없이 안정적으로 처리될 수 있어. 이 방식은 많은 대규모 데이터 처리 시스템에서 사용되는 검증된 방법이야.]]></description><link>root\dev\data-pipe-line\kafka\kafak에-mysql-연결.html</link><guid isPermaLink="false">root/dev/data pipe line/kafka/kafak에 mysql 연결.md</guid><pubDate>Sun, 28 Jul 2024 18:12:21 GMT</pubDate></item><item><title><![CDATA[kafka 설정 및 실행]]></title><description><![CDATA[ 
 <br><a data-href="kafka 설치" href="root\dev\data-pipe-line\kafka\kafka-설치.html" class="internal-link" target="_self" rel="noopener">kafka 설치</a><br>Attentionserver 1,2,3 모두 적용<br>그리고<br>정말 중요!docker 컨테이너 안에서 실행 할 때는 굳이<br>
-p 옵션을 줘서 포트포워딩 할 필요가 없다.<br>
그러니 이 부분에 있어서는 신경쓰지 말고 구현하자<br><br><br>서버에 맞게 설정!
<br>server1

cd
mkdir zkdata
cd zkdata
echo 1 &gt; ./myid
복사

<br>server2

cd
mkdir zkdata
cd zkdata
echo 2 &gt; ./myid
복사

<br>server3

cd
mkdir zkdata
cd zkdata
echo 3 &gt; ./myid
복사<br><br>cd /home/ubuntu/app/kafka/kafka_2.13-3.6.2/config
복사<br><br>Importantdocker image를 만들기 위해서 <a data-href="kafka server.properties" href="root\dev\data-pipe-line\kafka\kafka-server.properties.html" class="internal-link" target="_self" rel="noopener">kafka server.properties</a>를 적용 시키고<br>
서버에 맞게 설정 하는 것은 적용된 값에서 컨테이너마다 설정 해주자<br>서버에 맞게 설정!broker.id
listeners
advertised.listeners
복사
위의 프로퍼티는 각 서버에 맞게 수정해서 적용해야 함

<br>server1

broker.id = 1
listeners=PLAINTEXT://172.17.0.2:9092
advertised.listeners=PLAINTEXT://172.17.0.2:9092
복사

<br>server2

broker.id = 2
listeners=PLAINTEXT://172.17.0.3:9092
advertised.listeners=PLAINTEXT://172.17.0.3:9092
복사

<br>server3

broker.id = 3
listeners=PLAINTEXT://172.17.0.4:9092
advertised.listeners=PLAINTEXT://172.17.0.4:9092
복사<br><br># Licensed to the Apache Software Foundation (ASF) under one or more
# contributor license agreements.  See the NOTICE file distributed with
# this work for additional information regarding copyright ownership.
# The ASF licenses this file to You under the Apache License, Version 2.0
# (the "License"); you may not use this file except in compliance with
# the License.  You may obtain a copy of the License at
# 
#    http://www.apache.org/licenses/LICENSE-2.0
# 
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# the directory where the snapshot is stored.
dataDir=/home/ubuntu/zkdata
# the port at which the clients will connect
clientPort=2181
tickTime=2000
initLimit=10
syncLimit=5
server.1=172.17.0.2:2888:3888
server.2=172.17.0.3:2888:3888
server.3=172.17.0.4:2888:3888
# disable the per-ip limit on the number of connections since this is a non-production config
maxClientCnxns=0
# Disable the adminserver by default to avoid port conflicts.
# Set the port to something non-conflicting if choosing to enable this
admin.enableServer=false
# admin.serverPort=8080
복사<br><br><br><br><a data-href="shellscirpt kafka zookeeper server" href="root\dev\data-pipe-line\kafka\shellscript\shellscirpt-kafka-zookeeper-server.html" class="internal-link" target="_self" rel="noopener">shellscirpt kafka zookeeper server</a><br><br><a data-href="shellscript kafka server start" href="root\dev\data-pipe-line\kafka\shellscript\shellscript-kafka-server-start.html" class="internal-link" target="_self" rel="noopener">shellscript kafka server start</a><br><br><a data-href="shellscript kafka server conn check" href="root\dev\data-pipe-line\kafka\shellscript\shellscript-kafka-server-conn-check.html" class="internal-link" target="_self" rel="noopener">shellscript kafka server conn check</a><br><br>sudo chmod +x kafka_zookeeper_start.sh kafka_server_start.sh kafka_check.sh
복사<br><br><br><br>cd /home/ubuntu/app/kafka/kafka_2.13-3.6.2/
복사<br>Info기본값은 백그라운드지만, 포그라운드를 만들어 놓은 이슈는<br>
프로그램 동작 확인과 종료를 쉽게 하기 위함이다.<br><br>nohup ./bin/zookeeper-server-start.sh config/zookeeper.properties &gt;/dev/null 2&gt;&amp;1 &amp;
복사<br>nohup ./bin/kafka-server-start.sh config/server.properties &gt;/dev/null 2&gt;&amp;1 &amp;
복사<br><br>nohup ./bin/zookeeper-server-start.sh config/zookeeper.properties &gt;/dev/null 2&gt;&amp;1
복사<br>nohup ./bin/kafka-server-start.sh config/server.properties &gt;/dev/null 2&gt;&amp;1
복사<br>netstat -ntlp | grep 2181
복사<br>netstat -ntlp | grep 9092
복사<br><br><a data-href="kafka error handling" href="root\dev\data-pipe-line\kafka\kafka-error-handling.html" class="internal-link" target="_self" rel="noopener">kafka error handling</a><br><br><br>nohup ./bin/zookeeper-server-start.sh config/zookeeper.properties &gt;/dev/null 2&gt;&amp;1 &amp;
복사<br>
<br>
nohup: 

<br>목적: 터미널을 닫아도 명령어가 계속 실행되게 해주는 명령어야.
<br>상세: 'no hang up'의 줄임말로, 보통 터미널을 닫으면 그 터미널에서 실행 중인 프로세스도 종료되는데, nohup을 사용하면 백그라운드에서 계속 실행돼.


<br>
./bin/zookeeper-server-start.sh config/zookeeper.properties:

<br>목적: 주키퍼 서버를 시작하는 스크립트야.
<br>상세: zookeeper-server-start.sh는 주키퍼 서버를 시작하는 스크립트 파일이고, config/zookeeper.properties는 주키퍼의 설정 파일이야. 이 파일에 주키퍼 서버 설정들이 담겨 있어.


<br>
&gt;/dev/null 2&gt;&amp;1:

<br>목적: 출력과 에러 메시지를 무시하고 버려.
<br>상세: 

<br>&gt;/dev/null: 표준 출력을 /dev/null로 보내서 출력 결과를 버려.
<br>2&gt;&amp;1: 표준 에러를 표준 출력으로 리다이렉트해. 따라서 표준 출력과 표준 에러 모두 /dev/null로 가서 결과적으로 아무 출력도 보이지 않게 돼.




<br>
&amp;:

<br>목적: 명령어를 백그라운드에서 실행해.
<br>상세: 이걸 붙이면 명령어가 백그라운드에서 실행돼서 터미널을 계속 사용할 수 있게 해줘.


<br>종합해보면, 이 명령어는 주키퍼 서버를 설정 파일을 기반으로 백그라운드에서 실행하면서 출력 결과와 에러 메시지를 모두 무시하는 거야.<br><br><br><br>cd ~/app/kafka/kafka_2.13-3.6.2

./bin/kafka-topics.sh --create --bootstrap-server 172.17.0.2:9092 --replication-factor 3 --partitions 3 --topic testtopic
복사<br>cd ~/app/kafka/kafka_2.13-3.6.2

./bin/kafka-console-producer.sh --bootstrap-server 172.17.0.2:9092 --topic testtopic
복사<br><br>cd ~/app/kafka/kafka_2.13-3.6.2

./bin/kafka-console-consumer.sh --bootstrap-server 172.17.0.3:9092 --topic testtopic --from-beginning
복사<br><br>cd ~/app/kafka/kafka_2.13-3.6.2

./bin/kafka-console-consumer.sh --bootstrap-server 172.17.0.4:9092 --topic testtopic --from-beginning
복사<br><br><br>pkill -f kafka
복사]]></description><link>root\dev\data-pipe-line\kafka\kafka-설정-및-실행.html</link><guid isPermaLink="false">root/dev/data pipe line/kafka/kafka 설정 및 실행.md</guid><pubDate>Sat, 03 Aug 2024 15:45:17 GMT</pubDate></item><item><title><![CDATA[kafka 설치]]></title><description><![CDATA[ 
 <br><br><br>docker 설치시멈추면 터미널 모두 끄고 설정 해주면 됨<br>sudo apt-get update
sudo apt-get install -y openjdk-17-jre-headless
복사<br><br>java -version
# openjdk version "17.0.11" 2024-04-16
복사<br><br><br>
<br>amd
<br>export JAVA_HOME=/usr/lib/jvm/java-1.17.0-openjdk-amd64
복사<br>
<br>arm (mac)
<br>export JAVA_HOME=/usr/lib/jvm/java-1.17.0-openjdk-arm64
복사<br><br>source .bashrc
exec $SHELL
복사<br><br><br><br>cd

mkdir app
cd app

mkdir kafka
cd kafka
복사<br><br>Attention버전이 안 맞으면<br>
<a rel="noopener" class="external-link" href="https://downloads.apache.org/kafka" target="_blank">https://downloads.apache.org/kafka</a><br>
여기서 다운<br>wget https://downloads.apache.org/kafka/3.6.2/kafka_2.13-3.6.2.tgz
복사<br><br>tar -xzf kafka_2.13-3.6.2.tgz
복사<br><a data-href="kafka 설정 및 실행" href="root\dev\data-pipe-line\kafka\kafka-설정-및-실행.html" class="internal-link" target="_self" rel="noopener">kafka 설정 및 실행</a>]]></description><link>root\dev\data-pipe-line\kafka\kafka-설치.html</link><guid isPermaLink="false">root/dev/data pipe line/kafka/kafka 설치.md</guid><pubDate>Wed, 31 Jul 2024 05:21:00 GMT</pubDate></item><item><title><![CDATA[kafka 클러스터 서버 시동]]></title><description><![CDATA[ 
 <br><br>확인
<br>server1 
<br>server2 
<br>server3
<br>~/run/ssh_check.sh
복사<br><br><br>시동
<br>server1 
<br>server2 
<br>server3
<br>~/run/kafka_zookeeper_start.sh
복사<br><br><br>시동
<br>server1 
<br>server2 
<br>server3
<br>~/run/kafka_server_start.sh
복사<br><br><br>cd ~/app/kafka/kafka_2.13-3.6.2
./bin/kafka-topics.sh --create --bootstrap-server 172.17.0.2:9092 --replication-factor 3 --partitions 3 --topic testtopic
복사<br><br><br>cd ~/app/kafka/kafka_2.13-3.6.2
./bin/kafka-topics.sh --bootstrap-server 172.17.0.2:9092 --describe --topic testtopic
복사<br><br><br>cd ~/app/kafka/kafka_2.13-3.6.2
./bin/kafka-console-producer.sh --bootstrap-server 172.17.0.2:9092 --topic testtopic
복사<br><br><br><br>cd ~/app/kafka/kafka_2.13-3.6.2
./bin/kafka-console-consumer.sh --bootstrap-server 172.17.0.2:9092 --topic testtopic
복사<br><br>cd ~/app/kafka/kafka_2.13-3.6.2
./bin/kafka-console-consumer.sh --bootstrap-server 172.17.0.3:9092 --topic testtopic
복사<br><br>cd ~/app/kafka/kafka_2.13-3.6.2
./bin/kafka-console-consumer.sh --bootstrap-server 172.17.0.4:9092 --topic testtopic
복사<br><br>cd ~/app/kafka/kafka_2.13-3.6.2
./bin/kafka-topics.sh --bootstrap-server 172.18.0.11:9092 --describe --topic testtopic

cd ~/app/kafka/kafka_2.13-3.6.2
./bin/kafka-console-producer.sh --bootstrap-server 172.18.0.11:9092 --topic testtopic


cd ~/app/kafka/kafka_2.13-3.6.2
./bin/kafka-console-consumer.sh --bootstrap-server 172.18.0.12:9092 --topic testtopic --from-beginning

cd ~/app/kafka/kafka_2.13-3.6.2
./bin/kafka-console-consumer.sh --bootstrap-server 172.18.0.13:9092 --topic testtopic --from-beginning
복사]]></description><link>root\dev\data-pipe-line\kafka\kafka-클러스터-서버-시동.html</link><guid isPermaLink="false">root/dev/data pipe line/kafka/kafka 클러스터 서버 시동.md</guid><pubDate>Mon, 05 Aug 2024 00:28:30 GMT</pubDate></item><item><title><![CDATA[Kafka Consumer와 MySQL에 데이터 적재하기]]></title><description><![CDATA[ 
 <br><br>Infocsv -&gt; python -&gt; kafka -&gt; mysql<br><br><br>pip install kafka-python pandas sqlalchemy pymysql
복사<br><br><br>vi kafka_consumer_mysql.py
복사<br>from kafka import KafkaProducer, KafkaConsumer
import pandas as pd
import json
from sqlalchemy import create_engine, Table, Column, MetaData, inspect
from sqlalchemy.types import String, BigInteger, Float, DateTime
import pymysql

CSV_DATA = 'data_mini.csv'

# 데이터베이스 연결 설정
DATABASE_USER = 'ubuntu'
DATABASE_PASSWORD = '1234'
DATABASE_HOST = 'localhost'
DATABASE_NAME = 'my_data'

# Kafka 설정
KAFKA_BOOTSTRAP_SERVERS = ['172.17.0.2:9092', '172.17.0.3:9092', '172.17.0.4:9092']
KAFKA_TOPIC = 'testtopic'
KAFKA_GROUP_ID = 'my-group'  # group_id 설정

# 데이터베이스 연결 함수
def create_database_if_not_exists():
	connection = pymysql.connect(
		host=DATABASE_HOST,
		user=DATABASE_USER,
		password=DATABASE_PASSWORD
	)
	try:
		with connection.cursor() as cursor:
			cursor.execute(f"CREATE DATABASE IF NOT EXISTS {DATABASE_NAME}")
	finally:
		connection.close()

# SQLAlchemy 데이터 타입 매핑 함수
def get_sqlalchemy_type(dtype):
	if pd.api.types.is_integer_dtype(dtype):
		return BigInteger
	elif pd.api.types.is_float_dtype(dtype):
		return Float
	elif pd.api.types.is_datetime64_any_dtype(dtype):
		return DateTime
	else:
		return String(length=255)

# 데이터베이스 및 테이블 설정
def setup_database_and_table(csv_path):
	engine = create_engine(f'mysql+pymysql://{DATABASE_USER}:{DATABASE_PASSWORD}@{DATABASE_HOST}/{DATABASE_NAME}')
	
	df = pd.read_csv(csv_path)
	
	metadata = MetaData()
	
	columns = [Column(col, get_sqlalchemy_type(df[col].dtype)) for col in df.columns]
	table = Table('test_a', metadata, *columns)
	
	inspector = inspect(engine)
	if not inspector.has_table('test_a'):
		metadata.create_all(engine)
		print(f"Table 'test_a' created successfully from CSV file.")
	else:
		print(f"Table 'test_a' already exists.")

def produce_csv_to_kafka(file_path, topic):
	data = pd.read_csv(file_path)
	producer = KafkaProducer(
		bootstrap_servers=KAFKA_BOOTSTRAP_SERVERS,
		value_serializer=lambda v: json.dumps(v).encode('utf-8')
	)
	
	for _, row in data.iterrows():
		message = row.to_dict()
		producer.send(topic, value=message)
	producer.flush()
	producer.close()
	print("CSV 데이터를 Kafka에 게시 완료.")

def load_data_to_mysql(data):
	engine = create_engine(f'mysql+pymysql://{DATABASE_USER}:{DATABASE_PASSWORD}@{DATABASE_HOST}/{DATABASE_NAME}')
	df = pd.DataFrame(data)
	df.to_sql('test_a', engine, if_exists='append', index=False)

consumer = KafkaConsumer(
	KAFKA_TOPIC,
	bootstrap_servers=KAFKA_BOOTSTRAP_SERVERS,
	auto_offset_reset='earliest',
	enable_auto_commit=False,
	group_id=KAFKA_GROUP_ID,  # group_id 추가
	value_deserializer=lambda x: json.loads(x.decode('utf-8'))
)

create_database_if_not_exists()
setup_database_and_table(CSV_DATA)

produce_csv_to_kafka(CSV_DATA, KAFKA_TOPIC)

data_buffer = []
buffer_limit = 100
timeout_ms = 500  # 5초 동안 새로운 메시지가 없으면 타임아웃

while True:
	message_pack = consumer.poll(timeout_ms=timeout_ms)
	
	if not message_pack:
		break
	
	for tp, messages in message_pack.items():
		for message in messages:
			data_buffer.append(message.value)
			
			if len(data_buffer) &gt;= buffer_limit:
				load_data_to_mysql(data_buffer)
				data_buffer = []
				consumer.commit()

if data_buffer:
	load_data_to_mysql(data_buffer)
	consumer.commit()

consumer.close()

print("Kafka에서 MySQL로 데이터 적재 완료.")

Run복사<br><br><br>
<br>
Kafka Consumer 설정:

<br>KafkaConsumer를 사용하여 지정된 토픽(my_topic)에서 메시지를 소비합니다.
<br>bootstrap_servers에는 Kafka 클러스터의 브로커 주소를 지정합니다.


<br>
MySQL 데이터베이스와 테이블 설정:

<br>데이터베이스와 테이블이 존재하지 않으면 새로 생성합니다.


<br>
데이터 적재 함수 (load_data_to_mysql):

<br>Kafka에서 받은 메시지를 pandas 데이터프레임으로 변환하고, to_sql 메서드를 사용하여 MySQL에 데이터를 적재합니다.
<br>if_exists='append' 옵션을 사용하여 기존 테이블에 데이터를 추가합니다.


<br>
Kafka에서 메시지 소비 및 MySQL에 적재:

<br>Kafka에서 메시지를 소비하여 data_buffer에 저장합니다.
<br>버퍼의 데이터 수가 일정 한도(buffer_limit)를 넘으면, load_data_to_mysql 함수를 호출하여 MySQL에 데이터를 적재합니다.
<br>버퍼가 비워진 후에도 데이터가 남아 있으면, 마지막으로 MySQL에 적재합니다.


<br><br>
<br>
데이터 변환: Kafka에서 받은 데이터는 JSON 형식으로 변환되므로, MySQL의 테이블 구조에 맞게 데이터 변환이 필요할 수 있습니다. 실제 환경에서는 데이터를 필터링하거나 변환할 필요가 있을 수 있습니다.

<br>
에러 처리: 실제 사용 시에는 예외 처리 및 로그 기록을 추가하여 오류를 모니터링하고 대응할 수 있습니다.

<br>
성능 고려: 데이터 적재 성능을 높이기 위해, 데이터 배치 처리(batch processing)나 병렬 처리를 고려할 수 있습니다.

<br>이 코드는 실시간으로 Kafka에서 데이터를 소비하고 MySQL에 적재할 수 있도록 설계되었으며, 데이터가 지속적으로 들어오는 환경에서 유용합니다.<br><br><br>Info데이터를 MySQL에 적재할 때, Kafka를 거치는 것과 직접 MySQL에 적재하는 것 사이에는 여러 가지 차이점과 고려할 사항이 있습니다. 아래에 각각의 방법이 데이터베이스에 미치는 영향과 안정성에 대해 비교하여 설명하겠습니다.<br><br>장점:<br>
<br>
내결함성 (Fault Tolerance):

<br>Kafka는 메시지의 내구성을 보장하고 데이터 복제를 통해 장애에 대비할 수 있습니다. Kafka에 데이터가 게시되면, Kafka는 이를 복제하고 유지하여 MySQL 데이터베이스가 다운되더라도 데이터 손실을 방지할 수 있습니다.


<br>
성능 향상 (Performance):

<br>Kafka는 데이터를 버퍼링하고, 배치로 처리하여 대량의 데이터를 효율적으로 처리합니다. 이로 인해 MySQL 데이터베이스에 직접적인 부하를 줄일 수 있습니다.


<br>
비동기 처리 (Asynchronous Processing):

<br>Kafka는 비동기 처리 모델을 사용하여 데이터 전송과 처리를 분리합니다. 이를 통해 데이터 수집과 처리의 병목 현상을 줄일 수 있습니다.


<br>
확장성 (Scalability):

<br>Kafka는 클러스터 기반으로 설계되어 데이터의 양이 증가하더라도 확장 가능성을 제공합니다. Kafka의 파티셔닝 및 복제 기능을 활용하여 데이터 처리량을 높일 수 있습니다.


<br>단점:<br>
<br>
복잡성 증가 (Increased Complexity):

<br>Kafka를 추가하면 시스템의 복잡성이 증가합니다. Kafka 브로커의 설정, 모니터링, 유지 관리가 필요합니다.


<br>
지연 (Latency):

<br>Kafka를 경유하면 데이터 전송에 약간의 지연이 있을 수 있습니다. 하지만 이는 일반적으로 성능 향상과 데이터 안정성을 고려할 때 감수할 수 있는 부분입니다.


<br><br>장점:<br>
<br>
간단한 아키텍처 (Simpler Architecture):

<br>Kafka를 사용하지 않으면 데이터 전송 경로가 간단해지며 시스템이 간결해집니다. 설정 및 유지 관리가 단순해질 수 있습니다.


<br>
즉각적인 데이터 적재 (Immediate Data Insertion):

<br>데이터가 직접적으로 MySQL에 적재되므로 지연이 적을 수 있습니다.


<br>단점:<br>
<br>
부하 (Load):

<br>MySQL에 직접적으로 데이터를 적재할 경우, 데이터베이스에 큰 부하를 줄 수 있습니다. 특히 대량의 데이터가 동시에 들어오면 MySQL의 성능이 저하될 수 있습니다.


<br>
내결함성 부족 (Lack of Fault Tolerance):

<br>MySQL에 직접 데이터를 적재하는 경우, 데이터베이스의 장애나 다운타임에 대한 대비책이 부족할 수 있습니다. 데이터 손실이나 서비스 중단의 위험이 존재합니다.


<br>
확장성 문제 (Scalability Issues):

<br>데이터량이 증가할수록 MySQL의 성능이 저하될 수 있으며, 클러스터를 사용하지 않는 경우 데이터베이스의 확장에 한계가 있을 수 있습니다.


<br>
동기 처리 (Synchronous Processing):

<br>데이터 적재가 동기식으로 처리되면 데이터베이스의 응답 시간과 부하에 영향을 받을 수 있습니다.


<br><br><br>
<br>
Kafka를 사용하는 경우: Kafka는 데이터의 내결함성과 확장성을 제공하며, 대량의 데이터를 처리할 때 안정성을 높입니다. MySQL에 대한 부하를 줄이고, 장애 발생 시 데이터 손실을 방지할 수 있습니다. Kafka는 비동기식 데이터 전송을 통해 성능을 향상시키지만, 시스템의 복잡성이 증가할 수 있습니다.

<br>
Kafka 없이 직접 MySQL에 적재하는 경우: 시스템이 간단해지고 즉각적인 데이터 적재가 가능하지만, 데이터베이스에 부하가 증가하고 내결함성과 확장성에 한계가 있을 수 있습니다. 특히 대량의 데이터가 있을 때 안정성 문제를 겪을 수 있습니다.

<br>따라서, 데이터의 양과 시스템의 요구 사항에 따라 적절한 접근 방식을 선택하는 것이 중요합니다. 대량의 데이터 처리와 높은 안정성이 필요하다면 Kafka를 사용하는 것이 좋습니다. 반면, 데이터량이 상대적으로 적고 시스템의 복잡성을 줄이려는 경우 직접 MySQL에 적재하는 것도 고려할 수 있습니다.]]></description><link>root\dev\data-pipe-line\kafka\kafka-consumer와-mysql에-데이터-적재하기.html</link><guid isPermaLink="false">root/dev/data pipe line/kafka/Kafka Consumer와 MySQL에 데이터 적재하기.md</guid><pubDate>Thu, 01 Aug 2024 06:38:42 GMT</pubDate></item><item><title><![CDATA[kafka error handling]]></title><description><![CDATA[ 
 <br><br><br>rm -rf /tmp/kafka-logs
복사<br><br>로그를 분석해보면, Kafka 서버가 시작 중에 InconsistentClusterIdException 오류를 발생시키며 종료되고 있습니다. 이 오류는 Kafka 클러스터의 ID가 meta.properties 파일에 저장된 클러스터 ID와 일치하지 않음을 나타냅니다. 구체적인 내용은 다음과 같습니다:<br>
<br>
오류 원인:

<br>InconsistentClusterIdException: 이 예외는 Kafka 브로커가 현재 연결된 ZooKeeper의 클러스터 ID와 meta.properties 파일에 저장된 클러스터 ID가 일치하지 않을 때 발생합니다. 현재의 클러스터 ID는 FGvt6oxDTaScq61Hj0FieQ인데, meta.properties에는 6NLjhRndTQW9WpESn_EiEw가 저장되어 있습니다.


<br>
문제 해결 방법:

<br>클러스터 ID 확인: ZooKeeper에 저장된 클러스터 ID와 meta.properties 파일의 클러스터 ID가 일치하는지 확인합니다. meta.properties 파일은 Kafka 데이터 디렉터리 (/tmp/kafka-logs 등)에 위치합니다.
<br>클러스터 재설정: 클러스터 ID 불일치 문제를 해결하기 위해, meta.properties 파일을 삭제하고 Kafka 브로커를 재시작하여 새로운 클러스터 ID를 생성할 수 있습니다. 주의: 이 작업은 클러스터의 상태를 초기화하게 되므로, 데이터 손실이 발생할 수 있습니다.
<br>ZooKeeper 설정 확인: zookeeper.connect 설정이 올바른지 확인합니다. 잘못된 ZooKeeper 주소가 설정되어 있을 경우 클러스터 ID 불일치 문제가 발생할 수 있습니다.


<br>
조치 사항:

<br>Kafka가 실행되고 있는 디렉토리에서 meta.properties 파일을 확인하거나 삭제합니다. Kafka가 올바르게 시작될 수 있도록, 필요한 경우 kafka-server-start.sh를 다시 실행합니다.
<br>ZooKeeper 설정이 올바른지 확인한 후, 브로커를 재시작하여 문제를 해결합니다.


<br>이러한 단계를 통해 문제를 해결할 수 있으며, 상황에 따라 클러스터 설정을 재검토하거나 Kafka 및 ZooKeeper를 재설치해야 할 수도 있습니다.]]></description><link>root\dev\data-pipe-line\kafka\kafka-error-handling.html</link><guid isPermaLink="false">root/dev/data pipe line/kafka/kafka error handling.md</guid><pubDate>Sat, 27 Jul 2024 09:06:31 GMT</pubDate></item><item><title><![CDATA[kafka note]]></title><description><![CDATA[ 
 <br>bin/kafka-broker-api-versions.sh --bootstrap-server 172.31.6.227:9092
복사<br><br><br>./bin/kafka-topics.sh --create --bootstrap-server 172.31.6.227:9092 --replication-factor 3 --partitions 3 --topic testtopic
복사<br>./bin/kafka-topics.sh --bootstrap-server 172.31.6.227:9092 --describe --topic testtopic
복사<br><br><br>./bin/kafka-console-producer.sh --bootstrap-server 172.31.6.227:9092 --topic testtopic
복사<br><br>./bin/kafkaconsole-consumer.sh --bootstrap-server 172.31.14.208:9092 --topic testtopic --from-beginning
복사<br><br>./bin/kafkaconsole-consumer.sh --bootstrap-server 172.31.1.189:9092 --topic testtopic --from-beginning
복사<br><br><br><br>Kafka의 명령줄 도구를 사용하여 특정 토픽의 데이터를 확인할 수 있습니다. <br><br>kafka-console-consumer는 Kafka 토픽에서 메시지를 소비하고 출력하는 명령줄 도구입니다. 이 도구를 사용하여 실시간으로 데이터가 올라와 있는지 확인할 수 있습니다.<br>kafka-console-consumer --bootstrap-server localhost:9092 --topic my_topic --from-beginning
복사<br>./bin/kafka-console-consumer.sh --bootstrap-server 172.17.0.4:9092 --topic my_topi --from-beginning
복사<br>
<br>--bootstrap-server: Kafka 클러스터의 브로커 주소를 지정합니다.
<br>--topic: 데이터를 확인할 토픽의 이름을 지정합니다.
<br>--from-beginning: 토픽의 시작부터 메시지를 소비합니다. 이 옵션을 생략하면, 현재로부터 새로운 메시지만 소비합니다.
<br>이 명령을 실행하면 해당 토픽에 올라와 있는 메시지가 콘솔에 출력됩니다.<br><br>토픽의 메타데이터나 메시지 수를 확인할 수 있습니다.<br>kafka-topics --bootstrap-server.sh localhost:9092 --describe --topic my_topic
복사<br>./bin/kafka-topics --bootstrap-server.sh 172.17.0.4:9092 --describe --topic my_topic
복사<br>이 명령은 지정한 토픽의 파티션과 리더 상태, 오프셋 정보를 출력합니다. 이 정보를 통해 토픽의 상태를 확인할 수 있습니다.<br><br>Kafka 클라이언트 라이브러리를 사용하여 프로그래밍적으로 토픽의 데이터를 조회할 수도 있습니다. 다음은 Python을 사용한 예제입니다.<br><br>from kafka import KafkaConsumer

# Kafka Consumer 설정
consumer = KafkaConsumer(
    'my_topic',
    bootstrap_servers=['localhost:9092'],
    auto_offset_reset='earliest',
    enable_auto_commit=True,
    value_deserializer=lambda x: x.decode('utf-8')
)

# 메시지 출력
for message in consumer:
    print(f"Key: {message.key}, Value: {message.value}")
    # 특정 조건에서 루프를 종료하려면 추가 로직을 구현
    break  # 이 예제에서는 첫 번째 메시지 하나만 출력 후 종료
Run복사<br>이 코드는 my_topic 토픽에서 메시지를 소비하고 출력합니다. auto_offset_reset='earliest'를 설정하면 토픽의 처음부터 메시지를 읽습니다.<br><br>Kafka의 웹 기반 UI 도구를 사용하여 토픽의 데이터와 상태를 시각적으로 확인할 수 있습니다. 이러한 도구로는 다음과 같은 것들이 있습니다:<br>
<br><a data-tooltip-position="top" aria-label="https://docs.confluent.io/platform/current/control-center/index.html" rel="noopener" class="external-link" href="https://docs.confluent.io/platform/current/control-center/index.html" target="_blank">Confluent Control Center</a>: Confluent Platform의 일부로 제공되며, Kafka 클러스터를 모니터링하고 관리할 수 있습니다.
<br><a data-tooltip-position="top" aria-label="https://github.com/obsidiandynamics/kafdrop" rel="noopener" class="external-link" href="https://github.com/obsidiandynamics/kafdrop" target="_blank">Kafdrop</a>: Kafka 브로커와 토픽을 시각적으로 확인할 수 있는 오픈소스 웹 UI 도구입니다.
<br>이 도구들은 Kafka 클러스터의 상태를 모니터링하고, 토픽의 메시지를 조회하는 데 유용합니다.<br><br>
<br>명령줄 도구: kafka-console-consumer를 사용하여 실시간으로 토픽의 데이터를 확인할 수 있습니다.
<br>클라이언트 라이브러리: Python 등에서 Kafka 클라이언트를 사용하여 프로그램적으로 데이터를 조회할 수 있습니다.
<br>웹 UI 도구: Confluent Control Center나 Kafdrop 등의 도구를 사용하여 시각적으로 Kafka 클러스터와 토픽의 상태를 확인할 수 있습니다.
<br>이 방법들을 사용하여 Kafka에 데이터가 제대로 올라와 있는지 확인할 수 있습니다.<br><br><br>
<br>
토픽의 데이터 유지:

<br>Kafka는 메시지를 토픽에 저장하고, 이 메시지는 기본적으로 삭제되지 않고 계속 유지됩니다. --from-beginning 옵션을 사용하면 토픽의 시작부터 모든 메시지를 읽게 됩니다.


<br>
오프셋 관리:

<br>Kafka는 메시지의 위치를 오프셋(offset)이라는 숫자로 관리합니다. --from-beginning을 사용하면, 소비자가 현재 오프셋이 아닌, 토픽의 시작부터 모든 메시지를 읽기 시작합니다. 
<br>만약 소비자가 처음으로 메시지를 읽는 것이라면, 메시지의 시작부터 읽게 되며, 이전에 작성된 메시지도 모두 포함됩니다.


<br>
소비자 그룹 상태:

<br>만약 특정 소비자 그룹이 이미 존재하고 그 그룹이 저장된 오프셋이 있으면, --from-beginning 옵션을 사용하더라도 해당 소비자 그룹의 저장된 오프셋이 무시되고 시작부터 모든 메시지를 읽게 됩니다.
<br>새로운 소비자 그룹을 사용하거나, 기존 소비자 그룹의 오프셋이 초기화된 경우에도 동일한 결과를 얻을 수 있습니다.


<br>예시:<br>
<br>kafka-console-consumer.sh --bootstrap-server 172.17.0.2:9092 --topic my_topic --from-beginning 명령어를 실행하면, my_topic에서 생성된 모든 메시지를 토픽의 시작부터 현재까지 읽어오게 됩니다.
<br>이 옵션을 사용하지 않으면, 소비자는 마지막으로 읽은 지점부터 새로운 메시지만 읽어오게 됩니다. 만약 이전 메시지들만 읽고 싶지 않다면 --from-beginning 옵션을 제거하고 명령어를 실행하세요:<br>kafka-console-consumer.sh --bootstrap-server 172.17.0.2:9092 --topic my_topic
복사<br>이렇게 하면, 해당 토픽에서 새로 생성된 메시지만을 실시간으로 소비하게 됩니다.]]></description><link>root\dev\data-pipe-line\kafka\kafka-note.html</link><guid isPermaLink="false">root/dev/data pipe line/kafka/kafka note.md</guid><pubDate>Sat, 03 Aug 2024 15:37:04 GMT</pubDate></item><item><title><![CDATA[kafka server.properties]]></title><description><![CDATA[ 
 <br># Licensed to the Apache Software Foundation (ASF) under one or more
# contributor license agreements.  See the NOTICE file distributed with
# this work for additional information regarding copyright ownership.
# The ASF licenses this file to You under the Apache License, Version 2.0
# (the "License"); you may not use this file except in compliance with
# the License.  You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

#
# This configuration file is intended for use in ZK-based mode, where Apache ZooKeeper is required.
# See kafka.server.KafkaConfig for additional details and defaults
#

############################# Server Basics #############################

# The id of the broker. This must be set to a unique integer for each broker.
broker.id=1

############################# Socket Server Settings #############################

# The address the socket server listens on. If not configured, the host name will be equal to the value of
# java.net.InetAddress.getCanonicalHostName(), with PLAINTEXT listener name, and port 9092.
#   FORMAT:
#     listeners = listener_name://host_name:port
#   EXAMPLE:
#     listeners = PLAINTEXT://your.host.name:9092
#listeners=PLAINTEXT://:9092
listeners=PLAINTEXT://172.17.0.2:9092
# ubuntu@ip-172-31-6-227:~/app/kafka/kafka_2.13-3.6.1/config$

# Listener name, hostname and port the broker will advertise to clients.
# If not set, it uses the value for "listeners".
advertised.listeners=PLAINTEXT://172.17.0.2:9092

# Maps listener names to security protocols, the default is for them to be the same. See the config documentation for more details
#listener.security.protocol.map=PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL

# The number of threads that the server uses for receiving requests from the network and sending responses to the network
num.network.threads=3

# The number of threads that the server uses for processing requests, which may include disk I/O
num.io.threads=8

# The send buffer (SO_SNDBUF) used by the socket server
socket.send.buffer.bytes=102400

# The receive buffer (SO_RCVBUF) used by the socket server
socket.receive.buffer.bytes=102400

# The maximum size of a request that the socket server will accept (protection against OOM)
socket.request.max.bytes=104857600


############################# Log Basics #############################

# A comma separated list of directories under which to store log files
log.dirs=/tmp/kafka-logs

# The default number of log partitions per topic. More partitions allow greater
# parallelism for consumption, but this will also result in more files across
# the brokers.
# num.partitions=1
num.partitions=3

# The number of threads per data directory to be used for log recovery at startup and flushing at shutdown.
# This value is recommended to be increased for installations with data dirs located in RAID array.
num.recovery.threads.per.data.dir=1

############################# Internal Topic Settings  #############################
# The replication factor for the group metadata internal topics "__consumer_offsets" and "__transaction_state"
# For anything other than development testing, a value greater than 1 is recommended to ensure availability such as 3.
offsets.topic.replication.factor=3
transaction.state.log.replication.factor=3
transaction.state.log.min.isr=3

############################# Log Flush Policy #############################

# Messages are immediately written to the filesystem but by default we only fsync() to sync
# the OS cache lazily. The following configurations control the flush of data to disk.
# There are a few important trade-offs here:
#    1. Durability: Unflushed data may be lost if you are not using replication.
#    2. Latency: Very large flush intervals may lead to latency spikes when the flush does occur as there will be a lot of data to flush.
#    3. Throughput: The flush is generally the most expensive operation, and a small flush interval may lead to excessive seeks.
# The settings below allow one to configure the flush policy to flush data after a period of time or
# every N messages (or both). This can be done globally and overridden on a per-topic basis.

# The number of messages to accept before forcing a flush of data to disk
#log.flush.interval.messages=10000

# The maximum amount of time a message can sit in a log before we force a flush
#log.flush.interval.ms=1000

############################# Log Retention Policy #############################

# The following configurations control the disposal of log segments. The policy can
# be set to delete segments after a period of time, or after a given size has accumulated.
# A segment will be deleted whenever *either* of these criteria are met. Deletion always happens
# from the end of the log.

# The minimum age of a log file to be eligible for deletion due to age
log.retention.hours=168

# A size-based retention policy for logs. Segments are pruned from the log unless the remaining
# segments drop below log.retention.bytes. Functions independently of log.retention.hours.
#log.retention.bytes=1073741824

# The maximum size of a log segment file. When this size is reached a new log segment will be created.
#log.segment.bytes=1073741824

# The interval at which log segments are checked to see if they can be deleted according
# to the retention policies
log.retention.check.interval.ms=300000

############################# Zookeeper #############################

# Zookeeper connection string (see zookeeper docs for details).
# This is a comma separated host:port pairs, each corresponding to a zk
# server. e.g. "127.0.0.1:3000,127.0.0.1:3001,127.0.0.1:3002".
# You can also append an optional chroot string to the urls to specify the
# root directory for all kafka znodes.
# zookeeper.connect=localhost:2181
zookeeper.connect=172.17.0.2:2181,172.17.0.3:2181,172.17.0.4:2181
# Timeout in ms for connecting to zookeeper
zookeeper.connection.timeout.ms=18000


############################# Group Coordinator Settings #############################

# The following configuration specifies the time, in milliseconds, that the GroupCoordinator will delay the initial consumer rebalance.
# The rebalance will be further delayed by the value of group.initial.rebalance.delay.ms as new members join the group, up to a maximum of max.poll.interval.ms.
# The default value for this is 3 seconds.
# We override this to 0 here as it makes for a better out-of-the-box experience for development and testing.
# However, in production environments the default value of 3 seconds is more suitable as this will help to avoid unnecessary, and potentially expensive, rebalances during application startup.
group.initial.rebalance.delay.ms=0
복사]]></description><link>root\dev\data-pipe-line\kafka\kafka-server.properties.html</link><guid isPermaLink="false">root/dev/data pipe line/kafka/kafka server.properties.md</guid><pubDate>Sun, 28 Jul 2024 12:21:49 GMT</pubDate></item><item><title><![CDATA[kafka에 csv로 데이터 흘리기]]></title><description><![CDATA[ 
 <br><br>Infocsv -&gt; python -&gt; kafka<br><br><br>pip install kafka-python pandas
복사<br><br><br>vi csv_to_kafka.py
복사<br>from kafka import KafkaProducer
import pandas as pd
import json

def produce_csv_to_kafka(file_path, topic):
	# CSV 데이터 읽기
	data = pd.read_csv(file_path)

	# Kafka 프로듀서 설정 (클러스터 환경)
	producer = KafkaProducer(
		bootstrap_servers=['172.17.0.2:9092', '172.17.0.3:9092', '172.17.0.4:9092'],
		value_serializer=lambda v: json.dumps(v).encode('utf-8')
	)

	# 각 행을 Kafka 메시지로 게시
	for _, row in data.iterrows():
		message = row.to_dict()
		producer.send(topic, value=message)

	producer.flush()
	print("Kafka에 CSV 데이터 게시 완료.")

# CSV 파일 경로와 Kafka 토픽 설정
csv_file_path = 'data.csv'
produce_csv_to_kafka(csv_file_path, 'my_topic')
Run복사<br><br><br>
<br>CSV 데이터 읽기: pandas 라이브러리를 사용하여 CSV 파일을 읽습니다.
<br>Kafka 프로듀서 설정: 

<br>KafkaProducer를 사용하여 Kafka 클러스터에 데이터를 게시합니다.
<br>bootstrap_servers에는 Kafka 클러스터의 브로커 주소를 지정합니다.
<br>value_serializer를 사용하여 메시지 값을 JSON 형식으로 직렬화합니다.


<br>Kafka에 데이터 게시: 

<br>CSV 데이터프레임의 각 행을 row.to_dict()를 사용하여 딕셔너리 형태로 변환합니다.
<br>각 딕셔너리를 Kafka 메시지로 게시합니다.
<br>producer.flush()를 호출하여 모든 메시지가 Kafka에 전송되도록 합니다.


<br><br>
<br>데이터 형식: CSV 파일의 데이터 형식이 Kafka의 데이터 형식과 일치해야 합니다. 필요에 따라 데이터 변환이 필요할 수 있습니다.
<br>에러 처리: 실제 사용 시에는 예외 처리 및 로그 기록을 추가하여 오류를 모니터링하고 대응할 수 있습니다.
<br>성능 고려: 대량의 데이터를 처리하는 경우, 데이터를 배치로 처리하거나 병렬 처리를 고려하여 성능을 향상시킬 수 있습니다.
<br><br>이 코드는 CSV 파일을 읽어 Kafka에 데이터를 게시하는 기본적인 예시입니다. 실제 환경에서는 다음과 같은 추가 기능을 고려해야 할 수 있습니다.<br>
<br>데이터 필터링: 특정 조건을 만족하는 데이터만 Kafka에 게시합니다.
<br>데이터 변환: CSV 파일의 데이터 형식을 Kafka에 적합하게 변환합니다.
<br>데이터 압축: 데이터 크기를 줄이기 위해 데이터를 압축합니다.
<br>메시지 키 설정: Kafka의 파티셔닝을 위해 메시지 키를 설정합니다.
<br>메시지 타임스탬프 설정: 메시지의 타임스탬프를 설정하여 시간순으로 데이터를 처리합니다.
<br>데이터 유효성 검사: 데이터의 유효성을 검사하여 오류를 방지합니다.
<br>이 코드를 기반으로 필요한 추가 기능을 구현하여 CSV 파일에서 Kafka로 데이터를 효율적으로 전송할 수 있습니다. ]]></description><link>root\dev\data-pipe-line\kafka\kafka에-csv로-데이터-흘리기.html</link><guid isPermaLink="false">root/dev/data pipe line/kafka/kafka에 csv로 데이터 흘리기.md</guid><pubDate>Wed, 31 Jul 2024 06:16:05 GMT</pubDate></item><item><title><![CDATA[aws ec2에 docker로 kafka 클러스터 만들 때]]></title><description><![CDATA[ 
 <br>import sys, time
from pathlib import Path

base_dir = Path('/home/ubuntu/run')
sys.path.insert(0, str(base_dir))
from config.config import server_infos
from util.util import send_ssh_comm

ssh_key_dir = f"{base_dir}/config/keygen"
id_rsa_path = Path(ssh_key_dir) / "id_rsa"
id_rsa_pub_path = Path(ssh_key_dir) / "id_rsa.pub"

# ~/.ssh/config

ssh_config = '''
Host server1
	HostName 172.31.14.186
	Port 2222
	User ubuntu

Host server2
	HostName 172.31.10.99
	Port 2222
	User ubuntu

Host server3
	HostName 172.31.1.229
	Port 2222
	User ubuntu
'''

def get_create_container_comm(id, name, port=2222, server_infos=server_infos):
	with open(id_rsa_path, 'r') as id_rsa_file:
		id_rsa = id_rsa_file.read()
	
	with open(id_rsa_pub_path, 'r') as id_rsa_pub_file:
		id_rsa_pub = id_rsa_pub_file.read()
	print(id)
	return f'''
	docker network create --subnet=172.18.0.0/16 pipeline
	docker container run -itd \\
		--name {name} \\
		--hostname {name} \\
		--add-host {server_infos[0].name}:{server_infos[0].ip} \\
		--add-host {server_infos[1].name}:{server_infos[1].ip} \\
		--add-host {server_infos[2].name}:{server_infos[2].ip} \\
		-p {port}:{port} \\
		-p 2181:2181 \\
		-p 2888:2888 \\
		-p 3888:3888 \\
		-p 9092:9092 \\
		--net pipeline \\
		--ip 172.18.0.{id+10} \\
		namugach/ubuntu-pipeline:24.04-kafka-test \\
		/bin/bash -c "echo '{id_rsa}' &gt; /home/ubuntu/.ssh/id_rsa &amp;&amp; \\
				echo '{id_rsa_pub}' &gt; /home/ubuntu/.ssh/id_rsa.pub &amp;&amp; \\
				echo '{id_rsa_pub}' &gt; /home/ubuntu/.ssh/authorized_keys &amp;&amp; \\
				echo '{ssh_config}' &gt;&gt; /home/ubuntu/.ssh/config &amp;&amp; \\
				chmod 600 /home/ubuntu/.ssh/id_rsa &amp;&amp; \\
				chmod 644 /home/ubuntu/.ssh/id_rsa.pub &amp;&amp; \\
				sudo service ssh start &amp;&amp; \\
				sudo service mysql start &amp;&amp; \\
				tail -f /dev/null"
	'''

for info in server_infos:
	send_ssh_comm(info.name, info.name, get_create_container_comm(info.id, info.name))
	time.sleep(1)
Run복사<br><br>docker network create --subnet=172.18.0.0/16 pipeline
--ip 172.18.0.{id+10} \\
Run복사<br>이거 알아내려고.. 그랬다..]]></description><link>root\dev\data-pipe-line\server\ec2\aws-ec2에-docker로-kafka-클러스터-만들-때.html</link><guid isPermaLink="false">root/dev/data pipe line/server/ec2/aws ec2에 docker로 kafka 클러스터 만들 때.md</guid><pubDate>Sun, 04 Aug 2024 19:25:10 GMT</pubDate></item><item><title><![CDATA[ec2 docker ssh 터널링]]></title><description><![CDATA[ 
 <br>Attention보안에서 2222 포트 열어주면 됨<br># docker -&gt; ec2
ssh server1 -p 2222 -i ./ssh/id_rsa

# ec2 -&gt; docker
ssh server2 localhost -p 2222 -i ./ssh/id_rsa
복사<br>172.31.14.186 server1
172.31.10.99 server2
172.31.1.229 server3

docker run -d -p 22:22 --name my_ssh_container ubuntu:24.04


docker run -itd \
  --name docker_server \
  -p 22:22 \
  namugach/ubuntu-pipeline:24.04-kafka-test

docker run -itd \
  --name server2 \
  --hostname server2 \
  --add-host server1:172.31.14.186 \
  --add-host server2:172.31.10.99 \
  --add-host server3:172.31.1.229 \
  -p 2222:2222 \
  namugach/ubuntu-pipeline:24.04-kafka-test

docker run -itd \
  --name server3 \
  --hostname server3 \
  --add-host server1:172.31.14.186 \
  --add-host server2:172.31.10.99 \
  --add-host server3:172.31.1.229 \
  namugach/ubuntu-pipeline:24.04-kafka-test
복사]]></description><link>root\dev\data-pipe-line\server\ec2\ec2-docker-ssh-터널링.html</link><guid isPermaLink="false">root/dev/data pipe line/server/ec2/ec2 docker ssh 터널링.md</guid><pubDate>Sun, 04 Aug 2024 14:14:38 GMT</pubDate></item><item><title><![CDATA[ssh 포트 포함 이동]]></title><description><![CDATA[ 
 <br>/etc/hosts 파일에는 호스트 이름과 IP 주소의 매핑만을 설정할 수 있습니다. 포트 번호를 직접 지정할 수 있는 기능은 없습니다. ssh 명령어에서 포트 번호를 지정하려면 ssh 구성 파일을 사용하는 것이 일반적인 방법입니다.<br><br>SSH 구성 파일을 사용하여 특정 호스트에 대해 기본 포트 번호를 설정할 수 있습니다. ~/.ssh/config 파일에 다음과 같이 설정을 추가하면 됩니다:<br># ~/.ssh/config

Host server1
	HostName 172.31.14.186
	Port 2222
	User ubuntu

Host server2
	HostName 172.31.1.229
	Port 2222
	User ubuntu

Host server3
	HostName 172.31.10.99
	Port 2222
	User ubuntu
Run복사<br>이렇게 설정하면 ssh server1 명령어를 실행할 때 자동으로 -p 2222 옵션이 적용됩니다.<br><br>구성 파일을 설정한 후, send_ssh_comm 함수를 다음과 같이 사용할 수 있습니다:<br>import subprocess

def send_ssh_comm(host, name, comm):
	ssh_command = [
			'ssh',
			'-o', 'StrictHostKeyChecking=no',
			host, comm
	]
	print(f"=========={name} 실행...========")
	run = subprocess.run(ssh_command, capture_output=True, text=True)
	print(run.stdout)

# 사용 예시
send_ssh_comm('server1', '테스트 명령', 'echo Hello, World!')
Run복사<br>이렇게 하면 server1에 대해 ~/.ssh/config 파일에 정의된 설정이 자동으로 적용됩니다.<br><br>/etc/hosts 파일은 그대로 유지합니다:<br>172.31.14.186   server1
172.31.1.229    server2
172.31.10.99    server3
Run복사<br>이렇게 하면 server1, server2, server3에 대해 정의된 IP 주소가 호스트 이름으로 매핑됩니다.<br><br>import subprocess

def send_ssh_comm(host, name, comm):
	ssh_command = [
			'ssh',
			'-o', 'StrictHostKeyChecking=no',
			host, comm
	]
	print(f"=========={name} 실행...========")
	run = subprocess.run(ssh_command, capture_output=True, text=True)
	print(run.stdout)

# 사용 예시
send_ssh_comm('server1', '테스트 명령', 'echo Hello, World!')
send_ssh_comm('server2', '테스트 명령', 'echo Hello, World!')
send_ssh_comm('server3', '테스트 명령', 'echo Hello, World!')
Run복사<br>이렇게 하면 server1, server2, server3에 대해 정의된 포트 번호가 자동으로 적용됩니다.]]></description><link>root\dev\data-pipe-line\server\ec2\ssh-포트-포함-이동.html</link><guid isPermaLink="false">root/dev/data pipe line/server/ec2/ssh 포트 포함 이동.md</guid><pubDate>Sun, 04 Aug 2024 13:41:28 GMT</pubDate></item><item><title><![CDATA[ssh server 터널링]]></title><description><![CDATA[ 
 <br><br>nc -zv localhost 2181
nc -zv localhost 9092
복사<br><br><br># ZooKeeper 포트 포워딩
ssh -L 2181:localhost:2181 -N -f serverNumber

# Kafka 포트 포워딩
ssh -L 9092:localhost:9092 -N -f serverNumber
복사<br><br>ssh -L 2181:localhost:2181 -L 9092:localhost:9092 -N -f ubuntu@172.31.14.186

# ZooKeeper 포트 포워딩
ssh -L 2181:localhost:2181 -N -f server1

# Kafka 포트 포워딩
ssh -L 9092:localhost:9092 -N -f server1
복사<br><br>
ssh -L 2181:localhost:2181 -L 9092:localhost:9092 -N -f ubuntu@172.31.10.99 


# ZooKeeper 포트 포워딩
ssh -L 2181:localhost:2181 -N -f server2

# Kafka 포트 포워딩
ssh -L 9092:localhost:9092 -N -f server2
복사<br><br>ssh -L 2181:localhost:2181 -L 9092:localhost:9092 -N -f ubuntu@172.31.1.229


# ZooKeeper 포트 포워딩
ssh -L 2181:localhost:2181 -N -f server3

# Kafka 포트 포워딩
ssh -L 9092:localhost:9092 -N -f server3
복사]]></description><link>root\dev\data-pipe-line\server\ec2\ssh-server-터널링.html</link><guid isPermaLink="false">root/dev/data pipe line/server/ec2/ssh server 터널링.md</guid><pubDate>Sun, 04 Aug 2024 17:06:42 GMT</pubDate></item><item><title><![CDATA[우분투 hosts를 설정하여 ssh 편하게 이동하기]]></title><description><![CDATA[ 
 <br><br>sudo vi /etc/hosts
복사<br>ip_주소 사용하고_싶은_server_이름
복사<br>172.17.0.2 server1
172.17.0.3 server2
172.17.0.4 server3
복사<br><br><br><br>ssh-keygen -t rsa
복사<br>경고야!비번을 입력하지 않고 조건 없이 엔터<br><br>cd ~/.ssh/id_rsa.pub
복사<br>접속자의 pc에서 생성된 id_rsa.pub 를<br>vi ~/.ssh/authorized_keys
복사<br>touch ~/.ssh/authorized_keys
복사<br>접속할 pc의 authorized_keys안에 입력 한다.]]></description><link>root\dev\data-pipe-line\server\local\우분투-hosts를-설정하여-ssh-편하게-이동하기.html</link><guid isPermaLink="false">root/dev/data pipe line/server/local/우분투 hosts를 설정하여 ssh 편하게 이동하기.md</guid><pubDate>Sat, 27 Jul 2024 07:21:52 GMT</pubDate></item><item><title><![CDATA[우분투 sudo 비번 생략하기]]></title><description><![CDATA[ 
 <br>Attentionroot 계정으로 작업 해야함<br>echo '유저_이름 ALL=(ALL) NOPASSWD:ALL' &gt;&gt; /etc/sudoers
복사<br>echo 'ubuntu ALL=(ALL) NOPASSWD:ALL' &gt;&gt; /etc/sudoers
복사]]></description><link>root\dev\data-pipe-line\server\local\우분투-sudo-비번-생략하기.html</link><guid isPermaLink="false">root/dev/data pipe line/server/local/우분투 sudo 비번 생략하기.md</guid><pubDate>Sun, 28 Jul 2024 14:01:02 GMT</pubDate></item><item><title><![CDATA[docker container 시작 시 명령어 시작]]></title><description><![CDATA[ 
 <br>sudo 권한으로 실행하는 것들은 앞에 sudo를 붙여 줘야 함.<br>
그리고 계정이 sudo passwd 생략 할 수 있는 권한이 있어야 함
<a data-href="우분투 sudo 비번 생략하기" href="root\dev\data-pipe-line\server\local\우분투-sudo-비번-생략하기.html" class="internal-link" target="_self" rel="noopener">우분투 sudo 비번 생략하기</a><br>docker run -itd \
--name my_ssh_container \
root-ubuntu:24.01-mysql \
/bin/bash -c "sudo service ssh start &amp;&amp; tail -f /dev/null"
복사<br>docker run -itd --name my_ssh_container \
root-ubuntu:24.01-mysql \
/bin/bash -c "sudo service ssh start &amp;&amp; sudo service mysql start &amp;&amp; tail -f /dev/null"
복사<br>컨테이너가 바로 종료되는 이유는 -c "service ssh start &amp;&amp; bash" 명령어가 제대로 전달되지 않아서 bash가 실행되지 않기 때문이야. Docker에서는 CMD 명령어를 통해 전달되는 쉘 명령어를 실행할 때, -c 옵션을 사용하지 않아도 돼.<br>올바르게 실행하려면 다음과 같이 해봐:<br>docker run -itd --name my_ssh_container root-ubuntu:24.04-ssh-key /bin/bash -c "service ssh start &amp;&amp; tail -f /dev/null"
복사<br>여기서 tail -f /dev/null은 컨테이너가 백그라운드에서 계속 실행되도록 해주는 역할을 해. <br><br>
<br>docker run -itd: 백그라운드에서 인터랙티브 모드로 컨테이너 실행.
<br>--name my_ssh_container: 컨테이너 이름을 my_ssh_container로 설정.
<br>root-ubuntu:24.04-ssh-key: 사용할 Docker 이미지 이름.
<br>/bin/bash -c "service ssh start &amp;&amp; tail -f /dev/null": SSH 서비스를 시작하고, tail -f /dev/null 명령어를 실행해서 컨테이너가 계속 실행 상태를 유지하도록 함.
<br>이 명령어를 실행하면 SSH 서비스가 시작된 상태로 컨테이너가 계속 실행될 거야. 이제 컨테이너가 종료되지 않고, SSH 서버도 실행된 상태를 유지할 거야.]]></description><link>root\dev\data-pipe-line\server\local\docker-container-시작-시-명령어-시작.html</link><guid isPermaLink="false">root/dev/data pipe line/server/local/docker container 시작 시 명령어 시작.md</guid><pubDate>Sun, 28 Jul 2024 15:39:58 GMT</pubDate></item><item><title><![CDATA[Kafdrop kafka 클러스터 모니터링]]></title><description><![CDATA[ 
 <br>여러 브로커 서버가 있는 경우, KAFKA_BROKERCONNECT 환경 변수를 여러 브로커를 포함하도록 설정할 수 있습니다. Kafdrop은 이 변수를 통해 Kafka 클러스터의 브로커와 연결합니다. <br>브로커 서버가 server1, server2, server3에 위치하고 각각의 IP 주소가 172.17.0.2, 172.17.0.3, 172.17.0.4라면, 이를 다음과 같이 설정할 수 있습니다.<br><br>여러 브로커를 설정하려면 브로커 주소를 쉼표로 구분하여 KAFKA_BROKERCONNECT 환경 변수에 지정합니다.<br>docker run -d -p 9000:9000 \
  --add-host server1:172.17.0.2 \
  --add-host server2:172.17.0.3 \
  --add-host server3:172.17.0.4 \
  -e KAFKA_BROKERCONNECT=server1:9092,server2:9092,server3:9092 \
  obsidiandynamics/kafdrop
복사<br><br>컨테이너가 실행된 후 브라우저를 열고 다음 URL로 접속합니다.<br>http://localhost:9000
복사<br>http://172.17.0.2:9000
복사<br>이제 Kafdrop UI를 통해 Kafka 클러스터의 여러 브로커를 모니터링하고 관리할 수 있습니다.<br><br><br>브로커 서버가 Docker 컨테이너 내에서 실행되고 있다면, Docker 네트워크 설정이 올바르게 되어 있는지 확인해야 합니다. 브로커 컨테이너와 Kafdrop 컨테이너가 동일한 네트워크에 있어야 통신이 가능합니다.<br><br>위 예시에서는 브로커 호스트가 server1, server2, server3이고, 포트가 9092로 동일하다고 가정했습니다. 실제 환경에서는 호스트명과 포트 번호가 다를 수 있으니 환경에 맞게 수정하세요.<br><br>여러 Kafka 브로커를 사용하는 경우, Docker 명령어에서 --add-host 옵션을 사용해 브로커 호스트를 추가하고, KAFKA_BROKERCONNECT 환경 변수에 여러 브로커를 쉼표로 구분하여 설정합니다. 이를 통해 Kafdrop을 사용해 여러 브로커가 있는 Kafka 클러스터를 편리하게 관리할 수 있습니다.]]></description><link>root\dev\data-pipe-line\server\local\kafdrop-kafka-클러스터-모니터링.html</link><guid isPermaLink="false">root/dev/data pipe line/server/local/Kafdrop kafka 클러스터 모니터링.md</guid><pubDate>Sat, 03 Aug 2024 13:19:25 GMT</pubDate></item><item><title><![CDATA[ssh 접속시 yes 입력 생략하기]]></title><description><![CDATA[ 
 <br><br>SSH 서버에 처음 접속할 때 "yes"를 입력하는 과정은 서버의 호스트 키를 확인하고 저장하는 과정이야. 이 과정을 자동으로 생략하려면 StrictHostKeyChecking 옵션을 사용하면 돼.<br>다음과 같은 방법을 사용해봐:<br>
<br>명령어에 직접 추가하기:
<br>ssh -o StrictHostKeyChecking=no user@hostname
복사<br>
<br>SSH 설정 파일 수정하기:<br>
SSH 설정 파일인 ~/.ssh/config에 설정을 추가하면 매번 옵션을 입력하지 않아도 돼.
<br>
<br>설정 파일을 열고 (없으면 새로 만들면 돼):
<br>nano ~/.ssh/config
복사<br>
<br>다음 내용을 추가해:
<br>Host 172.*.*.*
 StrictHostKeyChecking no
 UserKnownHostsFile=/dev/null
복사<br>이렇게 하면 모든 호스트에 대해 호스트 키 확인을 하지 않게 돼.<br>주의: StrictHostKeyChecking=no 옵션을 사용하면 보안적으로 위험할 수 있어. 신뢰할 수 없는 서버에 접속할 때는 주의가 필요해. 가능한 경우, 초기 연결 시만 "yes"를 입력하고 나중에 설정 파일을 통해 관리하는 방법을 추천해.<br><br><br>맞아, SSH 설정 파일에 다음 내용을 추가하면 모든 호스트에 대해 StrictHostKeyChecking을 비활성화하고, 호스트 키를 known_hosts 파일에 저장하지 않게 설정할 수 있어. 이렇게 하면 SSH 접속 시 "yes"를 입력할 필요가 없어져.<br><br>
<br>
SSH 설정 파일 열기:
nano ~/.ssh/config
복사

<br>
다음 내용을 추가:
Host *
  StrictHostKeyChecking no
  UserKnownHostsFile=/dev/null
복사
위 설정은 모든 SSH 접속에 대해 적용되며, 특정 IP 범위에 대해서만 적용하고 싶다면 Host * 대신 특정 IP 패턴을 사용할 수 있어.

<br><br>만약 특정 IP 범위(예: 172.*.*.*)에만 적용하고 싶다면 다음과 같이 설정할 수 있어:<br>Host 172.*
  StrictHostKeyChecking no
  UserKnownHostsFile=/dev/null
복사<br><br>Host server*
  StrictHostKeyChecking no
  UserKnownHostsFile=/dev/null
복사<br>이렇게 하면 <br>ssh server1
ssh server2
ssh server3
복사<br>이렇게 모두 생략할 수 있다.]]></description><link>root\dev\data-pipe-line\server\local\ssh-접속시-yes-입력-생략하기.html</link><guid isPermaLink="false">root/dev/data pipe line/server/local/ssh 접속시 yes 입력 생략하기.md</guid><pubDate>Sat, 03 Aug 2024 15:52:13 GMT</pubDate></item><item><title><![CDATA[웹 브라우저에서 Kafka 클러스터를 모니터링]]></title><description><![CDATA[ 
 <br><br>
# Prometheus 실행
cd ~/app/prometheus-2.32.1.linux-amd64
./prometheus --config.file=prometheus.yml

# Kafka Exporter 실행
cd ~/app/kafka_exporter-1.4.2.linux-amd64
./kafka_exporter --kafka.server=172.17.0.2:9092

# grafana 실행
sudo grafana-server --homepath=/usr/share/grafana &amp;

복사<br><br><br>웹 브라우저에서 Kafka 클러스터를 모니터링하려면 Prometheus와 Grafana를 설치하고 설정한 다음, 웹 브라우저를 통해 Grafana 대시보드를 확인하면 돼. 여기서 그 과정을 단계별로 설명할게.<br><br>1.1. Prometheus 설치<br># Prometheus 다운로드
wget https://github.com/prometheus/prometheus/releases/download/v2.32.1/prometheus-2.32.1.linux-amd64.tar.gz

# 압축 해제
tar -xvf prometheus-2.32.1.linux-amd64.tar.gz
cd ~/app/prometheus-2.32.1.linux-amd64

# Prometheus 실행
./prometheus --config.file=prometheus.yml
복사<br>1.2. Prometheus 설정 파일(prometheus.yml)<br>prometheus.yml 파일을 다음과 같이 설정해:<br>global:
  scrape_interval: 15s

scrape_configs:
  - job_name: 'kafka'
    static_configs:
      - targets: ['localhost:9308'] # Kafka Exporter가 실행되는 호스트와 포트
복사<br><br>2.1. Kafka Exporter 설치<br># Kafka Exporter 다운로드
wget https://github.com/danielqsj/kafka_exporter/releases/download/v1.4.2/kafka_exporter-1.4.2.linux-amd64.tar.gz

# 압축 해제
tar -xvf kafka_exporter-1.4.2.linux-amd64.tar.gz
cd ~/app/kafka_exporter-1.4.2.linux-amd64

# Kafka Exporter 실행
./kafka_exporter --kafka.server=172.17.0.2:9092
복사<br><br>3.1. Grafana 설치<br># Grafana 다운로드 및 설치 (Ubuntu 예시)
sudo apt-get install -y software-properties-common
sudo add-apt-repository "deb https://packages.grafana.com/oss/deb stable main"
sudo apt-get update
sudo apt-get install -y grafana

# Grafana 실행
sudo systemctl start grafana-server
sudo systemctl enable grafana-server
복사<br><br>
<br>웹 브라우저에서 http://localhost:3000으로 이동해 Grafana에 로그인해. (기본 로그인: admin/admin)
<br>로그인을 완료한 후, 왼쪽 사이드바에서 "Add data source"를 클릭해.
<br>Prometheus를 선택해.
<br>Prometheus 설정 페이지에서 URL을 http://localhost:9090으로 설정하고 "Save &amp; Test"를 클릭해 연결을 확인해.
<br><br>
<br>Grafana 홈 화면에서 "Create" -&gt; "Import"를 클릭해.
<br>Import 페이지에서, Grafana Labs의 Kafka Exporter 대시보드 ID인 7589를 입력하고 "Load"를 클릭해.
<br>데이터를 입력하라는 창이 나타나면, "Prometheus" 데이터 소스를 선택해.
<br>"Import"를 클릭해 대시보드를 가져와.
<br><br>이제 웹 브라우저에서 http://localhost:3000으로 Grafana 웹 UI에 접속하면, Kafka 클러스터에 대한 다양한 모니터링 지표를 확인할 수 있는 대시보드를 볼 수 있을 거야.<br>이 과정에서 문제가 발생하면, 로그 파일을 확인하거나 설정 파일을 다시 검토해서 올바르게 설정되었는지 확인해봐. Prometheus와 Kafka Exporter, 그리고 Grafana가 제대로 설치되고 실행되어야만 모든 모니터링이 정상적으로 이루어질 거야.<br><br><br>네, 맞아. 컨테이너 내부에서 실행되는 서비스를 호스트 시스템에서 접근하려면 포트 포워딩이 필요해. 이걸 통해 컨테이너 내부의 포트를 호스트 시스템의 포트에 매핑할 수 있어. 그래서 호스트 시스템에서 localhost:3000으로 접근할 수 있게 돼.<br>포트 포워딩을 설정하지 않으면 컨테이너 내부의 서비스에 호스트 시스템에서 직접 접근할 수 없어. 예를 들어, Docker 컨테이너에서 Grafana를 실행하고 호스트 시스템에서 접근하려면 컨테이너를 시작할 때 -p 옵션을 사용해 포트를 매핑해야 해.<br>다시 정리해서 설명할게.<br><br>컨테이너를 시작할 때 포트 포워딩을 설정해서 다시 실행해 보자:<br><br>먼저, Ubuntu 컨테이너를 실행할 때 포트를 매핑해:<br>docker run -d -it --name monitoring-ubuntu -p 3000:3000 -p 9090:9090 -p 9308:9308 ubuntu
복사<br>이제 컨테이너에 접속해:<br>docker exec -it monitoring-ubuntu bash
복사<br><br>컨테이너 내부에서 필요한 패키지를 설치해:<br>apt-get update
apt-get install -y wget gnupg2 curl
복사<br><br># Prometheus 다운로드 및 압축 해제
wget https://github.com/prometheus/prometheus/releases/download/v2.32.1/prometheus-2.32.1.linux-amd64.tar.gz
tar -xvf prometheus-2.32.1.linux-amd64.tar.gz
mv prometheus-2.32.1.linux-amd64 /opt/prometheus

# Prometheus 설정 파일 작성
mkdir /opt/prometheus/config

cat &lt;&lt;EOF &gt; /opt/prometheus/config/prometheus.yml
global:
  scrape_interval: 15s

scrape_configs:
  - job_name: 'kafka'
    static_configs:
      - targets: ['localhost:9308']
EOF

# Prometheus 실행
/opt/prometheus/prometheus --config.file=/opt/prometheus/config/prometheus.yml &amp;
복사<br><br># Kafka Exporter 다운로드 및 압축 해제
wget https://github.com/danielqsj/kafka_exporter/releases/download/v1.4.2/kafka_exporter-1.4.2.linux-amd64.tar.gz
tar -xvf kafka_exporter-1.4.2.linux-amd64.tar.gz
mv kafka_exporter-1.4.2.linux-amd64 /opt/kafka_exporter

# Kafka Exporter 실행
/opt/kafka_exporter/kafka_exporter --kafka.server=localhost:9092 &amp;
복사<br><br>설치할 때!su root
복사
해서 root로 접속해서 설치해야함!<br>Grafana의 GPG 키를 추가하고 APT 소스 리스트에 Grafana 저장소를 추가해:<br># Grafana의 GPG 키 추가
wget -q -O - https://packages.grafana.com/gpg.key | apt-key add -

# Grafana 저장소 추가
add-apt-repository "deb https://packages.grafana.com/oss/deb stable main"

# 패키지 리스트 업데이트 및 Grafana 설치
apt-get update
apt-get install -y grafana
복사<br>Grafana를 설치하고 서비스로 실행해:<br># Grafana 실행
grafana-server --homepath=/usr/share/grafana &amp;
복사<br><br>컨테이너 내부에서 Grafana 서버가 실행되면, 호스트 시스템의 웹 브라우저에서 http://localhost:3000으로 접속할 수 있어. 이후 절차는 다음과 같아:<br>
<br>웹 브라우저에서 http://localhost:3000으로 이동해 Grafana에 로그인해. (기본 로그인: admin/admin)
<br>로그인을 완료한 후, 왼쪽 사이드바에서 "Add data source"를 클릭해.
<br>Prometheus를 선택해.
<br>Prometheus 설정 페이지에서 URL을 http://localhost:9090으로 설정하고 "Save &amp; Test"를 클릭해 연결을 확인해.
<br>Grafana 홈 화면에서 "Create" -&gt; "Import"를 클릭해.
<br>Import 페이지에서, Grafana Labs의 Kafka Exporter 대시보드 ID인 7589를 입력하고 "Load"를 클릭해.
<br>데이터를 입력하라는 창이 나타나면, "Prometheus" 데이터 소스를 선택해.
<br>"Import"를 클릭해 대시보드를 가져와.
<br>이제 호스트 시스템의 웹 브라우저에서 http://localhost:3000으로 Grafana 웹 UI에 접속하면, Kafka 클러스터에 대한 다양한 모니터링 지표를 확인할 수 있어.]]></description><link>root\dev\data-pipe-line\server\웹-브라우저에서-kafka-클러스터를-모니터링.html</link><guid isPermaLink="false">root/dev/data pipe line/server/웹 브라우저에서 Kafka 클러스터를 모니터링.md</guid><pubDate>Sat, 03 Aug 2024 08:44:25 GMT</pubDate></item><item><title><![CDATA[docker 우분투 mysql 설치]]></title><description><![CDATA[ 
 <br><a rel="noopener" class="external-link" href="https://jongsky.tistory.com/79" target="_blank">https://jongsky.tistory.com/79</a><br><br>sudo apt-get update
sudo apt-get -y install mysql-server
복사<br>음...?ubuntu 계정의 sudo 패스워드를 패스 하는 권한을 줘서 그런지<br>
설치하고 나면 shell로 나와야 하는데
done!
update-alternatives: using /var/lib/mecab/dic/ipadic-utf8 to provide /var/lib/mecab/dic/debian (mecab-dictionary) in auto mode
Setting up libhtml-parser-perl:amd64 (3.81-1build3) ...
Setting up libhttp-message-perl (6.45-1ubuntu1) ...
Setting up mysql-server-8.0 (8.0.37-0ubuntu0.24.04.1) ...
debconf: unable to initialize frontend: Dialog
debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 79.)
debconf: falling back to frontend: Readline
invoke-rc.d: could not determine current runlevel
invoke-rc.d: policy-rc.d denied execution of stop.
update-alternatives: using /etc/mysql/mysql.cnf to provide /etc/mysql/my.cnf (my.cnf) in auto mode
Renaming removed key_buffer and myisam-recover options (if present)
mysqld will log errors to /var/log/mysql/error.log
mysqld is running as pid 2171
복사
이렇게 뜨고, shell이 멈춤<br>
ctrl + c 로 캔슬로 안되고..
나갔다 들어오면 잘 되긴 함.<br><br><br>sudo service mysql start
복사<br><br><br><a data-href="mysql 계정 생성시 %의 의미" href="root\dev\data-pipe-line\server\local\mysql-계정-생성시-의-의미.html" class="internal-link" target="_self" rel="noopener">mysql 계정 생성시 %의 의미</a><br><br>sudo mysql -u root
복사<br><br>CREATE USER 'ubuntu'@'%' IDENTIFIED BY '1234';
복사<br>계정이 존재 하면 아래의 것으로 비번을 초기화 함ALTER USER 'ubuntu'@'%' IDENTIFIED BY '1234';
Run복사<br><br>GRANT ALL PRIVILEGES ON *.* TO 'ubuntu'@'%' WITH GRANT OPTION;
복사<br><br>FLUSH PRIVILEGES;
복사<br><br>exit
복사<br><br><br><br>sudo chown -R mysql:mysql /var/run/mysqld
sudo chmod 755 /var/run/mysqld
복사<br><br><br>
<br>열기
<br>sudo vi /etc/mysql/mysql.conf.d/mysqld.cnf
복사<br>
<br>편집
<br>port                    = 3306
bind-address            = 0.0.0.0
복사<br><br>sudo service mysql restart
복사<br><br>
<br>입력
<br>sudo service --status-all
복사<br>
<br>출력
<br> [ - ]  dbus
 [ + ]  mysql
 [ - ]  procps
 [ - ]  ssh
 [ - ]  x11-common
복사<br><br>mysql -u ubuntu -p -h 자신의_아이피_주소
복사<br>
<br>ex
<br>mysql -u ubuntu -p -h 172.17.0.3
복사<br>Important테스트를 할 때, 설정을 한, 본 서버에서 접속이 된다면<br>
타 서버에서도 접속 가능.]]></description><link>root\dev\data-pipe-line\server\docker-우분투-mysql-설치.html</link><guid isPermaLink="false">root/dev/data pipe line/server/docker 우분투 mysql 설치.md</guid><pubDate>Wed, 31 Jul 2024 05:11:41 GMT</pubDate></item><item><title><![CDATA[Docker 태그 없는 이미지 삭제하기]]></title><description><![CDATA[ 
 <br><br>Docker 명령어를 사용해서 태그가 없는 이미지(즉, &lt;none&gt;으로 표시된 이미지)를 제거할 수 있어. 주로 사용되는 명령어는 docker image prune이야. 이 명령어는 사용하지 않는(dangling) 이미지를 삭제해줘.<br>먼저, 모든 사용하지 않는 이미지를 정리하고 싶으면 다음 명령어를 사용할 수 있어:<br>docker image prune -a
복사<br>하지만 이 명령어는 태그가 있는 사용되지 않는 이미지도 삭제하니까 주의해야 해.<br>만약 태그가 없는 이미지들만 정리하고 싶다면, 다음 명령어를 사용하면 돼:<br>docker images purge $(docker images -f "dangling=true" -q)
복사<br>위 명령어들은 아래와 같은 상황에서 실행될 수 있어:<br>
<br>모든 사용하지 않는 이미지(태그 있는 것과 없는 것 모두)를 삭제하고 싶을 때:
<br>docker image prune -a
복사<br>
<br>태그가 없는 이미지들만 삭제하고 싶을 때:
<br>docker image prune
복사<br>위 명령어들을 실행하면 이미지를 정리할 수 있어. 정리한 후 다시 이미지를 확인하고 싶으면 docker image ls -a를 다시 실행하면 돼.<br><br><br>태그 없는 이미지들을 삭제할 때, 그 이미지들이 다른 이미지의 기반이 되는 경우 영향을 미칠 수 있어. 다만, Docker는 기본적으로 실제로 사용되고 있는 이미지를 삭제하지 않기 때문에, 태그가 없는 이미지 중에서도 다른 이미지들이 의존하는 경우에는 삭제되지 않아.<br>안전하게 태그 없는 이미지를 삭제하기 위해 docker image prune 명령어를 사용하면 돼. 이 명령어는 사용되지 않는(dangling) 이미지들만 삭제하기 때문에, 다른 이미지에 영향을 주지 않아.<br>docker image prune
복사<br>이 명령어는 태그가 없는 사용되지 않는 이미지들만 삭제해.<br>만약 정말로 태그가 없는 이미지들이 사용 중인지 확인하고 싶다면, 아래 명령어로 확인할 수 있어:<br>docker images -f "dangling=true"
복사<br>이 명령어는 태그가 없는 이미지들만 표시해줘. 그리고 나서 안전하게 삭제할 수 있어.<br>마지막으로, 이미지 간의 의존성을 파악하기 위해선 docker image inspect 명령어를 사용할 수 있어:<br>docker image inspect &lt;IMAGE_ID&gt;
복사<br>이 명령어로 특정 이미지의 상세 정보를 확인할 수 있어. 이를 통해 이미지 간의 관계를 이해하고 삭제 여부를 결정할 수 있어.<br><br>의존성이 있는 이미지를 다룰 때는 신중해야 해. 이미지 간의 의존성을 확인하고 적절하게 처리하기 위한 몇 가지 방법이 있어.<br>
<br>의존성 확인:<br>
docker image inspect 명령어를 사용해서 이미지의 상세 정보를 확인하고, 이미지 간의 의존성을 파악해. 예를 들어, 특정 이미지의 부모 이미지가 무엇인지 확인할 수 있어.
<br>docker image inspect &lt;IMAGE_ID&gt;
복사<br>
<br>이미지 태그 변경:<br>
만약 특정 이미지가 다른 이미지에 의존하고 있고 태그가 없는 경우, 의존성 문제를 피하기 위해 태그를 추가해. 
<br>docker tag &lt;IMAGE_ID&gt; &lt;new_tag&gt;
복사<br>
<br>필요 없는 이미지 삭제:<br>
의존성이 없는 태그가 없는 이미지들을 안전하게 삭제하기 위해 docker image prune 명령어를 사용해.
<br>docker image prune
복사<br>이 명령어는 다른 이미지에 의존하지 않는 사용되지 않는(dangling) 이미지만 삭제해.<br>
<br>필요한 이미지 백업:<br>
의존성이 있는 이미지라도 삭제가 필요한 경우, 이미지를 백업한 후 삭제할 수 있어. 이미지를 백업하려면 docker save 명령어를 사용해.
<br>docker save -o &lt;output_file.tar&gt; &lt;IMAGE_ID&gt;
복사<br>백업 후 필요 시 docker load 명령어로 이미지를 복원할 수 있어.<br>docker load -i &lt;output_file.tar&gt;
복사<br>
<br>이미지 정리 후 확인:<br>
이미지를 삭제하거나 정리한 후, 다시 이미지 리스트를 확인하고 의도치 않은 이미지 삭제가 없는지 확인해.
<br>docker image ls -a
복사<br>요약하자면, 의존성이 있는 이미지를 처리하기 전에 반드시 의존성을 확인하고, 필요 시 태그를 변경하거나 백업을 진행한 후 안전하게 삭제해.]]></description><link>root\dev\data-pipe-line\server\docker-태그-없는-이미지-삭제하기.html</link><guid isPermaLink="false">root/dev/data pipe line/server/Docker 태그 없는 이미지 삭제하기.md</guid><pubDate>Sat, 03 Aug 2024 09:03:29 GMT</pubDate></item><item><title><![CDATA[pyenv 설치]]></title><description><![CDATA[ 
 <br><br><br>sudo apt-get update
sudo apt-get install locales
sudo locale-gen en_US.UTF-8
export LANG=en_US.UTF-8
export LC_ALL=en_US.UTF-8
echo 'export LANG=en_US.UTF-8' &gt;&gt; ~/.bashrc
echo 'export LC_ALL=en_US.UTF-8' &gt;&gt; ~/.bashrc
source ~/.bashrc
복사<br>너무나 중요!!초기 설정을 모두 끝낸 후 터미널 재시작!!<br><br>exit
복사<br><br><br>sudo apt-get update; sudo apt-get -y install make build-essential libssl-dev zlib1g-dev libbz2-dev libreadline-dev libsqlite3-dev wget curl llvm libncursesw5-dev xz-utils tk-dev libxml2-dev libxmlsec1-dev libffi-dev liblzma-dev
복사<br><br><br>curl https://pyenv.run | bash
복사<br><br><br>vi ~/.bashrc
복사<br>export PYENV_ROOT="$HOME/.pyenv"
[[ -d $PYENV_ROOT/bin ]] &amp;&amp; export PATH="$PYENV_ROOT/bin:$PATH"
eval "$(pyenv init -)"
eval "$(pyenv virtualenv-init -)"
복사<br>Info.bashrc 하단에 추가<br>. ~/.bashrc
복사<br><br><br>pyenv install --list
복사<br><br><br>pyenv install 3.11.9
복사<br><br><br><br>pyenv versions
복사<br><br>pyenv virtualenv 3.11.9 py3_11_9
복사<br><br>pyenv activate py3_11_9
복사<br><br><br>. ~/.bashrc
복사<br>위와 아래는 같음<br>source ~/.bashrc
복사]]></description><link>root\dev\data-pipe-line\server\pyenv-설치.html</link><guid isPermaLink="false">root/dev/data pipe line/server/pyenv 설치.md</guid><pubDate>Sun, 28 Jul 2024 15:18:35 GMT</pubDate></item><item><title><![CDATA[간단 파이프 라인에 스파크 붙이기]]></title><description><![CDATA[ 
 <br><a data-href="python 간단 파이프라인" href="root\dev\data-pipe-line\데이터-파이프라인-구축\python-간단-파이프라인.html" class="internal-link" target="_self" rel="noopener">python 간단 파이프라인</a><br>
<a data-href="간단 파이프 라인에 카프카 붙이기" href="root\dev\data-pipe-line\데이터-파이프라인-구축\간단-파이프-라인에-카프카-붙이기.html" class="internal-link" target="_self" rel="noopener">간단 파이프 라인에 카프카 붙이기</a><br>Apache Spark를 데이터 파이프라인에 추가하면 데이터 처리 및 분석의 성능을 대폭 향상시킬 수 있어. Spark는 대량의 데이터를 빠르게 처리하고 분석할 수 있는 분산 처리 프레임워크야. 카프카와 스파크를 결합하면 실시간 데이터 스트리밍과 대규모 데이터 처리를 더 강력하게 할 수 있어.<br><br>
<br>CSV에서 카프카로 데이터 전송: CSV 파일에서 카프카로 데이터를 전송 (위에서 다룬 내용).
<br>스파크에서 카프카로부터 데이터 스트리밍: 카프카 토픽에서 실시간으로 데이터를 읽어들이고, Spark로 데이터 처리 및 변환을 수행.
<br>스파크에서 MySQL로 데이터 적재: 처리된 데이터를 MySQL 데이터베이스에 적재.
<br><br>아래는 스파크를 사용하여 카프카에서 데이터를 읽고, 간단한 변환을 수행한 후 MySQL에 적재하는 예제야.<br><br>스파크를 설치하고, 스파크에서 카프카를 사용할 수 있도록 필요한 라이브러리를 설치해:<br>pip install pyspark
pip install kafka-python
복사<br>스파크 클러스터를 로컬에 설치하거나 클라우드에 배포할 수 있어. <a data-tooltip-position="top" aria-label="https://spark.apache.org/docs/latest/" rel="noopener" class="external-link" href="https://spark.apache.org/docs/latest/" target="_blank">스파크 공식 문서</a>를 참조해 스파크를 설정하고, 필요한 경우 스파크 클러스터를 시작해.<br><br>from pyspark.sql import SparkSession
from pyspark.sql.functions import col
from pyspark.sql.types import StructType, StructField, StringType, IntegerType

# 스파크 세션 설정
spark = SparkSession.builder \
    .appName("KafkaToMySQL") \
    .getOrCreate()

# 카프카에서 데이터 읽기
kafka_stream = spark \
    .readStream \
    .format("kafka") \
    .option("kafka.bootstrap.servers", "localhost:9092") \
    .option("subscribe", "my_topic") \
    .load()

# 데이터의 스키마 정의
schema = StructType([
    StructField("name", StringType(), True),
    StructField("age", IntegerType(), True)
])

# 카프카 메시지의 값 파싱
parsed_df = kafka_stream.selectExpr("CAST(value AS STRING)") \
    .select(from_json(col("value"), schema).alias("data")) \
    .select("data.*")

# 데이터 변환 (예: 나이 컬럼을 1.5배로 변환)
transformed_df = parsed_df.withColumn("age", col("age") * 1.5)

# MySQL로 데이터 적재
def write_to_mysql(df, batch_id):
    df.write \
        .format("jdbc") \
        .option("url", "jdbc:mysql://localhost:3306/testdb") \
        .option("driver", "com.mysql.cj.jdbc.Driver") \
        .option("dbtable", "users") \
        .option("user", "ubuntu") \
        .option("password", "1234") \
        .mode("append") \
        .save()

query = transformed_df.writeStream \
    .foreachBatch(write_to_mysql) \
    .outputMode("append") \
    .start()

query.awaitTermination()
Run복사<br><br>
<br>스파크 세션 설정: 스파크 세션을 생성해.
<br>카프카에서 데이터 읽기: spark.readStream.format("kafka")를 사용해 카프카에서 데이터를 스트리밍으로 읽어들여.
<br>데이터 파싱 및 변환: 카프카 메시지에서 JSON 값을 파싱하고, 나이 컬럼을 1.5배로 변환해.
<br>MySQL로 데이터 적재: write_to_mysql 함수에서 스파크 데이터프레임을 MySQL 데이터베이스에 적재해.
<br><br>
<br>MySQL JDBC 드라이버: 스파크가 MySQL에 연결할 수 있도록 MySQL JDBC 드라이버가 필요해. com.mysql.cj.jdbc.Driver를 사용해. 드라이버를 스파크 클러스터의 클래스패스에 추가해야 해.
<br>스파크 클러스터: 로컬 모드가 아닌 클러스터 모드에서 실행할 경우, 스파크 클러스터 설정을 맞춰야 해.
<br>이렇게 하면 카프카와 스파크를 결합하여 실시간으로 데이터를 처리하고, MySQL에 적재하는 강력한 데이터 파이프라인을 구현할 수 있어.]]></description><link>root\dev\data-pipe-line\spark\간단-파이프-라인에-스파크-붙이기.html</link><guid isPermaLink="false">root/dev/data pipe line/spark/간단 파이프 라인에 스파크 붙이기.md</guid><pubDate>Sun, 28 Jul 2024 08:28:58 GMT</pubDate></item><item><title><![CDATA[spark에 대한 고찰]]></title><description><![CDATA[ 
 <br>Spark는 빅 데이터 처리와 분석에 널리 사용되는 오픈 소스 분산 컴퓨팅 시스템입니다. Kafka와 마찬가지로 데이터 처리와 분석에 있어 강력한 도구이지만, Spark는 특히 대규모 데이터 처리와 분석에서 빛을 발합니다. Spark를 사용할 때와 사용하지 않을 때의 차이점과 이를 체험할 수 있는 실습 코드를 제공하겠습니다.<br><br>
<br>
속도:

<br>Spark는 메모리 내에서 데이터를 처리하기 때문에, 디스크 기반의 Hadoop MapReduce에 비해 최대 100배 빠른 속도로 데이터를 처리할 수 있습니다.


<br>
유연성:

<br>Spark는 SQL, 데이터 프레임, 스트리밍, 머신러닝, 그래프 처리를 지원하여 다양한 데이터 처리 요구사항을 충족할 수 있습니다.


<br>
확장성:

<br>Spark는 클러스터 컴퓨팅 프레임워크로 설계되어 있으며, 대규모 데이터 처리와 분석 작업을 수천 대의 노드에서 동시에 수행할 수 있습니다.


<br>
배치 및 실시간 스트리밍 처리:

<br>Spark는 배치 처리와 실시간 스트리밍 처리를 모두 지원하여, 실시간 데이터 분석 및 처리에도 적합합니다.


<br><br><br>이 시나리오에서는 데이터를 MySQL에 직접 로드하고, SQL 쿼리를 사용하여 분석하거나 처리합니다.<br><br>
<br>설정이 간단하며, SQL을 사용해 손쉽게 데이터를 처리할 수 있습니다.
<br><br>
<br>대규모 데이터 처리에 있어 성능이 제한됩니다.
<br>실시간 데이터 처리 및 복잡한 데이터 분석 작업에 있어 유연성이 떨어집니다.
<br><br>이 시나리오에서는 데이터를 Spark에 로드하여, 데이터 프레임 API, SQL, 또는 스트리밍 API를 사용하여 데이터를 처리하고 분석합니다.<br><br>
<br>대규모 데이터 세트를 빠르게 처리할 수 있습니다.
<br>실시간 데이터 스트리밍과 배치 처리 모두 지원합니다.
<br>다양한 분석 작업을 효율적으로 수행할 수 있습니다.
<br><br>
<br>초기 설정과 학습 곡선이 있으며, 클러스터 관리와 같은 추가적인 운영 작업이 필요할 수 있습니다.
<br><br><br>
<br>Apache Spark 설치
<br>PySpark 라이브러리 설치
<br><br><br>name,age
Alice,30
Bob,24
Charlie,29
복사<br><br>기본적으로 MySQL로 CSV 데이터를 읽고 처리하는 코드는 이전과 동일하므로 생략합니다.<br><br>from pyspark.sql import SparkSession
from pyspark.sql.functions import col

# SparkSession 생성
spark = SparkSession.builder \
    .appName("CSV to DataFrame") \
    .config("spark.master", "local") \
    .getOrCreate()

# CSV 파일을 Spark DataFrame으로 로드
df = spark.read.csv('users.csv', header=True, inferSchema=True)

# 데이터 출력
df.show()

# 데이터 필터링 (예: 나이가 25 이상인 사용자만 선택)
filtered_df = df.filter(col('age') &gt;= 25)

# 필터링된 데이터 출력
filtered_df.show()

# 필터링된 데이터를 MySQL에 저장 (예제, 실제 동작 시 데이터베이스 연결 필요)
# filtered_df.write \
#     .format("jdbc") \
#     .option("url", "jdbc:mysql://localhost:3306/my_data") \
#     .option("dbtable", "users_filtered") \
#     .option("user", "root") \
#     .option("password", "password") \
#     .save()

# SparkSession 종료
spark.stop()
Run복사<br><br>
<br>
Spark 없이 MySQL을 사용하는 경우:

<br>데이터를 MySQL에 직접 로드하고, SQL을 사용하여 데이터를 분석하거나 처리합니다.


<br>
Spark를 사용하는 경우:

<br>Spark 데이터 프레임 API를 사용하여 데이터를 로드, 처리, 분석합니다. 예를 들어, 특정 조건에 맞는 데이터를 필터링하거나, 데이터를 집계하고, 이를 다시 MySQL에 저장할 수 있습니다.


<br>이 실습을 통해 Spark를 사용했을 때의 장점, 특히 대규모 데이터 처리 속도와 유연성을 직접 경험할 수 있습니다. Spark의 강력한 데이터 처리 및 분석 기능은 특히 대량의 데이터 처리 및 복잡한 분석 작업에서 그 진가를 발휘합니다.]]></description><link>root\dev\data-pipe-line\spark\spark에-대한-고찰.html</link><guid isPermaLink="false">root/dev/data pipe line/spark/spark에 대한 고찰.md</guid><pubDate>Sat, 27 Jul 2024 07:10:26 GMT</pubDate></item><item><title><![CDATA[docker pipe line 구축]]></title><description><![CDATA[ 
 <br>작업에 들어가기 앞서!
<br>(L): local에서 하는 작업

<br>windows: wsl
<br>mac: terminal


<br>(C): container에서 하는 작업
<br><br>pull 받으려 하는데 로그인 하라고?
<br><a rel="noopener" class="external-link" href="http://dockerhub.com/" target="_blank">http://dockerhub.com/</a> 에서
<br>아이디 없으면 만들고
<br>있으면 확인하고
<br>shell에서 아래의 명령어를 입력하여 로그인

docker login
복사<br><br>docker pull ubuntu:24.04
복사<br><br>docker tag ubuntu:24.04 ubuntu-pipeline:24.04
복사<br><br>docker container run -it -d ubuntu-pipeline:24.04
복사<br><br><br><br>apt-get update
apt-get install -y sudo
apt-get install -y net-tools
apt-get install -y git
apt-get install -y wget
apt-get install -y tree
apt-get install -y openssh-server
apt-get install -y vim
복사<br><br>매우 주의!root 계정으로 작업 할 것!<br><br>passwd
복사<br><br>passwd ubuntu
복사<br><br><a data-href="우분투 sudo 비번 생략하기" href="root\dev\data-pipe-line\server\local\우분투-sudo-비번-생략하기.html" class="internal-link" target="_self" rel="noopener">우분투 sudo 비번 생략하기</a><br>echo 'ubuntu ALL=(ALL) NOPASSWD:ALL' &gt;&gt; /etc/sudoers
복사<br><br><br><br><br>docker container ls
복사<br><br>docker container commit 컨테이너_이름 ubuntu-pipeline:24.04-basic
복사<br><br>docker container rm -f 컨테이너_이름
복사<br><br><br><br><br>docker container run -itd \
  -u ubuntu \
  -w /home/ubuntu \
  ubuntu-pipeline:24.04-basic
복사<br><br>docker container ls
복사<br><br>docker container commit 컨테이너_이름 ubuntu-pipeline:24.04-user-setting
복사<br><br>docker container rm -f 컨테이너_이름
복사<br><br><br><br>docker container run -itd ubuntu-pipeline:24.04-user-setting 
복사<br><br><a data-href="pyenv 설치" href="root\dev\data-pipe-line\server\pyenv-설치.html" class="internal-link" target="_self" rel="noopener">pyenv 설치</a><br><br><br>docker container ls
복사<br><br>docker container commit 컨테이너_이름 ubuntu-pipeline:24.04-pyenv
복사<br><br>docker container rm -f 컨테이너_이름
복사<br><br><br><br>docker container run -itd ubuntu-pipeline:24.04-pyenv
복사<br><br><a data-href="docker 우분투 mysql 설치" href="root\dev\data-pipe-line\server\docker-우분투-mysql-설치.html" class="internal-link" target="_self" rel="noopener">docker 우분투 mysql 설치</a><br><br><br>docker container ls
복사<br><br>docker container commit 컨테이너_이름 ubuntu-pipeline:24.04-mysql
복사<br><br>docker container rm -f 컨테이너_이름
복사<br><br><br><br>docker container run -itd ubuntu-pipeline:24.04-mysql
복사<br><a data-href="docker container 시작 시 명령어 시작" href="root\dev\data-pipe-line\server\local\docker-container-시작-시-명령어-시작.html" class="internal-link" target="_self" rel="noopener">docker container 시작 시 명령어 시작</a><br><br>docker container run -itd \
  ubuntu-pipeline:24.04-mysql\
  /bin/bash -c "sudo service ssh start &amp;&amp; sudo service mysql start &amp;&amp; tail -f /dev/null"
복사<br><br><br>sudo service --status-all
복사<br><br> [ - ]  dbus
 [ + ]  mysql
 [ - ]  procps
 [ + ]  ssh
 [ - ]  x11-common
복사<br><br><br>docker container ls
복사<br><br>docker container commit 컨테이너_이름 ubuntu-pipeline:24.04-service-auto-load
복사<br><br>docker container rm -f 컨테이너_이름
복사<br><br><br><br>docker container run -itd ubuntu-pipeline:24.04-service-auto-load
복사<br><br><a data-href="우분투 hosts를 설정하여 ssh 편하게 이동하기" href="root\dev\data-pipe-line\server\local\우분투-hosts를-설정하여-ssh-편하게-이동하기.html" class="internal-link" target="_self" rel="noopener">우분투 hosts를 설정하여 ssh 편하게 이동하기</a><br><br>ssh-keygen -t rsa
cd .ssh
cat id_rsa.pub &gt; authorized_keys
복사<br><br>Host server*
  StrictHostKeyChecking no
  UserKnownHostsFile=/dev/null
복사<br><a data-href="ssh 접속시 yes 입력 생략하기" href="root\dev\data-pipe-line\server\local\ssh-접속시-yes-입력-생략하기.html" class="internal-link" target="_self" rel="noopener">ssh 접속시 yes 입력 생략하기</a><br><br>cd
mkdir run
cd run
vi ssh_check.sh
복사<br><a data-href="shell ssh 여러 개 접속 테스트" href="root\dev\data-pipe-line\자동화\shell-ssh-여러-개-접속-테스트.html" class="internal-link" target="_self" rel="noopener">shell ssh 여러 개 접속 테스트</a> 를 작성<br>sudo chmod +x ssh_check.sh
복사<br><br><br>docker container ls
복사<br><br>docker container commit 컨테이너_이름 ubuntu-pipeline:24.04-ssh-key
복사<br><br>docker container rm -f 컨테이너_이름
복사<br><br>그리고commit 된 이미로 3개의 컨테이너를 띄움<br>docker run -itd \
  --name server1 \
  --hostname server1 \
  --add-host server1:172.17.0.2 \
  --add-host server2:172.17.0.3 \
  --add-host server3:172.17.0.4 \
  ubuntu-pipeline:24.04-ssh-key

docker run -itd \
  --name server2 \
  --hostname server2 \
  --add-host server1:172.17.0.2 \
  --add-host server2:172.17.0.3 \
  --add-host server3:172.17.0.4 \
  ubuntu-pipeline:24.04-ssh-key

docker run -itd \
  --name server3 \
  --hostname server3 \
  --add-host server1:172.17.0.2 \
  --add-host server2:172.17.0.3 \
  --add-host server3:172.17.0.4 \
  ubuntu-pipeline:24.04-ssh-key
복사<br><br><a data-href="shell ssh 여러 개 접속 테스트" href="root\dev\data-pipe-line\자동화\shell-ssh-여러-개-접속-테스트.html" class="internal-link" target="_self" rel="noopener">shell ssh 여러 개 접속 테스트</a><br>./run/check_ssh.sh
복사<br><br><br>docker container ls
복사<br><br>docker container commit 컨테이너_이름 ubuntu-pipeline:24.04-service-auto-load
복사<br><br>docker container rm -f 컨테이너_이름
복사<br><br><br><br>docker container run -itd ubuntu-pipeline:24.04-ssh-key
복사<br><a data-href="kafka 설치#JAVA" href="root\dev\data-pipe-line\kafka\kafka-설치.html#JAVA" class="internal-link" target="_self" rel="noopener">kafka 설치 &gt; JAVA</a><br><br><br>docker container ls
복사<br><br>docker container commit 컨테이너_이름 ubuntu-pipeline:24.04-java
복사<br><br>docker container rm -f 컨테이너_이름
복사<br><br>Checkroot 계정으로 java를 설치 했을 때는<br>
hostname이 java 설치 했을 때와 다르면<br>
컨테이너가 죽는 현상이 발견 됐다.<br>
하지만 이게 과연 root 계정이기 때문에 발생 된 것인지에 대한 건 모른다.<br>
때문에 아래의 테스트를 꼭 거치고 다음 스텝을 밟아야 한다<br><br>docker run -itd \
  --name server1 \
  --hostname server1 \
  --add-host server1:172.17.0.2 \
  --add-host server2:172.17.0.3 \
  --add-host server3:172.17.0.4 \
  ubuntu-pipeline:24.04-java

docker run -itd \
  --name server2 \
  --hostname server2 \
  --add-host server1:172.17.0.2 \
  --add-host server2:172.17.0.3 \
  --add-host server3:172.17.0.4 \
  ubuntu-pipeline:24.04-java

docker run -itd \
  --name server3 \
  --hostname server3 \
  --add-host server1:172.17.0.2 \
  --add-host server2:172.17.0.3 \
  --add-host server3:172.17.0.4 \
  ubuntu-pipeline:24.04-java

복사<br><br>docker container rm -f server1 server2 server3 
복사<br><br><br><br>docker container run -itd ubuntu-pipeline:24.04-java
복사<br><a data-href="kafka 설치#install" href="root\dev\data-pipe-line\kafka\kafka-설치.html#install" class="internal-link" target="_self" rel="noopener">kafka 설치 &gt; install</a><br><a data-href="kafka 설정 및 실행" href="root\dev\data-pipe-line\kafka\kafka-설정-및-실행.html" class="internal-link" target="_self" rel="noopener">kafka 설정 및 실행</a><br>정말 위험해!docker 컨테이너로 서버를 start 할 때 순서를 꼭 치켜야 한다.<br>
그렇지 않으면 ip가 켜진 순서대로 할당 받기 때문에<br>
kafka에서 정상 작동을 기대하기 어려워진다.<br>docker run -itd \
  --name server1 \
  --hostname server1 \
  --add-host server1:172.17.0.2 \
  --add-host server2:172.17.0.3 \
  --add-host server3:172.17.0.4 \
  ubuntu-pipeline:24.04-kafka

docker run -itd \
  --name server2 \
  --hostname server2 \
  --add-host server1:172.17.0.2 \
  --add-host server2:172.17.0.3 \
  --add-host server3:172.17.0.4 \
  ubuntu-pipeline:24.04-kafka

docker run -itd \
  --name server3 \
  --hostname server3 \
  --add-host server1:172.17.0.2 \
  --add-host server2:172.17.0.3 \
  --add-host server3:172.17.0.4 \
  ubuntu-pipeline:24.04-kafka
복사<br><br><br><a data-href="kafka 클러스터 서버 시동" href="root\dev\data-pipe-line\kafka\kafka-클러스터-서버-시동.html" class="internal-link" target="_self" rel="noopener">kafka 클러스터 서버 시동</a><br><a data-href="kafka에 csv로 데이터 흘리기" href="root\dev\data-pipe-line\kafka\kafka에-csv로-데이터-흘리기.html" class="internal-link" target="_self" rel="noopener">kafka에 csv로 데이터 흘리기</a><br><a data-href="Kafka Consumer와 MySQL에 데이터 적재하기" href="root\dev\data-pipe-line\kafka\kafka-consumer와-mysql에-데이터-적재하기.html" class="internal-link" target="_self" rel="noopener">Kafka Consumer와 MySQL에 데이터 적재하기</a>]]></description><link>root\dev\data-pipe-line\docker-pipe-line-구축.html</link><guid isPermaLink="false">root/dev/data pipe line/docker pipe line 구축.md</guid><pubDate>Mon, 05 Aug 2024 01:41:31 GMT</pubDate></item><item><title><![CDATA[EC2 - mariaDB workbench 연결]]></title><description><![CDATA[ 
 <br><br><img alt="Pasted image 20240501003521.png" src="lib\media\pasted-image-20240501003521.png"><br><br><br><img alt="Pasted image 20240501003750.png" src="lib\media\pasted-image-20240501003750.png"><br>
<br>Connection Name: EC2-mariadb
<br>Connection Methods: Standard TCP/IP over SSH
<br>SSH Hostname: 자신의_공개아이피:22
<br>SSH Username: ubuntu
<br>SSH-Key File: master-key.pem
<br>Username: hr_admin
<br>해서 7 번 누르면<br><br><br><img alt="Pasted image 20240501004345.png" src="lib\media\pasted-image-20240501004345.png"><br>
<br>password 적고
<br>ok를 누르고
<br>Continue Anyway 를 누르면
<br>ok를 누르게 되는데
<br>눌러서 꺼버리자.
<br>그리고<br><br><br><img alt="Pasted image 20240501004917.png" src="lib\media\pasted-image-20240501004917.png"><br>
<br>선택
<br>역시 비번: password
<br>ok
<br><br><br><img alt="Pasted image 20240501004958.png" src="lib\media\pasted-image-20240501004958.png"><br>baam!!]]></description><link>root\dev\database\mariadb\ec2-mariadb-workbench-연결.html</link><guid isPermaLink="false">root/dev/database/mariaDB/EC2 - mariaDB workbench 연결.md</guid><pubDate>Tue, 30 Apr 2024 16:04:19 GMT</pubDate><enclosure url="lib\media\pasted-image-20240501003521.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src="lib\media\pasted-image-20240501003521.png"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[mariaDB 설치]]></title><description><![CDATA[ 
 <br><br>
<br>22.04 "jammy"
<br>10.6
<br><br>sudo apt-get install apt-transport-https curl
복사<br><br>sudo mkdir -p /etc/apt/keyrings
복사<br><br>sudo curl -o /etc/apt/keyrings/mariadb-keyring.pgp 'https://mariadb.org/mariadb_release_signing_key.pgp'
복사<br><br>sudo vi /etc/apt/sources.list.d/mariadb.sources
복사<br># MariaDB 10.6 repository list - created 2024-04-30 05:48 UTC
# https://mariadb.org/download/
X-Repolib-Name: MariaDB
Types: deb
# deb.mariadb.org is a dynamic mirror if your preferred mirror goes offline. See https://mariadb.org/mirrorbits/ for details.
# URIs: https://deb.mariadb.org/10.6/ubuntu
URIs: https://tw1.mirror.blendbyte.net/mariadb/repo/10.6/ubuntu
Suites: jammy
Components: main main/debug
Signed-By: /etc/apt/keyrings/mariadb-keyring.pgp

sudo apt-get update -y &amp;&amp; sudo apt-get install mariadb-server -y
복사<br><br>
<br><a rel="noopener" class="external-link" href="https://mariadb.org/download/?t=repo-config" target="_blank">https://mariadb.org/download/?t=repo-config</a>
]]></description><link>root\dev\database\mariadb\mariadb-설치.html</link><guid isPermaLink="false">root/dev/database/mariaDB/mariaDB 설치.md</guid><pubDate>Tue, 30 Apr 2024 15:58:12 GMT</pubDate></item><item><title><![CDATA[mariaDB 설치부터 workbench 연결까지]]></title><description><![CDATA[ 
 <br><br><a data-tooltip-position="top" aria-label="mariaDB 설치" data-href="mariaDB 설치" href="root\dev\database\mariadb\mariadb-설치.html" class="internal-link" target="_self" rel="noopener">하고</a><br><br><a data-tooltip-position="top" aria-label="mariaDB 아이디 생성" data-href="mariaDB 아이디 생성" href="root\dev\database\mariadb\mariadb-아이디-생성.html" class="internal-link" target="_self" rel="noopener">해서</a><br><br><a data-tooltip-position="top" aria-label="EC2 - mariaDB workbench 연결" data-href="EC2 - mariaDB workbench 연결" href="root\dev\database\mariadb\ec2-mariadb-workbench-연결.html" class="internal-link" target="_self" rel="noopener">하면 된다.</a>]]></description><link>root\dev\database\mariadb\mariadb-설치부터-workbench-연결까지.html</link><guid isPermaLink="false">root/dev/database/mariaDB/mariaDB 설치부터 workbench 연결까지.md</guid><pubDate>Tue, 30 Apr 2024 17:30:30 GMT</pubDate></item><item><title><![CDATA[mariaDB 아이디 생성]]></title><description><![CDATA[ 
 <br><br>sudo mariadb -u root -p
복사<br><br>CREATE DATABASE hrdb;

GRANT ALL PRIVILEGES ON hrdb.*
TO hr_admin@'%' IDENTIFIED BY 'password'
WITH GRANT OPTION;

FLUSH PRIVILEGES;
EXIT;
Run복사<br><br>mysql -u hr_admin -p hrdb
# 비번 password
복사<br><br>STATUS;
SOURCE hr_info.sql;
Run복사<br>
<br><a class="internal-link" data-href="hr_info.sql" href="hr_info.sql" target="_self" rel="noopener">hr_info.sql</a>
<br><br>SHOW TABLES;
DESC employees;
SELECT * FROM employees;
Run복사]]></description><link>root\dev\database\mariadb\mariadb-아이디-생성.html</link><guid isPermaLink="false">root/dev/database/mariaDB/mariaDB 아이디 생성.md</guid><pubDate>Tue, 30 Apr 2024 15:57:05 GMT</pubDate></item><item><title><![CDATA[mysql note]]></title><description><![CDATA[ 
 <br><br>
<br>일번적으로 대소문자를 구분하지 않음
<br>주로 예약어(SELECT, FROM)는<br>
대문자, 사용자 정의어(code, name, population)는 소문자를 사용
<br><br><br><br>SHOW DATABASES;
Run복사<br><br>SHOW TABLES;
Run복사<br><br>DESC &lt;table_name&gt;;
Run복사<br><br><br>USE &lt;database_name&gt;;
Run복사<br><br>SELECT * FROM &lt;table_name&gt;;
Run복사<br><br><br><br>mysql -u root -p비번 &lt; schema-data.sql
복사<br><br>mysql -u root -p비번 &lt; schema.sql
mysql -u root -p비번 &lt; data.sql
복사<br><br>mysql -u root -p비번 data_base_name &lt; data.sql
복사<br><br><br>Info
<br>-- : 한줄주석, -- 를 한 후에 반드시 한칸을 띄어서 사용해야 합니다.
<br>/* */ : 블럭주석
<br>-- 국가코드와 국가 이름을 출력합니다.
/* SELECT code, population
FROM country; */
SELECT code, name
FROM country;
Run복사<br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br>InfoData Manipulation Language<br>
데이터 조작어<br>
데이터 검색, 삽입, 수정, 삭제등에 사용<br>
SELECT, INSERT, UPDATE, DELETE<br>
트랜젝션이 발생하는 SQL문<br><br>SELECT &lt;column_name_1&gt;, &lt;column_name_2&gt;, ...
FROM &lt;database_name&gt;.&lt;table_name&gt;;
또는 FROM &lt;table_name&gt;;
Run복사<br>-- 전체 조회
SELECT *
FROM world.country;
Run복사<br>-- code, name 세개의 컬럼 데이터 조회
SELECT code, name
FROM world.country;
Run복사<br>-- alias 조회
SELECT code AS country_code, name AS country_name
FROM country;
Run복사<br><br>INSERT INTO &lt;table_name&gt;(&lt;column_name_1&gt;, &lt;column_name_2&gt;, ...)
VALUES(&lt;value_1&gt;, &lt;value_2&gt;, …)
Run복사<br>-- user1 테이블에 user_id, namex, email, age, rdate를 입력
INSERT INTO user1(user_id, name, email, age, rdate)
VALUES (1, "jin", "pdj@gmail.com", 30, now()),
(2, "peter", "peter@daum.net", 33, '2017-02-20'),
(3, "alice", "alice@naver.com", 23, '2018-01-05'),
(4, "po", "po@gmail.com", 43, '2002-09-16'),
(5, "andy", "andy@gmail.com", 17, '2016-04-28'),
(6, "jin", "jin1224@gmail.com", 33, '2013-09-02');
Run복사<br><br>UPDATE &lt;table_name&gt;
SET &lt;column_name_1&gt; = &lt;value_1&gt;, &lt;column_name_2&gt; = &lt;value_2&gt;,
WHERE &lt;condition&gt;
Run복사<br>-- jin 이름을 가지고 있는 사람의 나이를 20, 이메일을 pdj@daum.net으로 변경
UPDATE user1
SET age=20, email="pdj@daum.net"
WHERE name="jin"
Run복사<br><br>DELETE FROM &lt;table_name&gt;
WHERE &lt;condition&gt;
Run복사<br>-- 2016-01-01 이전 데이터 삭제 (DML)
DELETE FROM user1
WHERE rdate &lt; "2016-01-01"
Run복사<br><br>SELECT &lt;컬럼이름 1&gt;, &lt;컬럼이름 2&gt;, ...
FROM &lt;테이블 이름&gt;
WHERE &lt;조건식&gt;
Run복사<br><br>-- 인구가 7000만에서 1억인 국가를 출력
SELECT *
FROM country
WHERE Population &gt;= 70000000 AND Population &lt;= 100000000;
Run복사<br><br><br>SELECT *
FROM country
WHERE Continent = "Asia" OR Continent = "Africa";
Run복사<br><br>-- 인구가 7000만에서 1억인 국가를 출력
SELECT *
FROM country
WHERE Population BETWEEN 70000000 AND 100000000;
Run복사<br><br>-- 아시아와 아프리카 대륙의 국가 데이터를 출력
SELECT *
FROM country
WHERE Continent IN ("Asia", "Africa");

-- 아시아와 아프리카 대륙의 국가가 아닌 데이터를 출력
SELECT *
FROM country
WHERE Continent NOT IN ("Asia", "Africa");

-- 아시아와 아프리카 대륙의 국가가 아닌 데이터를 출력 (논리연산 사용)
SELECT *
FROM country
WHERE Continent != "Asia" AND Continent != "Africa";
Run복사<br><br>-- country 테이블에서 국가 코드가 Z로 시작되는 데이터를 출력
SELECT *
FROM country
WHERE code like "Z%";

-- 정부형태에 Republic이 포함된 데이터 출력
SELECT *
FROM country
WHERE GovernmentForm LIKE “%Republic%”;
Run복사<br><br><br>-- 오름차순 인구순으로 국가의 리스트를 출력
-- ASC는 생략이 가능
SELECT *
FROM country
ORDER BY population ASC
Run복사<br><br>SELECT *
FROM country
ORDER BY population DESC

-- ORDER BY에 여러개의 정렬 조건을 사용
-- 국가 코드를 알파벳 순으로 정렬하고 같은 국가 코드를 가지면 인구순으로 내림차순으로 정렬
SELECT *
FROM city
ORDER BY CountryCode ASC, Population DESC
Run복사<br><br>-- 인구가 많은 상위 5개 국가 데이터를 출력
SELECT *
FROM country
ORDER BY population DESC
LIMIT 5;

-- 인구가 많은 상위 6위 ~ 8위의 3개 국가 데이터를 출력
-- OFFSET 사용
SELECT *
FROM country
ORDER BY population DESC
LIMIT 3 OFFSET 5; -- # 5개 스킵하고 3개를 출력

SELECT *
FROM country
ORDER BY population DESC
LIMIT 5, 3; # -- 5개 스킵하고 3개를 출력
Run복사<br><br>-- city 테이블에서 도시의 인구수가 100만에서 200만인 도시의 국가 코드를 중복을 제거후 출력
SELECT DISTINCT countrycode
FROM city
WHERE population BETWEEN 1000000 AND 2000000;
Run복사<br><br><br>Note실수 데이터 올림<br>-- 12.345를 올림하여 정수로 나타냄
SELECT CEIL(12.345);

-- 국가별 언어 사용 비율을 소수 첫번째자리에서 올림하여 정수로 나타냄
SELECT CountryCode, Language, Percentage, CEIL(Percentage)
FROM countrylanguage;
Run복사<br><br>Note실수데이터 반올림<br>-- 12.345를 소수 둘째자리까지 나타내고 소수 셋째자리에서 반올림
SELECT ROUND(12.345, 2);

-- 국가별 언어 사용 비율을 소수 첫번째자리에서 반올림하여 정수로 나타냄
SELECT CountryCode, Language, Percentage, ROUND(Percentage, 0)
FROM countrylanguage;
Run복사<br><br>Note실수 데이터를 버림<br>-- 12.345를 소수 둘째자리까지 나타내고 소수 셋째자리에서 버림
SELECT TRUNCATE(12.345, 2);

-- 국가별 언어 사용 비율을 소수 첫번째자리에서 버림하여 정수로 나타냄
SELECT CountryCode, Language, Percentage, TRUNCATE(Percentage, 0)
FROM countrylanguage;

SELECT CountryCode, Language, Percentage, ROUND(Percentage, 0), TRUNCATE(Percentage, 0)
FROM countrylanguage;
Run복사<br><br>Note날짜 데이터 포멧<br><a data-tooltip-position="top" aria-label="https://dev.mysql.com/doc/refman/5.7/en/date-and-time-functions.html" rel="noopener" class="external-link" href="https://dev.mysql.com/doc/refman/5.7/en/date-and-time-functions.html" target="_blank">reference</a><br>-- sakila의 payment 테이블에서 요금 지불일을 "년-월"로 데이터 포멧을 변경했을때,
-- 중복을 제거한 "년-월" 데이터를 출력
SELECT DISTINCT(DATE_FORMAT(payment_date, "%Y-%m")) AS unique_month
FROM payment;
Run복사<br><br>Note문자열을 합침<br>-- world 데이터베이스의 country 테이블에서 국가코드, 대륙이름과 국가이름이 
-- " / " 구분자로 구분해서 하나의 컬럼에 출력
SELECT code, CONCAT(continent, " / ", name) as continent_name
FROM country;
Run복사<br><br>Note데이터의 갯수를 출력<br>-- world 데이터 베이스의 city 데이터의 갯수를 출력
SELECT count(*) as city_count
FROM city;
Run복사<br><br>IF(조건, 참, 거짓)
Run복사<br>-- 도시 인구가 100만 이상이면 big city,
-- 아니면 small city 출력
-- IF(조건, true, false)
SELECT `Name`, `Population`,
	IF(`Population` &gt;= 100 * 10000, 'big city', 'small city')
FROM city;
Run복사<br><br>IFNULL(참, 거짓)
Run복사<br>-- 독립년도가 없는 데이터는 0으로 출력
SELECT IndepYear, IFNULL(IndepYear, 0) as IndepYear
FROM country;
Run복사<br><br>CASE
	WHEN (조건1) THEN (출력1)
	WHEN (조건2) THEN (출력2)
END AS (컬럼명)
Run복사<br>-- # 나라별로 인구가 10억 이상, 1억 이상, 1억 이하인 컬럼을 추가하여 출력
SELECT name, population,
	CASE
		WHEN population &gt; 1000000000 THEN "upper 1 bilion"
		WHEN population &gt; 100000000 THEN "upper 100 milion"
		ELSE "below 100 milion"
	END AS result
FROM country;
Run복사<br>-- 도시에서 인구가 500만 이상 big, 100만 이상 medium, 100만 미만 samll 출력

SELECT `Name`, `Population` 
	, CASE 
		WHEN `Population` &gt;= 500 * 10000 THEN  'big'
		WHEN `Population` &gt;= 100 * 10000 THEN  'medeium'
		ELSE 'small'
	END AS scale
FROM city
ORDER BY `Population` DESC;
Run복사<br><br>Note여러개의 동일한 데이터를 가지는 특정 컬럼을 합쳐주는 역할<br><br>-- city 테이블의 CountryCode를 묶고 각 코드마다 몇개의 데이터가 있는지 확인
SELECT CountryCode, COUNT(CountryCode)
FROM city
GROUP BY CountryCode;
Run복사<br>-- 국가별 도시 수를 출력
-- 도시가 많은 상위 10개의 국가, 도시수를 출력
SELECT `CountryCode`, COUNT(`Name`) AS city_count
FROM city
GROUP BY `CountryCode`
ORDER BY city_count DESC
LIMIT 10;
Run복사<br>-- 국가별 도시 수를 출력
-- 인구수 50만 이상의 10개의 국가, 도시수를 출력
SELECT `CountryCode`, COUNT(`Name`) AS city_count
FROM city
WHERE `Population` &gt;= 50 * 10000
GROUP BY `CountryCode`
ORDER BY city_count DESC
LIMIT 10;
Run복사<br><br>-- 대륙별 인구수와 GNP 최대 값을 조회
SELECT continent, MAX(Population) as Population, MAX(GNP) as GNP
FROM country
GROUP BY continent;
Run복사<br><br>-- 대륙별 인구수와 GNP 최소 값을 조회 (GNP와 인구수가 0이 아닌 데이터 중에서)
SELECT continent, MIN(Population) as Population, MIN(GNP) as GNP
FROM country
WHERE GNP != 0 AND Population != 0
GROUP BY continent;
Run복사<br><br>-- 대륙별 총 인구수와 총 GNP
SELECT continent, SUM(Population) as Population, SUM(GNP) as GNP
FROM country
WHERE GNP != 0 AND Population != 0
GROUP BY continent;
Run복사<br>-- 대륙별 총인구수 출력
SELECT `Continent`, SUM(`Population`) AS total_population
FROM country
GROUP BY `Continent`;
Run복사<br>-- 대륙별 평균 GNP
SELECT `Continent`, SUM(`Population`) AS total_population
	, AVG(`GNP`/`Population`) AS avg_gnp
FROM country
GROUP BY `Continent`;
Run복사<br>-- 평균인당 GBP가 높은 순으로 정렬
SELECT `Continent`, SUM(`Population`) AS total_population
	, AVG(`GNP`/`Population`) AS avg_gnp
FROM country
GROUP BY `Continent`
ORDER BY avg_gnp DESC;
Run복사<br>-- 고객별 가장 많은 매출 발생 시켜준 상위 3명의 고객 출력
SELECT customer_id, SUM(amount) AS total_amount
FROM payment
GROUP BY customer_id
ORDER BY total_amount DESC
LIMIT 10;
Run복사<br>-- 고객별 가장 많은 매출 발생 시켜준 상위 3명의 고객 출력
-- 조건: 2005년 6월 이 후
SELECT customer_id, SUM(amount) AS total_amount
FROM payment
WHERE payment_date &gt;= '2005-06-01'
GROUP BY customer_id
ORDER BY total_amount DESC
LIMIT 10;
Run복사<br><br>-- 대륙별 평균 인구수와 평균 GNP 결과를 인구수로 내림차순 정렬
SELECT continent, AVG(Population) as Population, AVG(GNP) as GNP
FROM country
WHERE GNP != 0 AND Population != 0
GROUP BY continent
ORDER BY Population DESC;
Run복사<br><br>NoteGROUP BY에서 반환되는 결과에 조건을 줄수 있음<br>-- 대륙별 전체인구를 구하고 5억이상인 대륙만 조회
SELECT continent, SUM(Population) as Population
FROM country
GROUP BY continent
HAVING Population &gt; 500000000;

-- 대륙별 평균 인구수, 평균 GNP, 1인당 GNP한 결과를 
-- 1인당 GNP가 0.01 이상인 데이터를 조회하고
-- 1인당 GNP를 내림차순으로 정렬
SELECT continent, AVG(Population) as Population, AVG(GNP) as GNP,
	AVG(GNP) / AVG(Population) * 1000 as AVG
FROM country
WHERE GNP != 0 AND Population != 0
GROUP BY continent
HAVING AVG &gt; 0.01
ORDER BY AVG DESC;
Run복사<br><br>Note여러개의 컬럼을 GROUP BY 하고 각 컬럼별 총 합을 row에 출력<br>-- sakila 데이터 베이스에서 고객과 스탭별 매출과 고객별 매출의 총합을 출력
SELECT customer_id, staff_id, SUM(amount) as amount
FROM payment
GROUP BY customer_id, staff_id
WITH ROLLUP;
Run복사<br><br>-- KPI 지포: 년월별 총 매출, 매출 횟수, 평균 매출
SELECT DATE_FORMAT(payment_date, '%Y-%m') AS monthly
	, SUM(amount) AS total_amount
	, COUNT(amount) AS count_amount
	, AVG(amount) AS avg_amount
FROM payment
GROUP BY monthly;
Run복사<br>-- 직원별: 년월별 총 매출, 매출 횟수, 평균 매출
SELECT  staff_id, DATE_FORMAT(payment_date, '%Y-%m') AS monthly
	, SUM(amount) AS total_amount
	, COUNT(amount) AS count_amount
	, AVG(amount) AS avg_amount
FROM payment
GROUP BY staff_id, monthly
ORDER BY monthly, staff_id;
Run복사<br><br>-- staff_id를 기준으로 그룹으로 정렬
USE sakila;

SELECT staff_id
	, DATE_FORMAT(payment_date, '%Y-%m') AS monthly
	, SUM(amount) AS total_amount
FROM payment
GROUP BY staff_id, monthly
WITH ROLLUP;
Run복사<br><br>
<br>기본값: inner
<br><br><br><br><br><br><br>SELECT * 
FROM `user`
JOIN addr
ON user.ui = addr.ui;
Run복사<br><br>SELECT `user`.ui, `user`.un, addr.an
FROM `user`
JOIN addr
ON user.ui = addr.ui;
Run복사<br><br>USE world;
/* USE DATABASE */
-- 국가코드, 국가이름, 도시이름, 국가인구수, 도시인구수 출력
-- 도시의 도시화율(도시인구수/국가인구수)을 출력
-- 조건 : 국가의 인구수가 1000만이 넘는 국가중에서
-- 도시화율이 높은 상위 10개의 국가를 출력
SELECT country.code, country.name, city.name
	, country.population AS country_population
	, city.population AS city_population
	, round(city.population / country.population * 100, 2) AS rate
FROM country
JOIN city
ON country.code = city.countrycode
HAVING country_population &gt;= 1000 * 10000
ORDER BY rate DESC
LIMIT 10;
Run복사<br>-- 국가이름, 도시갯수
-- JOIN, GROUP BY
SELECT country.`Name`, COUNT(city.`Name`) AS city_count
FROM country
JOIN city
ON country.`Code` = city.`CountryCode`
GROUP BY country.`Name`
ORDER BY city_count DESC;
Run복사<br>-- country, countrylanguage
-- 국가코드, 국가이름, 언어이름, 국가인구수, 언어사용률, 언어사용인구수 출력
SELECT country.code, country.name, countrylanguage.language
	, country.population, countrylanguage.percentage
	, round(country.population * countrylanguage.percentage / 100)
	AS population_count
FROM country
JOIN countrylanguage
ON country.code = countrylanguage.countrycode;
Run복사<br><br>SELECT `user`.ui, `user`.un, addr.an
FROM `user`
LEFT JOIN addr
ON user.ui = addr.ui;
Run복사<br><br><br>SELECT addr.ui, `user`.un, addr.an
FROM `user`
RIGHT JOIN addr
ON user.ui = addr.ui;
Run복사<br><br><br>-- Left Join
SELECT `user`.ui, `user`.un, addr.an
FROM `user`
LEFT JOIN addr
ON user.ui = addr.ui
UNION -- 이것을 함으로써 Outer가 완성됨.
-- Right Join
SELECT addr.ui, `user`.un, addr.an
FROM `user`
RIGHT JOIN addr
ON user.ui = addr.ui;
Run복사<br><br><br>두개의 쿼리 결과를 결합, 중복 제거<br>SELECT un FROM `user`
UNION
SELECT an FROM `addr`;
Run복사<br><br><br>두개의 쿼리 결과를 결합, 중복 제거 X<br>SELECT un FROM `user`
UNION ALL
SELECT an FROM `addr`;
Run복사<br><br><br>-- 스탭 1
SELECT COUNT(*) FROM country;
SELECT COUNT(*) FROM city;
SELECT COUNT(DISTINCT(`Language`)) FROM countrylanguage;

-- 스탭 2
SELECT
	(SELECT COUNT(*) FROM country) AS total_country,
	(SELECT COUNT(*) FROM city) AS total_city,
	(SELECT COUNT(DISTINCT(`Language`)) FROM countrylanguage) AS total_countrylanguage
FROM DUAL;
Run복사<br><br>NoteHAVING보다 SubQuery가 더 빠르다.<br>
이유는<br>
HAVING : JOIN(2394096=978944) &gt; Filtering(HAVING:10) =&gt; Result<br>
SubQuery: Filtering(WHERE:10) &gt; JOIN(23910=2390) =&gt; Result<br>-- 800만 인구 이상 도시의 국가코드, 국가이름, 도시이름, 도시인구수 출력 

-- HAVING
SELECT country.code, country.name, city.name, city.population
FROM country
JOIN city
ON country.code = city.countrycode
HAVING city.population &gt;= 800 * 10000;


-- SubQuery
SELECT country.code, country.name, city.name, city.population
FROM country
JOIN (  SELECT countrycode, name, population 
		FROM city 
		WHERE population &gt;= 800 * 10000
	) AS city
ON country.code = city.countrycode;
Run복사<br>-- WHERE SubQuery
-- 한국보다 인구가 많은 국가의 국가코드, 국가이름, 인구수, GNP 출력
SELECT `Population`
FROM country
WHERE `Code` = 'KOR';
-- 46844000
SELECT `Code`, `Name`, `Population`, `GNP`
FROM country
WHERE `Population` &gt; 46844000;

-- SubQuery
SELECT `Code`, `Name`, `Population`, `GNP`
FROM country
WHERE `Population` &gt; (
	SELECT `Population`
	FROM country
	WHERE `Code` = 'KOR'
);
Run복사<br><br><br>InfoData Definition Language<br>
데이터 정의어<br>
데이터 베이스, 테이블, 뷰, 인덱스등의 데이터 베이스 개체를 생성, 삭제, 변경에 사용<br>
CREATE, DROP, ALTER, TRUNCATE<br>
실행 즉시 DB에 적용<br><br><br>CREATE DATABASE &lt;database_name&gt;;
Run복사<br>-- test 데이터 베이스 생성
CREATE DATABASE test;
Run복사<br><br>CREATE TABLE &lt;table_name&gt; (
	column_name_1 column_data_type_1 column_constraint_1,
	column_name_2 column_data_type_2 column_constraint_2,
	...
)
Run복사<br>-- 제약조건이 없는 user1 테이블 생성
CREATE TABLE user1(
	user_id INT,
	name Varchar(20),
	email Varchar(30),
	age INT(3),
	rdate DATE
)
Run복사<br>-- 제약조건이 있는 user2 테이블 생성
CREATE TABLE user2(
	user_id INT PRIMARY KEY AUTO_INCREMENT,
	name Varchar(20) NOT NULL,
	email Varchar(30) UNIQUE NOT NULL,
	age INT(3) DEFAULT '30',
	rdate TIMESTAMP default CURRENT_TIMESTAMP
)
Run복사<br><br>DROP FROM &lt;database_name&gt;
Run복사<br>-- 테이블 전체를 모두 삭제 (DLL)
DROP FROM user1
Run복사<br>-- DATABASE
-- tmp 데이터 베이스 생성
CREATE DATABASE tmp;
SHOW DATABASES;

-- tmp 데이터 베이스 삭제
DROP DATABASE tmp;
SHOW DATABASES;

-- TABLE
-- tmp 데이터 베이스 생성
CREATE DATABASE tmp;

-- tmp 데이터 베이스 선택
USE tmp;

-- tmp 테이블 생성
CREATE TABLE tmp( id INT );

-- tmp 테이블 삭제
DROP TABLE tmp;
Run복사<br><br>INSERT INTO &lt;table_name&gt;(&lt;column_name_1&gt;, &lt;column_name_2&gt;, ...)
VALUES(&lt;value_1&gt;, &lt;value_2&gt;, …)
Run복사<br>-- user1 테이블에 user_id, namex, email, age, rdate를 입력
INSERT INTO user1(user_id, name, email, age, rdate)
VALUES (1, "jin", "pdj@gmail.com", 30, now()),
(2, "peter", "peter@daum.net", 33, '2017-02-20'),
(3, "alice", "alice@naver.com", 23, '2018-01-05'),
(4, "po", "po@gmail.com", 43, '2002-09-16'),
(5, "andy", "andy@gmail.com", 17, '2016-04-28'),
(6, "jin", "jin1224@gmail.com", 33, '2013-09-02');
Run복사<br>-- city_2 테이블 생성
CREATE TABLE city_2 (
	Name VARCHAR(50),
	CountryCode CHAR(3),
	District VARCHAR(50),
	Population INT
)

-- select 절에서 나온 결과데이터를 Insert
INSERT INTO city_2
SELECT Name, CountryCode, District, Population
FROM city
WHERE Population &gt; 8000000;
Run복사<br><br><br><br>ALTER TABLE `테이블 이름` ADD COLUMN `컬럼 명` `속성값`;
Run복사<br>ALTER TABLE user ADD contents TEXT NOT NULL;
Run복사<br><br>ALTER TABLE `테이블 아름` DROP COLUMN `컬럼 이름`;
Run복사<br>ALTER TABLE user DROP contents;
Run복사<br><br>ALTER TABLE 테이블명 RENAME COLUMN 변경할 컬럼명 TO 변경될 이름;
Run복사<br>ALTER TABLE user RENAME COLUMN email TO mail;
Run복사<br><br>ALTER TABLE `기존 테이블 이름` RENAME `새 테이블 이름`;
Run복사<br><br>-- 사용중인 데이터베이스의 인코딩 방식 확인
SHOW VARIABLES LIKE "character_set_database"

-- test 데이터 베이스의 문자열 인코딩을 utf8으로 변경
ALTER DATABASE world CHARACTER SET = ascii
ALTER DATABASE world CHARACTER SET = utf8

-- 사용중인 데이터베이스의 인코딩 방식 확인
SHOW VARIABLES LIKE "character_set_database"

-- Table
-- ALTER를 이용하여 Table의 컬럼을 추가하거나 삭제하거나 수정할수 있습니다.

-- ADD
-- user2 테이블에 TEXT 데이터 타입을 갖는 tmp 컬럼을 추가
ALTER TABLE user2 ADD tmp 


-- MODIFY
-- user2 테이블에 INT 데이터 타입을 갖는 tmp 컬럼으로 수정
ALTER TABLE user2 MODIFY COLUMN tmp INT


-- CONVERT TO
-- 테이블 인코딩 확인
show full columns from test2;

-- 테이블의 모든 인코딩 변환
ALTER TABLE user2 CONVERT TO character set utf8;

-- DROP
-- user2 테이블의 tmp 컬럼을 삭제
ALTER TABLE user2 DROP tmp;
Run복사<br><br>NoteForeign key를 설정하면 데이터의 무결성을 지킬수 있다.<br>
UNIQUE 나 PRAMARY 제약조건이 있어야 설정이 가능하다.<br>-- user 테이블 생성
	create table user(
	user_id int primary key auto_increment,
	name varchar(20),
	addr varchar(20)
);

-- # money 테이블 생성
create table money(
	money_id int primary key auto_increment,
	income int,
	user_id int,
	-- # 외래키 설정
	FOREIGN KEY (user_id) REFERENCES user(user_id)
);

desc money;

-- 수정해서 생성
alter table money
add constraint fk_user
foreign key (user_id)
references user (user_id);

desc money;


-- 데이터 입력
insert into user(name, addr)
values ("jin", "Seoul"), ("andy", "Pusan");


-- 데이터 확인
select * from user;

-- 데이터 입력
insert into money(income, user_id)
values (5000, 1), (7000, 2);



-- 데이터 확인
select * from money;

-- user 테이블에 user_id가 3이 없으므로 에러
insert into money(income, user_id)
values (8000, 3);
delete from money
where user_id = 2;

-- money 테이블에 user_id가 있어서 삭제할수 없다.
delete from user
where user_id = 1;

-- 테이블 삭제도 안된다.
drop table user;

Run복사<br><br>NoteFOREIGN KEY로 참조되는 데이터를 수정 및 삭제할때 참조되는 데이터까지 수정이나 삭제하는 설정<br>
<br>CASCADE : 참조되는 테이블에서 데이터를 삭제하거나 수정하면, 참조하는 테이블에서도 삭제와 수정
<br>SET NULL : 참조되는 테이블에서 데이터를 삭제하거나 수정하면, 참조하는 테이블의 데이터는 NULL로 변경
<br>NO ACTION : 참조되는 테이블에서 데이터를 삭제하거나 수정해도, 참조하는 테이블의 데이터는 변경되지 않음
<br>SET DEFAULT : 참조되는 테이블에서 데이터를 삭제하거나 수정하면, 참조하는 테이블의 데이터는 필드의 기<br>
본값으로 설정
<br>RESTRICT : 참조하는 테이블에 데이터가 남아 있으면, 참조되는 테이블의 데이터를 삭제하거나 수정할 수 없음
<br>--업데이트되면 같이 업데이트, 삭제되면 NULL 값으로 변경
select * from user;
drop table money;
create table money(
money_id int primary key auto_increment,
income int,
user_id int,

--외래키 설정
FOREIGN KEY (user_id) REFERENCES user(user_id)
ON UPDATE CASCADE ON DELETE SET NULL
);

-- money에 데이터 추가
insert into money(income, user_id)
values (5000, 1), (7000, 2);

-- 데이터 추가 확인
select * from money;

-- user 테이블 업데이트 : money 테이블의 user_id도 같이 업데이트 됨
update user
set user_id = 3
where user_id = 2;

select * from user;
select * from money;


-- user 테이블의 데이터 삭제 : money 테이블의 fk로 설정되어 있는 데이터가 NULL로 변경
delete from user
where user_id = 3;

select * from user;
select * from money;
Run복사<br><br><br>USE employees;
SELECT COUNT(*)
FROM salaries; -- 2844047
Run복사<br><br>SHOW INDEX FROM salaries;
Run복사<br><br><br>-- 408ms
SELECT * FROM salaries WHERE to_date &lt; '1986-01-01';
Run복사<br><br>-- 8.8s
CREATE INDEX tdate ON salaries (to_date);

SHOW INDEX FROM salaries;
Run복사<br><br><br>-- 3ms
CREATE INDEX tdate ON salaries (to_date);
Run복사<br>Note408ms -&gt; 3ms<br><br>DROP INDEX tdate ON salaries;
Run복사<br><br>-- 변수선언
SET @data = 1;

-- 선언된 변수 출력
SELECT @data;

-- city 테이블에서
SET @RANK = 0;

SELECT @RANK := @RANK + 1 AS ranking, countrycode, name, population
FROM city
ORDER BY population DESC
LIMIT 5;
Run복사<br><br><br>InfoData Control Language<br>
데이터 제어어<br>
사용자의 권한을 부여하거나 빼앗을때 사용<br>
GRUNT, REVORKE, DENY<br><br>-- 사용자 권한 부여 명령어
GRANT ALL PRIVILEGES ON [dbname.table_name] TO [user@host] IDENTIFIED BY 'my_password';

-- 예제 (호스트 : 로컬호스트)
GRANT ALL PRIVILEGES ON testDB.testTable TO myuser@localhost IDENTIFIED BY 'testPassword';

-- 예제 (호스트 : 원격 접속)
GRANT ALL PRIVILEGES ON testDB.testTable TO myuser@'%' IDENTIFIED BY 'testPassword';

-- 예제 (호스트 : 아이피)
GRANT ALL PRIVILEGES ON testDB.testTable TO myuse@192.168.0.100 IDENTIFIED BY 'testPassword';
Run복사<br><br>-- 권한 해제 명령어(INSERT, UPDATE, CREATE 권한 해제)
REVOKE insert, update, create ON [dbname.table_name] TO [user@host];
 
-- 권한 해제 명령어(전체 권한 해제)
REVOKE ALL ON [dbname.table_name] TO [user@host];

-- 권한 확인 명령어
SHOW GRANTS FOR [user@host];
Run복사]]></description><link>root\dev\database\mysql-note.html</link><guid isPermaLink="false">root/dev/database/mysql note.md</guid><pubDate>Mon, 20 May 2024 16:36:19 GMT</pubDate></item><item><title><![CDATA[vscode mysql 플러그인 사용하기]]></title><description><![CDATA[ 
 <br><br><img alt="Pasted image 20240515174351.png" src="lib\media\pasted-image-20240515174351.png"><br>
<br>입력: mysql
<br>클릭: MySQL
<br>클릭: 설치
<br>클릭: Database
<br><br><br><img alt="Pasted image 20240515175233.png" src="lib\media\pasted-image-20240515175233.png"><br>
<br>클릭: Database
<br>클릭: AddConnection
<br>입력: EC3_MySQL_Test
<br>입력: 내 public IP
<br>입력: root
<br>입력: yeardream04
<br>클릭: Connect
<br>확인: Success
<br><br><br><img alt="Pasted image 20240515213851.png" src="lib\media\pasted-image-20240515213851.png"><br>
<br>클릭: filter
<br>클릭: 최상단
<br>확인
<br><br><br><br><img alt="Pasted image 20240515180219.png" src="lib\media\pasted-image-20240515180219.png"><br>
<br>클릭: Create Query
<br>엔터
<br><br><br><img alt="Pasted image 20240515215016.png" src="lib\media\pasted-image-20240515215016.png"><br>
<br>작성
<br>SELECT * FROM COLUMNS;

SELECT `COLUMN_NAME` FROM COLUMNS;
Run복사<br>
<br>클릭: Run
<br>확인
<br>클릭: Run
<br>확인
]]></description><link>root\dev\database\vscode-mysql-플러그인-사용하기.html</link><guid isPermaLink="false">root/dev/database/vscode mysql 플러그인 사용하기.md</guid><pubDate>Wed, 15 May 2024 12:57:49 GMT</pubDate><enclosure url="lib\media\pasted-image-20240515174351.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src="lib\media\pasted-image-20240515174351.png"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[도커 설치 및 기본 사용법]]></title><description><![CDATA[ 
 <br><br><br>sudo wget -qO- http://get.docker.com/ | sh
복사<br><br>
<br>도커는 실행할 때, 관리자 권한으로 실행 해야 한다.
<br>sudo를 일일이 입력하기 번거롭다면, 아래의 명령어를 입력한다.
<br><a data-tooltip-position="top" aria-label="https://davi06000.tistory.com/25" rel="noopener" class="external-link" href="https://davi06000.tistory.com/25" target="_blank">reboot 해줘야</a> 한다.
<br>sudo usermod -aG docker 사용자계정
복사<br>그리고 위의 사항이 잘 적용 됐는지 확인 하기 위해서<br>
다시 계정을 나갔다가 들어와서 아래의 명령어를 입력한다.<br>docker version
복사<br>만약 제대로 되지 않았다면, 올바른 정보를 출려하지 않고,<br>
sudo를 붙였을 때, 정보가 나타날 것이다.<br><br><br>docker search ubuntu
복사<br><br><a rel="noopener" class="external-link" href="https://hub.docker.com" target="_blank">https://hub.docker.com</a> -&gt; Browse popular images<br>
-&gt; 찾고 싶은 이미지 이름 클릭 -&gt; Tag 탭 클릭<br><br>docker pull ubuntu:22.04
복사<br><br>docker images
복사<br><br><br><br># docker run -i -t ubuntu:18.04 /bin/bash
# 예전 버전
docker run -it ubuntu:22.04 bash
# 마지막의 /bin/bash를 실행해야 한다.

docker container run -d --name web -p 3000:3000 duddy/dc:docker-test1
# 좀 더 자세하게
복사<br><a rel="noopener" class="external-link" href="https://fronquarry.tistory.com/27" target="_blank">https://fronquarry.tistory.com/27</a><br><br><br>
<br>사용자의 입출력을 허용 함
<br><br>
<br>가상 터미널 환경을 에뮬레이터 함  
<br>Note이 옵션을 사용해야만 bash를 띄워서 명령을 입출력 할 수 있음<br><br>Note도커는 vmware와 같은 가상 머신과 다르게<br>
메인 실행 파일을 실행 시켜줘야 한다.<br>
때문에 이렇게 마지막에 시작 해야할 프로그램을 실행 시켜준다.<br><br>Note도커에서 이미지를 pull 해서 가지고 온 우분투 이미지는<br>
아무것도 없고, 거기에서 ps를 해보면 bash와 ps 말고는 실행된 게 없다.<br>
그렇기 때문에 이 안에서 뭔가를 설치하면 apt-get update를 필수로 해줘야<br>
프로그램을 설치 할 수 있는 환경이 만들어 진다.<br><br><br><br>exit
복사<br><br>docker ps -a
복사<br>Notedocker ps -a 명령의 출력 결과물의 맨 마지막 컬럼에 name을 보면<br>
뭔가 임의로 만들어진 문자열을 볼 수 있다.<br>
실행 절차에서 이름을 정해줬더라면 그 이름을 썼겠지만<br>
그렇지 않았기 때문에 생긴 이름이다.<br><br><br><br>docker start container_id
# 혹은
docker start container_name
복사<br>docker start 8915d6dbee06

docker start ubuntu:22.04
복사<br>위에서 실행할 때 run으로 했고, 지금은 start로 실행한다.<br>
차이는 run은 실행하고, 안으로 들어가는 것이고,<br>
start는 밖에서 실행만 한다는게 요점이다.  <br><br><br><br>sudo docker ps -a
복사<br><br><br>docker attach container_id
# 혹은
docker attach container_name
복사<br>docker attach 8915d6dbee06

docker attach ubuntu:22.04
복사<br><br><br>ctrl + p + q
복사<br>이는 bash의 단축키다.<br><br><br>docker rm container_id
# 혹은
docker rm container_name
복사<br><br><br>docker exec container_id 명령어
# 혹은
docker exec container_name 명령어
복사<br><br><br><br><br>docker rmi container_id
# 혹은
docker rmi container_name
복사<br><br><br>docker pull nginx:latest
# latest는 항상 최신 버전을 가르킨다.
복사<br><br>docker run -d --name hello-nginx nginx:latest
# 데몬을 실행하기 때문에 /bin/bash같이 실행파일을 지정하지 않아도 된다.
복사<br><br>docker run -d --name hello-nginx -p 8000:80 nginx:latest
# -p 8000:80 === 호스트:컨테이너
복사<br><br>도커는 이미지와 컨테이너가 나뉘고<br>
이미지로 컨테이너를 만든다.<br>
컨테이너를 만들고, 그 안에서 어떤 작업을 하여<br>
자료를 저장하거나 지울 때에는,<br>
기존의 이미지에 영향을 미치는 가상 머신과는 다르게<br>
이미지에 영향은 받지 않는다.<br>때문에 하나의 이미지로 여러 개의 컨테이너를 만들어서<br>
각기 다른 환경에서 서로 아무런 작용 없이 작업을 할 수 있다.<br>이것은 마치 git의 브런치 같은 느낌을 준다.<br>하지만 좀 더 명확하게 설명하자면<br>이미지는 prototype,<br>
그리고 그 prototype을 기반으로 쌓아 올린 객체,<br>
동일한 props를 지우거나 삭제, 혹은 변경을 한다면,<br>
오버라이딩 하여 값을 처리하는 느낌이다.]]></description><link>root\dev\docker\도커-설치-및-기본-사용법.html</link><guid isPermaLink="false">root/dev/docker/도커 설치 및 기본 사용법.md</guid><pubDate>Fri, 12 Apr 2024 07:50:42 GMT</pubDate></item><item><title><![CDATA[docker note]]></title><description><![CDATA[ 
 <br><br><br>docker login
복사<br><br>docker info | grep -i username
복사<br><br>docker logout
복사<br><br>docker image tag tagname:1.0 username/tagname:1.0
docker push username/tagname:1.0
복사<br><br><br><br>docker images
복사<br><br>docker pull 이미지_이름:버전
# docker pull ubuntu:22.04
# docker pull ubuntu:latest
# docker pull eninx:latest
복사<br><br><a rel="noopener" class="external-link" href="https://hub.docker.com" target="_blank">https://hub.docker.com</a> <br>docker search 이미지이름
# docker search ubuntu
복사<br><br>FROM nginx:latest
COPY index.html /usr/share/nginx/html/index.html
EXPOSE 80
CMD ["nginx", "-g", "daemon off;"]	
# ---&gt; 해당 이미지가 docker run 으로 컨테이너화가 될때 내부에 데몬 실행
복사<br>집중!파일 Dockerfile 다른 것으로 하면 안됨<br>docker build -t your-image-name .
# docker build -t testweb:1.0 .
복사<br><br>docker rmi container_id
# 혹은
docker rmi container_name
복사<br><br><br><br><br>docker ps
복사<br><br>docker ps -a
복사<br><br><br>docker create -i -t --name 컨테이너_이름 이미지_이름:버전
# docker create -i -t --name myUbuntu ubuntu:latest
복사<br>Info
<br>-i 상호 입출력
<br>-t tty를 활성화하여 bash 셸을 사용하도록 컨테이너에서 설정.

이 두 옵션을 사용하지 않으면 shell을 사용할 수 없음<br><br>docker create -p 8001:80 --name 컨테이너_이름 이미지_이름:버전
# docker create -p 8001:80 --name myUbuntu enginx:latest
복사<br>Info
<br>-p a:b: 포트포워딩

이렇게 하면 a를 b로 접근 시켜준다<br><br>docker start 컨테이너_이름
복사<br><br>docker attach 컨테이너_이름
복사<br><br>단축키Ctrl + P + Q<br><br>docker rm 컨테이너_이름
# docker rm myUbuntu
복사<br><br><br><br>docker cp 복사대상파일 tag:/경로
복사]]></description><link>root\dev\docker\docker-note.html</link><guid isPermaLink="false">root/dev/docker/docker note.md</guid><pubDate>Sun, 05 May 2024 15:36:20 GMT</pubDate></item><item><title><![CDATA[간단 ssh github 인증]]></title><description><![CDATA[ 
 <br><br> ssh-keygen -t rsa -C "your_email@example.com"
복사<br><br><br><img alt="Pasted image 20240417140113.png" src="lib\media\pasted-image-20240417140113.png"><br><br><br>ssh -T git@github.com
복사<br>CheckHi [user-name]! You've successfully authenticated, but GitHub does not provide shell access.]]></description><link>root\dev\github\간단-ssh-github-인증.html</link><guid isPermaLink="false">root/dev/github/간단 ssh github 인증.md</guid><pubDate>Thu, 18 Apr 2024 15:29:40 GMT</pubDate><enclosure url="lib\media\pasted-image-20240417140113.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src="lib\media\pasted-image-20240417140113.png"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[이어드림 DE ssh 보안 업데이트 수동]]></title><description><![CDATA[ 
 <br>진짜 중요!master-key.pem과<br>
같은 디렉토리에서 작업을 해야함<br><br>mkdir ssh-connection
cd ssh-connection
vi master-key.pem
복사<br>아래를 붙여 넣기<br>-----BEGIN RSA PRIVATE KEY-----
MIIEowIBAAKCAQEA3iDpFLZokx4Ur5Tsa3nRKnrxbSIm7hL4BHDvJMtpokBSbOdm
djLqYMoX2yr3l+HzJ87HzPeJnXHHWunF2zxlENXqyXoT3b3Re50T5KVrz5r/p3ne
BQ5lOD+I+bTKfTVzPF0PJWeVxXt3YiyqDzSrpjiBnxH6Mdo54mB8rfswwu1Snml7
hPJhsOjYeeBS0KgsmcJS3gdhNOxuaTOsIIV8f2iLeAAiyiJTd/3goH718NfeHN3e
RGfLg0AGHK18IWpHKEgLU9jE79O1KqAx2rkItMfcd3eFvOvDKVxtq7ZbJm+RqRwi
ZNdTv/EGXXKKylo7G7cEnWgF7rqGWDvqNGehpwIDAQABAoIBAQCcuVu64XinVHID
8G9e5XRPJK9y8MXG9FtJxuT0cRD3Casea6Y/f20fHXf3izlmUGXfkGYol/7gt4aQ
/qA7L0Gfv08JGLkrmuJS9WEz0gNfV11KLRIZPy7roOhkRssXzL6huIcXPR7PV23E
Nv9F+0Og4/2Q3n5I7lApCSrvFmwxGzDIv1y2plv2A+nwZXpH1eRDN2gZGffAwg2+
q1Wtj3y0tY36JV8IF9JzJPDQbcwVzC0pjNVZQj+8dRI358Zq1zmC2lROCvsgaPkU
D/gr34M1ZKrAy3ZH6Wy4gCpTn825wFKITpJDh+PuQuU7BWmi5/7cClPHd3ph0FIz
mJIL6zkBAoGBAPFQ6bdhg/9VAoh+FJSWQgXYou4zLKmYsjk5R4pivfXwtS6aISPe
EmCUV2lGge0kxuq4lL6jzzXdESMgKKQbHKSbRBfWGX9lW2L4Newlp+3s/IKV3F07
T+fME9cb2LcY0m0DVpKgJPA1BNycqEhoNcc+r/CbikrIT07/esJsCfYbAoGBAOul
Gu4uZfRcboz+A319dEHl/xZFJs3I6BnmcC62qg9Nwg1pMOH4VlAEHmImnnLlzDH8
rcINPkU5d56Hn/WB+dAdSwrUj5Bq6ZBlvgCjCtIHLMosEY1huJ7DnLmH1l6kH9I4
GhkldcIGXfiDbtFOu+q3mHDrTd1hLXPqJTiWmStlAoGAbBe+WPJJWhoOJG21cklM
EapUcTZjDyTi0FckAIzyYjQMNG+94H8c5D4OWY3HrR4ILCO6HRrrOkln38AL9FZg
oisaeULh8PrJ0K82GC1V53F8OlI+f1SOGlqDmJtUm892knYoVU1+vkpBf0B88NId
JL6juLczXwQS4mP17RjP7XkCgYAv3kU/Nxus7Q3kBEGvP0nbjR4pZvi/+tzzTfVh
9+dJ3pDZ6pFsheb6sCt/4rpzOq0lRmABuHD63PaotIJQ/AtENH8m/xD+1EkH9TMI
rBYpnh2CIDucjcpULgZrReXNKefw60aZ7xshw+tY7VIYoLbZslv8LECQBQqXrmvL
OAR7ZQKBgCH/NqqMDuRBCQ0+ur2RLqjMEmKxWrnbfSn0Uetr8YvagSzqOzOyM/xk
FZYIwJCOUb4JlE8NscoHdXRbcjwWXGKlbUNM523URo0Nfa7NEoVXlSGtl82X++Rp
ySCslDCgiOafpOviJND5INLatij9QVTRBAFlqyJjoOzZwambss7C
-----END RSA PRIVATE KEY-----
복사<br>:wq
복사<br><br><br>집중!업데이트 하기 전에
ssh ubuntu@아이피_주소 -i ./master-key.pem
이거 하고 접속 되는 거 확인하고 해야 해!<br>
접속이 안되면 아래의 과정이 소용이 없음.<br><br>sudo ssh-keygen -t rsa -P '' -f new-master-key
복사<br><br>sudo scp -i ./master-key.pem \
    new-master-key.pub \
    ubuntu@인스턴스_아이피:/home/ubuntu/.ssh 
복사<br><br>sudo ssh -i ./master-key.pem \
    ubuntu@인스턴스_아이피 \
    "cd ~/.ssh &amp;&amp; cat new-master-key.pub &gt; authorized_keys"
복사<br>집중!일단
ssh ubuntu@아이피_주소 -i ./master-key.pem
접속 해보자. 여기서 접속이 안된다고 하면 성공
그리고 
ssh ubuntu@아이피_주소 -i ./new-master-key
이렇게 접속 한다면 일단은 성공<br><br>sudo chmod 600 master-key.pem  # 키 삭제 권한 부여
mv new-master-key master-key.pem
sudo chmod 400 master-key.pem
rm new-master-key.pub
복사<br>Cite여기까지 하면 ssh-connection 디렉토리엔 딸랑 master-key.pem 파일만 남을 것이다.<br>
그럼 다시
ssh ubuntu@아이피_주소 -i ./master-key.pem
접속을 해보고 성공 한다면, 우리 조금만 더 편해져 보자.<br><br><br><br>Note장인의 손맛은 어지러울 수 있기 때문에 요약부터<br>cd ..
mv ssh-connection ~/.key
vi join.sh
복사<br>ssh ubuntu@아이피_주소 -i ~/.key/master-key.pem
복사<br>sudo chmod +x ./join.sh
./join.sh
복사<br>경고?가독성...<br><br><br>cd ..
복사<br>해서<br><br>mv ssh-connection ~/.key
복사<br>하고<br><br>cd
복사<br>홈으로 가서<br><br>vi join.sh
복사<br>하고<br><br>ssh ubuntu@아이피_주소 -i ~/.key/master-key.pem
복사<br>한 다음에<br><br>sudo chmod +x ./join.sh
복사<br>그리고<br><br>./join.sh
복사<br>하면 잘 접속 될 걸?? 되겠지????]]></description><link>root\dev\linux\이어드림-de-ssh-보안-업데이트-수동.html</link><guid isPermaLink="false">root/dev/linux/이어드림 DE ssh 보안 업데이트 수동.md</guid><pubDate>Mon, 06 May 2024 16:33:55 GMT</pubDate></item><item><title><![CDATA[crontab 예약하기]]></title><description><![CDATA[ 
 <br><br><br>cd ~/LABs
복사<br><br>vi log_backup.sh
복사<br><br>#!/bin/bash
set $(date)
fname="$6-$2-$3-backup"
tar -cvzf /home/ubuntu/LABs/$fname.tar.gz /var/log
복사<br><br>chmod 700 log_backup.sh
복사<br><br>./log_backup.sh
복사<br><br><br><br>crontab -e
복사<br><br>53 01 * * * /home/ubuntu/script/log_backup.sh
복사<br><br>vi /var/mail/ubuntu
복사]]></description><link>root\dev\linux\crontab-예약하기.html</link><guid isPermaLink="false">root/dev/linux/crontab 예약하기.md</guid><pubDate>Tue, 30 Apr 2024 02:19:35 GMT</pubDate></item><item><title><![CDATA[ubuntu node]]></title><description><![CDATA[ 
 <br><br>cat /etc/os-release
복사<br><br><br>tar -cvf 압축할이름.tar 디렉토리
복사<br>tar -xvf 압축파일이름.tar
복사<br><br><br>sudo apt install sysstat

sar 2 2
복사<br>2초마다 2번 출력 해라<br>
끝나면 통계도 출력 함<br>sar 2 100 &gt; sar-server1-$(date '+%y-%m-%d').log
복사<br><br><br><br>set -o noclobber
복사<br><br>set +o noclobber
복사<br><br><br>ssh 사용자이름@공개아이피 -i ssh키
복사<br><br><br>alias pscheck='ps -ef | grep $proc'

alias pscheck ssh
복사<br>Note$proc 인자값 처리<br>alias syscall='sudo systemctl $status $proc'

syscall status nginx
복사<br><br><br><br>sudo useradd name

sudo passwd name
복사<br><br>/etc/passwd

/etc/shadow
복사<br><br><br><br>vi .bash_history
복사<br><br>history
!39
복사<br>history 안에 있는 39번째 있는 라인을 실행<br><br><br>PS1='[\h@\w]\$ '
복사<br><br><br>file name
복사<br><br><br>0.0.0.0
복사<br><br><br>more filename
복사<br>cat 대신 단위로 열 수 있네~<br><br><br>sudo tail -f /var/log/nginx/access.log

# 끝에서 3줄만

sudo tail -3 /var/log/nginx/access.log

# 첫줄에서 3줄

sudo head -3 /var/log/nginx/access.log
복사<br><br>awk '{ print $1 }' /var/log/nginx/access.log
복사<br>ubuntu@ip-172-31-6-186:~$ awk '{ print $1 }' /var/log/nginx/access.log | sort | uniq -c | sort -r

	 24 39.114.126.77

		4 74.82.47.3

		3 118.26.39.231

		2 59.88.181.192

		1 71.6.232.24

		1 66.175.213.4

		1 198.235.24.25

		1 172.104.210.105

		1 172.104.11.46

		1 127.0.0.1
복사<br><br><br>ubuntu@ip-172-31-6-186:~$ which adduser

/usr/sbin/adduser

ubuntu@ip-172-31-6-186:~$ which useradd

/usr/sbin/useradd
복사<br><br><br><br>ln test intest
복사<br>
<br>원본파일이 깨져도 괜찮다.
<br><br>ln data1 data1.sl
복사<br>
<br>소프트링크: 원본 깨지면 깨짐 
<br><br><br><br>echo $PATH
복사<br><br>#!/bin/bash
echo -------------------------------------------------
echo 'current time is' $(date '+%Y-%m-%d:%H-%M-%S')
echo -------------------------------------------------
복사<br>파일이 있는 경로를<br>PATH=$PATH:/home/ubuntu/script
복사<br>하면<br>cd
time.sh
복사<br>했을 때<br>-------------------------------------------------
current time is 2024-05-01:00-06-04
-------------------------------------------------
복사<br>출력<br>Warning이렇게만 하면 세션을 나갔다 다시 들어오면 초기화 된다.<br>
때문에 .bashrc에 추가 해야지 초기화 되지 않는다.<br># 이 코드를 추가
PATH=$PATH:/home/ubuntu/script
복사<br><br><br>기본 보안 수준을 설정한다.<br>umask 002
복사<br><br><br>
<br>
최상위 프로세스 (부모, PID=1) -&gt; systemd (init process)

<br>
nginx container -&gt; docker exe -it

<br>nginx가 pid=1


<br>
데몬: 백그라운드에서 돌아가는 프로세스

<br><br><br>
<br>

<br>SIGTERM: 정상종료(graceful shutdown)


<br>

<br>SIGKILL: 비정상종료( shutdown)


<br>Note프로세스는 디렉토리와 같다?<br>ubuntu@ip-172-31-6-186:~$ pstree -p | grep nginx
           |-nginx(16156)---nginx(16157)
ubuntu@ip-172-31-6-186:~$ ls /proc/16156
ls: cannot read symbolic link '/proc/16156/cwd': Permission denied
ls: cannot read symbolic link '/proc/16156/root': Permission denied
ls: cannot read symbolic link '/proc/16156/exe': Permission denied

arch_status         environ            mem            personality   status
attr                exe                mountinfo      projid_map    syscall
autogroup           fd                 mounts         root          task
auxv                fdinfo             mountstats     sched         timens_offsets
cgroup              gid_map            net            schedstat     timers
clear_refs          io                 ns             sessionid     timerslack_ns
cmdline             ksm_merging_pages  numa_maps      setgroups     uid_map
comm                ksm_stat           oom_adj        smaps         wchan
coredump_filter     limits             oom_score      smaps_rollup
cpu_resctrl_groups  loginuid           oom_score_adj  stack
cpuset              map_files          pagemap        stat
cwd                 maps               patch_state    statm
복사<br><br><br><br>향상된 모니터링을 제공<br><img alt="Pasted image 20240429173736.png" src="lib\media\pasted-image-20240429173736.png"><br>sudo apt -y install glances

sudo glances
복사<br><br>sudo apt -y install all

dstat --all
복사<br><img alt="Pasted image 20240429173923.png" src="lib\media\pasted-image-20240429173923.png"><br>과부화 테스트도 가능]]></description><link>root\dev\linux\ubuntu-node.html</link><guid isPermaLink="false">root/dev/linux/ubuntu node.md</guid><pubDate>Wed, 01 May 2024 03:16:01 GMT</pubDate><enclosure url="lib\media\pasted-image-20240429173736.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src="lib\media\pasted-image-20240429173736.png"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[docker mlops 빌드 및 실행]]></title><description><![CDATA[ 
 <br><br><br>sudo apt-get update
sudo apt-get install -y unzip
mkdir workspace
cd workspace
wget https://github.com/namugach/mlops-study/archive/refs/heads/master.zip
unzip master.zip
cd mlops-study-master/mlops-movie-predictor
복사<br><br><a data-href="docker network 생성" href="root\dev\mloops\docker-network-생성.html" class="internal-link" target="_self" rel="noopener">docker network 생성</a><br><br><br>docker build -t my-mlops:v1 .
복사<br><br><br>docker container run -itd --name my-mlops \
  -e WANDB_API_KEY=c9177943bdd16a302be32788ed7c28f35347f005 \
  -e DB_USER=root \
  -e DB_PASSWORD=root \
  -e DB_HOST=my-mlops-db \
  -e DB_PORT=3306 \
  --network mlops \
  my-mlops:v1
복사<br><br><br><br>docker exec -it my-mlops env
복사<br><br>PATH=/usr/local/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
HOSTNAME=ca0e5d05d3c7
TERM=xterm
DB_PORT=3306
WANDB_API_KEY=c9177943bdd16a302be32788ed7c28f35347f005
DB_USER=root
DB_PASSWORD=root
DB_HOST=my-mlops-db
LANG=C.UTF-8
GPG_KEY=A035C8C19219BA821ECEA86B64E628F8D684696D
PYTHON_VERSION=3.11.4
PYTHON_PIP_VERSION=23.1.2
PYTHON_SETUPTOOLS_VERSION=65.5.1
PYTHON_GET_PIP_URL=https://github.com/pypa/get-pip/raw/0d8570dc44796f4369b652222cf176b3db6ac70e/public/get-pip.py
PYTHON_GET_PIP_SHA256=96461deced5c2a487ddc65207ec5a9cffeca0d34e7af7ea1afc470ff0d746207
HOME=/root
복사<br><br><br>실행하기 전에<a data-href="mlops mysql 컨테이너 연결" href="root\dev\mloops\mlops-mysql-컨테이너-연결.html" class="internal-link" target="_self" rel="noopener">mlops mysql 컨테이너 연결</a>
이거부터 확인<br><br>docker exec -it my-mlops python src/main.py preprocessing --date 240813
복사<br><br>docker exec -it my-mlops python src/main.py train --model_name movie_predictor --optimizer adam
복사<br><br><br>docker exec -it my-mlops python src/main.py inference \
--data "[1, 1209290, 4508, 7.577, 1204.764]" \
--batch_size 1
복사<br><br>docker exec -it my-mlops python src/main.py inference
복사<br><br><br><br>docker container run -itd --name my-mlops-api \
-e WANDB_API_KEY=c9177943bdd16a302be32788ed7c28f35347f005 \
-e DB_USER=root \
-e DB_PASSWORD=root \
-e DB_HOST=my-mlops-db \
-e DB_PORT=3306 \
-p 9999:8000 \
--network mlops \
my-mlops:v1
복사<br><br>docker exec -it my-mlops-api python src/main.py train --model_name movie_predictor --optimizer adam
복사<br><br>docker exec -d my-mlops-api bash start_api_server.sh
복사<br><br><br>http://공개_ip:9999/docs
복사<br><br>http://127.0.0.1:9999/docs
복사]]></description><link>root\dev\mloops\docker-mlops-빌드-및-실행.html</link><guid isPermaLink="false">root/dev/mloops/docker mlops 빌드 및 실행.md</guid><pubDate>Mon, 12 Aug 2024 18:54:55 GMT</pubDate></item><item><title><![CDATA[docker network 생성]]></title><description><![CDATA[ 
 <br><br>docker network create --gateway 172.20.0.1 --subnet 172.20.0.0/24 mlops
복사<br><br><br>ubuntu@ip-172-31-23-166:~$ docker network ls
NETWORK ID     NAME      DRIVER    SCOPE
14fc8c65bc96   bridge    bridge    local
ae569fc79b54   host      host      local
299688b5d3d9   mlops     bridge    local
06be7d2218af   none      null      local
복사<br><br><br>docker run -itd --name my-mlops --network mlops python:3.11-buster
복사]]></description><link>root\dev\mloops\docker-network-생성.html</link><guid isPermaLink="false">root/dev/mloops/docker network 생성.md</guid><pubDate>Mon, 12 Aug 2024 18:56:01 GMT</pubDate></item><item><title><![CDATA[mlops docker github action 연결하기]]></title><description><![CDATA[ 
 <br>작업 환경windows: wsl2
mac도 비슷할 것임.<br><br><br><br>cd
복사<br><br>vi Dockerfile
복사<br><br># Ubuntu 기반의 Docker 이미지 생성
FROM ubuntu:24.04

# 필수 패키지 설치
RUN apt-get update &amp;&amp; \
  apt-get install -y \
  docker.io \
  openssh-server \
  curl \
  net-tools \
  git \
  wget \
  tree \
  vim \
  &amp;&amp; rm -rf /var/lib/apt/lists/*

# .bashrc 파일을 root 홈으로 복사
RUN cp /home/ubuntu/.bashrc /root/.bashrc


# SSH 설정
RUN mkdir /var/run/sshd &amp;&amp; \
  sed -i 's/#PermitRootLogin prohibit-password/PermitRootLogin yes/' /etc/ssh/sshd_config

# 포트 22 열기
# EXPOSE 22

# Docker 데몬과 SSH 데몬을 동시에 실행
CMD ["/bin/bash", "-c", "dockerd &amp; /usr/sbin/sshd -D"]
복사<br><br>docker build -t ubuntu-dind:v1 .
복사<br><br>중요!!docker 컨테이너 안에서 docker를 사용할 때는
꼭--privileged 
옵션을 붙여서 컨테이너를 생성해야 한다.<br><br>docker container run --privileged -itd --name ml-pipe ubuntu-dind:v1
복사<br><br>docker container exec -it ml-pipe bash
복사<br><br><br>docker container ls
복사<br><br>ONTAINER ID   IMAGE     COMMAND   CREATED   STATUS    PORTS     NAMES
복사<br><br><br><br>curl -sSL https://install.python-poetry.org | python3 -
복사<br><br>vi ~/.bashrc
복사<br><br>export PATH="/root/.local/bin:$PATH"
복사<br><br>source .bashrc
복사<br><br>poetry --version
복사<br><br><br><br><br><img alt="Pasted image 20240814013010.png" src="lib\media\pasted-image-20240814013010.png"><br><img alt="Pasted image 20240814013151.png" src="lib\media\pasted-image-20240814013151.png"><br><br><img alt="Pasted image 20240814014038.png" src="lib\media\pasted-image-20240814014038.png"><br><img alt="Pasted image 20240814014048.png" src="lib\media\pasted-image-20240814014048.png"><br>git clone https://github.com/namugach/my-django-backend.git
복사<br><br><img alt="Pasted image 20240814014411.png" src="lib\media\pasted-image-20240814014411.png"><br>cd my-django-backend
git remote -v
복사<br><br><img alt="Pasted image 20240814014514.png" src="lib\media\pasted-image-20240814014514.png"><br>vi README.md
복사<br><img alt="Pasted image 20240814014540.png" src="lib\media\pasted-image-20240814014540.png"><br>원하는 내용을 입력
복사<br>저장 및 종료<br><br><br><img alt="Pasted image 20240814014712.png" src="lib\media\pasted-image-20240814014712.png"><br>git status
복사<br><br><img alt="Pasted image 20240814014747.png" src="lib\media\pasted-image-20240814014747.png"><br>git add .
git status
복사<br><br><img alt="Pasted image 20240814014827.png" src="lib\media\pasted-image-20240814014827.png"><br>git commit -m "start"
복사<br><br><img alt="Pasted image 20240814014905.png" src="lib\media\pasted-image-20240814014905.png"><br>git log
복사<br><br><br><img alt="Pasted image 20240814014939.png" src="lib\media\pasted-image-20240814014939.png"><br>git push
복사<br><br><img alt="Pasted image 20240814015031.png" src="lib\media\pasted-image-20240814015031.png"><br><br><br><a rel="noopener" class="external-link" href="https://app.docker.com/" target="_blank">https://app.docker.com/</a><br>회원 가입/로그인<br><br><img alt="Pasted image 20240813171826.png" src="lib\media\pasted-image-20240813171826.png"><br><img alt="Pasted image 20240813171851.png" src="lib\media\pasted-image-20240813171851.png"><br><img alt="Pasted image 20240814022732.png" src="lib\media\pasted-image-20240814022732.png"><br>
<br>입력: my-django-backend
<br>선택: read, write, delete
<br>클릭
<br><img alt="Pasted image 20240814023045.png" src="lib\media\pasted-image-20240814023045.png"><br>
<br>클릭: 복사
<br><br><br><img alt="Pasted image 20240814023358.png" src="lib\media\pasted-image-20240814023358.png"><br>
<br>확인
<br>클릭
<br>클릭
<br>클릭
<br><br><img alt="Pasted image 20240814023603.png" src="lib\media\pasted-image-20240814023603.png"><br>
<br>입력: DOCKERHUB_TOKEN
<br>입력: 복사한 토큰
<br>클릭
<br><img alt="Pasted image 20240814023727.png" src="lib\media\pasted-image-20240814023727.png"><br>
<br>확인
<br>클릭
<br><br><img alt="Pasted image 20240814024000.png" src="lib\media\pasted-image-20240814024000.png"><br>
<br>입력: DOCKERHUB_USER
<br>입력: docker hub 아이디
<br>클릭
<br><img alt="Pasted image 20240814024116.png" src="lib\media\pasted-image-20240814024116.png">]]></description><link>root\dev\mloops\mlops-docker-github-action-연결하기.html</link><guid isPermaLink="false">root/dev/mloops/mlops docker github action 연결하기.md</guid><pubDate>Tue, 13 Aug 2024 17:45:48 GMT</pubDate><enclosure url="lib\media\pasted-image-20240814013010.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src="lib\media\pasted-image-20240814013010.png"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[mlops mysql 컨테이너 연결]]></title><description><![CDATA[ 
 <br><br>docker container run -itd --name my-mlops-db \
  --network mlops \
  -e MYSQL_ROOT_PASSWORD=root \
  mysql:8.0.39
복사<br><br><br># 컨테이너 진입
docker exec -it my-mlops-db bash

# MySQL 로그인
mysql -u root -p  # root 패스워드 입력

# 데이터베이스 생성
create database mlops;

# 생성 확인
show databases;

# 패스워드 인증 방식 변경(python mysqlclient 라이브러리 호환성)
alter user 'root'@'%' identified with mysql_native_password by 'root';
flush privileges;
복사]]></description><link>root\dev\mloops\mlops-mysql-컨테이너-연결.html</link><guid isPermaLink="false">root/dev/mloops/mlops mysql 컨테이너 연결.md</guid><pubDate>Mon, 12 Aug 2024 18:58:42 GMT</pubDate></item><item><title><![CDATA[pyenv 설치]]></title><description><![CDATA[ 
 <br><br>sudo apt-get update; sudo apt-get install make build-essential libssl-dev zlib1g-dev libbz2-dev libreadline-dev libsqlite3-dev wget curl llvm libncursesw5-dev xz-utils tk-dev libxml2-dev libxmlsec1-dev libffi-dev liblzma-dev
복사<br><br>curl https://pyenv.run | bash
복사<br><br>export PYENV_ROOT="$HOME/.pyenv"
[[ -d $PYENV_ROOT/bin ]] &amp;&amp; export PATH="$PYENV_ROOT/bin:$PATH"
eval "$(pyenv init -)"
eval "$(pyenv virtualenv-init -)"
복사<br>Info.bashrc 하단에 추가]]></description><link>root\dev\python\pyenv-설치.html</link><guid isPermaLink="false">root/dev/python/pyenv 설치.md</guid><pubDate>Sun, 02 Jun 2024 17:36:44 GMT</pubDate></item><item><title><![CDATA[pyenv 실습]]></title><description><![CDATA[ 
 <br>
<br><a data-href="root/dev/python/pyenv 설치" href="root\dev\python\pyenv-설치.html" class="internal-link" target="_self" rel="noopener">root/dev/python/pyenv 설치</a>
<br><br>pyenv install --list
복사<br><br>pyenv install 3.11.9
복사<br><br>pyenv activate py3_11_9
pip install pandas
pip install scikit-learn
pip install flask
pip install gunicorn
pip install psycopg2-binary
복사<br><br>nohup python pytest02.py &gt; /dev/null 2&gt;&amp;1 &amp;
복사<br><br>ps -ef | grep pytest02
복사<br><br>kill -9 23978
복사]]></description><link>root\dev\python\pyenv-실습.html</link><guid isPermaLink="false">root/dev/python/pyenv 실습.md</guid><pubDate>Mon, 05 Aug 2024 01:25:26 GMT</pubDate></item><item><title><![CDATA[python note]]></title><description><![CDATA[ 
 <br>
<br><a data-tooltip-position="top" aria-label="https://velog.io/@dkwjd131/%EC%9E%91%EC%84%B1%EC%A4%91Python-regex-%EC%A0%95%EA%B7%9C%ED%91%9C%ED%98%84%EC%8B%9D" rel="noopener" class="external-link" href="https://velog.io/@dkwjd131/%EC%9E%91%EC%84%B1%EC%A4%91Python-regex-%EC%A0%95%EA%B7%9C%ED%91%9C%ED%98%84%EC%8B%9D" target="_blank">https://velog.io/@dkwjd131/작성중Python-regex-정규표현식</a>
<br><br>a = 10
b = 20
print(a + b)
Run복사<br>a, b = 1, 2
print(a, b) # 1, 2 완전 쩔어?!
Run복사<br><br><br>phone = "갈럭시"
usage = 50.888

print("%s 베터리 %d%% 남았음" % (phone, usage))
print("%s 베터리 %.2f%% 남았음" % (phone, usage))

print("{} 베터리 {}% 남았음".format(phone, usage))
print("{} 베터리 {:.2f}% 남았음".format(phone, usage))

print(f"{phone}베터리 {usage}% 남았음")
print(f"{phone}베터리 {usage:.2f}% 남았음")
Run복사<br><br><br><br>s = "Life is too short."
s.split('i') # token
Run복사<br><br>s = "Life is too short."
# Life를 This pencil로 바꿔봅시다.
s.replace("Life", "This pencil")
s.replace(" ", "")
Run복사<br><br><br><br>def sum(a, b):
	return a + b
print(sum(1, 2))
Run복사<br><br>f = lamda a, b : a + b
print(f(3, 5))
Run복사<br><br>def call_back(lam):
	return lam(10)

print(call_back(lambda num : num + 20)) # 30
Run복사<br><br>def add(a, b)
	'''
	a, b: integer
	return: a, b를 입력 받아서 더한 값
	'''
	c = a + b
	return c
Run복사<br><br>def add(a:int, b:int): -&gt; int
	c = a + b
	return c
Run복사<br><br>def add_many(*args):
    print(args) # (1, 2, 3, 4, 5)

add_many(1, 2, 3, 4, 5)
Run복사<br>튜플로 받을 수 있음<br><br><br>
name = "kim"

def change_name()
	global name = "what 쓰지마 이거"

change_name()

print(name) # "what 쓰지마 이거"
Run복사<br><br><br>Note배열이라고 하지 않고 리스트라고 함<br><br>
L3 = [1, "Hi", 3.14, [1, 2, 3]] 
print(L3) # [1, 'Hi', 3.14, [1, 2, 3]]
Run복사<br><br>L = [1, 2, 3, 4, 5]
L[0] # 1
Run복사<br><br># L의 첫번째부터 index2 까지 자르기
L[0:2]
# 두번째 부터 네번재까지 자르기
L[1:4]
# 생략가능
L[:3] # start를 생략하면 맨 앞부터
L[1:] # end를 생략하면 맨 뒤까지

L[:-1] # 맨 마지막 원소 제외하고 나머지
L[-1:]

L[2:-1] #end 부터 start까지
len(L)
L[1:len(L)] == L[1:] # True


# L[start:end:step]
a = L[0:5] # 1, 2, 3, 4, 5
b = L[0:5:2] # 1, 3, 5
c = L[::-1] # 5, 4, 3, 2, 1
d = L[::-2] # 5, 3, 1
print(a) # [5, 4, 3, 2, 1] 
print(b) # [5, 3, 1] 
print(c) # [1, 2, 3, 4, 5] 
print(d) # [1, 3, 5]

Run복사<br><br>L = [1, 2, 3]
L2 = [4, 5]
print(L + L2) # [1, 2, 3, 4, 5]  concatenation

L * 3 # [1, 2, 3, 1, 2, 3, 1, 2, 3]

Run복사<br><br>L = [1, 2, 3]
L = [1, 2, 3, 4, 5]
L2 = [4, 5]
print(L + L2) # [1, 2, 3, 4, 5, 4, 5]
Run복사<br><br>L = []
L.append(3)
L.append(2)
L.append(1)
Run복사<br><br><br># sort()를 이용해 L을 정렬합니다.
L = [4, 3, 16]
sorted(L) # 원본 보존
L
L.sort()
L # 원본 훼손
L.sort(reverse=True)
L # 내림차
Run복사<br><br>names = ["kim", "park", "chang", "jessica"]
names.sort(key=lambda s : len(s), reverse=True)

names
Run복사<br><br>
inputs = input("숫자 여러개 입력하라: e.g. 1, 2, 3, 4, ...")

# 특정 원소 표현을 가지는 리스트를 만들고 싶을 때 사용
total = [int(x) for x in inputs.split(",")]
print(total, sum(total))

# 매우 좋고만

Run복사<br><br>def cut_string(word:str, separator:str = ",") -&gt; list:
	return [w for w in word.split(separator)]

print(cut_string("와, 이렇게, 하면, 어떨까?"))
# ['와', ' 이렇게', ' 하면', ' 어떨까?']

Run복사<br>## 입력: a, b, c, d, ...., asdf, qwer, dfd
## 출력: a b c d .... asdf qwer dfd
## 조건: split() 함수에서 ','를 쓰지 않고 빈 칸으로 잘라서 사용하시오.
temp = "a, b, c, d, ...., asdf, qwer, dfd"

outputs = []
for x in temp.split():
	x = x[:-1]
	# x = x.replace(", ", "")
	outputs.append()
	

ourputs = [x[:-1] for x in temp.split()]

for x in outputs:
	print(x, end = " ")
Run복사<br><br><br><br>arr:list = [1,2,3,4]
for elem in arr:
	print(elem)
Run복사<br><br><br><br>coffees = ['아메리카노', '카페라떼', '카페모카', '바닐라라떼', '핸드드립', '콜드브루']
prices = [4100, 4600, 4600, 5100, 6000, 5000]
Run복사<br><br>for i in range(len(coffees)):
	if prices[i] &lt;= 5000:
		print(f"{coffees[i]}: {prices[i]}원")
Run복사<br><br>for t in enumerate(prices):
	if t[1] &lt;= 5000:
		print(coffees[t[0]])

# 응용
for i, price in enumerate(prices):
	if price &lt;= 5000:
		print(coffees[i])
Run복사<br><br>for coffee, price in zip(coffees, prices):
if price &lt;= 5000:
	print(coffee)
Run복사<br><br><br>a: int = 10
b: str = "this is string"
c: float = 0.1
d: float = 0.2
a = "200" # 되기는 하는데 오류가 안뜨네.
print(0.1 + 0.2)
print(c + d) # 안된다...
Run복사<br><br><br>what = True
def huh():
	if what:
		print("wow")
	else:
		print("ooo!")
huh()
what = False
huh()
Run복사<br><br>test = False if 1 &lt; 2 else True
Run복사<br><br><br>obj = {
	"a": 10,
	"b": "wowo",
	"arr": [1, 2, 3]
}
obj["c"] = "huh??"
print(obj)
print(obj["a"])
print(obj["arr"][1])
for key in obj:
	print(f"key: {key}, value: {obj[key]}")
Run복사<br><br><br>D = {'name': 'kim', 'phone': '01012345679', 'birth': '1234'}

D.keys() # dict_keys(['name', 'phone', 'birth'])
D.values() # dict_values(['kim', '01012345679', '1234'])
D.items() # dict_items([('name', 'kim'), ('phone', '01012345679'), ('birth', '1234')])
print(D.get('name', 0)) # kim
Run복사<br><br>"phone" in D # True
"1234" in D.values() # True
Run복사<br><br><br>class Box():
	width = 100
	height = 100
	color = "#aaa"
	name = "box"
	def __init__(self, name):
		self.name = name
		
	def intro(self):
		print(f"My name is {self.name}!!")

boxA = Box("boxA")
boxA.intro()
Run복사<br><br>class Notebook:

	def __init__(self, 
							brand:str = "", 
							cpu:str = "", 
							ram:int = 0,
							year: int = "",
							weight: float = 0.1,
							os: str = "",
							color: str = "",
							price: int = 0) -&gt; None:
		self.brand = brand
		self.cpu = cpu
		self.ram = ram
		self.year = year
		self.weight = weight
		self.os = os
		self.color = color
		self.price = price
	def get_info(self):
		for key, value in vars(self).items():
			print(f"{key}: {value}")


nb = Notebook(
	brand = "느그",
	cpu = "뇌",
	ram = 256,
	year = 2024,
	weight = 2.1,
	os = "뭐?!",
	color = "#aaa",
	price = 7
)
nb.get_info()
Run복사<br><br><br>class Box():
	width = 100
	height = 100
	color = "#aaa"
	name = "box"
	def __init__(self, name):
		self.name = name
		
	def intro(self):
		print(f"My name is {self.name}!!")
	def huhOverride(self):
		print("Do it!!")

class PizzaBox(Box):
	def __init__(self, name):
		super().__init__(name)
		self.name = f"{name} pizza {super().name}"
	def huhOverride(self):
		super().huhOverride()
		print("what!!")

nene = PizzaBox("nene")
nene.intro()
nene.huhOverride()
Run복사<br><br><br>class Box():
	width = 100
	height = 100
	_color = "#aaa"
	name = "box"
	def __init__(self, name):
		self.name = name
		
	def intro(self):
		print(f"My name is {self.name}!!")
	def huhOverride(self):
		print("Do it!!")
	def getColor(self):
		return self._color
	
class PizzaBox(Box):
	__content = "empty"
	def __init__(self):
		super().__init__("pizza")
		self.name = f"{self.name} {super().name}"
	def setPizza(self, content):
		self.__content = content
	
	def checkPizza(self):
		print(self.__content)
	
	def getPizza(self):
		content = self.__content
		self.__content = "empty"
		return content

pizzaBox = PizzaBox()
pizzaBox.checkPizza()
pizzaBox.setPizza("basic pizza")
pizzaBox.checkPizza()
pizza = pizzaBox.getPizza()
pizzaBox.checkPizza()
print(f"Very delicious {pizza} Yum Yum~")
pizzaBox.intro()
Run복사<br><br><br>class Static:
	@staticmethod
	def print_now():
		print("ok")


Static.print_now()
Run복사<br><br><br>Note사용하기 위해서는 from abc import * 를 불러와야함.<br>from abc import *

class IBox():
	@abstractclassmethod
	def getName(self):
		pass
	def printInfo(self):
		pass

class GoldBox(IBox):
	name = "GoldBox"
	def getName():
		print(f"this name is {name}")
	pass

print(GoldBox().name)
Run복사<br><br><br>요론 느낌.<br><br>def so(func):
	print("what!1")
	func()
	print("what!2")

@so
def what():
	print("뭐!!!")
Run복사<br>def so(func):
	print("what!1")
	func()
	print("what!2")

so(lambda: print("뭐!!"))
Run복사<br>function so(func) {
	console.log("what1");
	func();
	console.log("what2");
}

so(() =&gt; {
	console.log("뭐!!")
})
Run복사<br><br>def so(func):
	def wrap():
		print("what!1")
		func()
		print("what!2")
	return wrap

@so
def what():
	print("뭐!!")

what()
Run복사<br>def so(func):
	def wrap():
		print("what!1")
		func()
		print("what!2")
	return wrap

what = so(lambda: print("뭐!!"))
what()
Run복사<br>function so(func) {
	return () =&gt; {
		console.log("what1");
		func()
		console.log("what2");
	}
}

let what = wow(() =&gt; {
	console.log("뭐");
})

what()

Run복사<br>def so(func):
	def wrap():
		print("what!1")
		func()
		print("what!2")
	return wrap

def what():
	print("뭐!!")

huh = so(what)
huh()
Run복사<br>function so(func) {
	return () =&gt; {
		console.log("what1");
		func();
		console.log("what2");
	}
}

function what() {
	console.log("뭐!!");
}

const huh = so(what);
huh();

Run복사<br><br><br>import re
Run복사<br><br>oldman_id = "911210-1234567"
res = re.search("(?&lt;=-\\d).+", oldman_id)
print(res.group()) #234567
Run복사<br>찾기<br><br>oldman_id = "911210-1234567"
print(re.sub("(?&lt;=-\\d).+", "******", oldman_id))
# 911210-1******
Run복사<br>치환<br><br><br>def div(a, b):
    try:
        return a / b
    except:
        print("0으로 나눌 수 가 있어?!!!??")


div(9, 3)
div("a", 5)
div(8, 0)
Run복사<br>def div(a, b):
    try:
        return a / b
    except ZeroDivisionError:
        print("0으로 나눌 수 가 있어?!!!??")
    except:
	    print("뭔가 잘 못 됐어!!")


div(9, 3)
div("a", 5)
div(8, 0)
Run복사<br><br><br><br>inputs = input("숫자 여러개 입력하라: e.g. 1, 2, 3, 4, ...")
print(inputs)
total = 0
for x in inputs.split(","):
	x = int(x)
	total += x
print(total)

Run복사<br><br><br><br>with open('./test.txt', 'r', encoding='utf-8') as f:
	text = f.read()
print(text)
Run복사<br><br># f.readline()를 통해 data 폴더안에 있는 test.txt를 read mode로 열어봅니다.
with open('./test.txt', 'r', encoding='utf-8')	as f:
	 lines = f.readlines()
Run복사<br><br># f.readlines()를 통해 data 폴더안에 있는 test.txt를 read mode로 열어봅니다.
txt = []
with open('./test.txt', 'r', encoding='utf-8')	as f:
	for line in f:
		txt.append(line)
Run복사<br># for문을 통해 data 폴더안에 있는 test.txt를 read mode로 열어서 출력해봅니다.
with open('./test.txt', 'r', encoding='utf-8')	as f:
	txt = [line for line in f]

print(txt)
Run복사<br><br># test.txt를 read mode로 열고 할 일이 끝나면 자동으로 닫는다.
output = []
with open('./test.txt', 'r', encoding='utf-8')	as f:
	for line in f:
		if 1 &lt; len(line[:-1]):
			output.append(line)


# 두글자 이상인 텍스트만 output list에 저장한다.

# result.txt로 output list에 있는 내용을 저장하기 위해 write mode로 열었다.
with open('./restul.txt', 'w', encoding='utf-8')	as f:
	for line in output:
		f.write(line)
		

# 제대로 데이터가 저장되어 있는지, 불러와서 확인한다.
with open('result.txt', 'r') as f:
    output = [line for line in f]


print(output)
Run복사<br><br><br>import pickle   # serialization

output = ["what", "one", "why?!"]

with open("result.pk", 'wb') as f:
    pickle.dump(output, f)

with open("result.pk", 'rb') as f:
    output2 = pickle.load(f)
    
print(output2)
Run복사<br>바이너리로 바꿔서 아주 빠르게 데이터들을 처리 할 수 있는 포멧<br><br><br><br>import file_name

file_name.func1()
file_name.func2()
file_name.func3()

import file_name as f_n
f_n.func1()
f_n.func2()
f_n.func3()

from file_name import func1, func2, func3 # ...
func1()
func2()
func3()

from file_name import func1 as f1, func2 as f2, func3 as f3 # ...
f1()
f2()
f3()
Run복사<br><br><br>def good_print():
	print("this is good! wow!!")

def what():
	print("huh???")
Run복사<br><br><br>import good

good.good_print()
good.what()
Run복사<br><br>import good as huh

huh.good_print()
huh.what()
Run복사<br><br><br>from good import good_print, what

good_print()
what()
Run복사<br><br>from good import good_print as okey, what as the

okey()
the()
Run복사<br><br><br>def good_print():
	print("this is good! wow!!")

def what():
	print("huh???")
Run복사<br><br><br>import module.good

module.good.good_print()
module.good.what()
Run복사<br><br>import module.good as good

good.good_print()
good.what()
Run복사<br><br><br>from module.good import good_print, what

good_print()
what()
Run복사<br><br>from module.good import good_print as okey, what as the

okey()
the()
Run복사<br><br>import sys

def huh():
	print(sys.argv)
	print(" ".join(sys.argv))
	print(sys.argv[1:])
	print(" ".join(sys.argv[1:]))

if __name__ == "__main__":
	huh()
Run복사<br>python what_the.py ok what huh
복사]]></description><link>root\dev\python\python-note.html</link><guid isPermaLink="false">root/dev/python/python note.md</guid><pubDate>Fri, 31 May 2024 02:49:36 GMT</pubDate></item><item><title><![CDATA[이어드림스쿨 실습용 wsl 배포 import]]></title><description><![CDATA[ 
 <br>Note이어드림스쿨 윈도우용 환경가이드 세팅을 참고하여 만든 wsl 통파일 배포


<br>mysql
<br>python conda
<br>python packages
<br>docker
<br>그 외 자잘한 세팅

<br>wsl 최초 로그인시 계정으로 로그인 (root로 로그인 하는 거 수정)
<br>로그인 할 때 비번 표시 (보안상 비밀번호가 너무 어려워서 잊기 싶기 때문에)
<br>conda 기본 가상환명 설정(conda activated yeardream 매번 치기 구찮음)


<br><br><img alt="Pasted image 20240330172323.png" src="lib\media\pasted-image-20240330172323.png"><br>
<a rel="noopener" class="external-link" href="https://drive.google.com/file/d/1uLHl3lNDwtJKfZFpxjDtA7FO27W4ULT3/view?usp=sharing" target="_blank">https://drive.google.com/file/d/1uLHl3lNDwtJKfZFpxjDtA7FO27W4ULT3/view?usp=sharing</a><br>주의다운로드를 "한 번"(매우 중요) 클릭한다.<br><img alt="Pasted image 20240330192430.png" src="lib\media\pasted-image-20240330192430.png"><br>경고무시하고 다운로드<br><br><br>wsl은 아래를 참고해서 설치 해보도록 한다.<br>Info이어드림 스쿨 노션 -&gt; 환경 셋팅 가이드 -&gt; 2.2. Windows OS -&gt; 0. WSL<br>wsl --install
복사<br><br><br><br><img alt="Pasted image 20240330192920.png" src="lib\media\pasted-image-20240330192920.png"><br>Note1번에 위치해 있는 2번 파일을<br>
3번 경로에 4번 위치로 이동<br><br><img alt="Pasted image 20240330193620.png" src="lib\media\pasted-image-20240330193620.png"><br>wsl --import Ubuntu2204Yeardream4 C:wsl\yeardream C:\wsl\Ubuntu2204Yeardream4DockerComplete.tar
복사<br>하면<br><img alt="Pasted image 20240330194601.png" src="lib\media\pasted-image-20240330194601.png"><br>요롷게<br>작업을 잘 완료했다고 나온다.<br>그리고<br><br>wsl -l -v
복사<br>치고 앤터 똭. (새끼 손가락으로 살포시 눌러야 함)<br><img alt="Pasted image 20240330194846.png" src="lib\media\pasted-image-20240330194846.png"><br>보라.<br>우리를 괴롭혔던 별이 Ubuntu에 똭. 밖혀있다.<br>저것은 cmd에서 wsl 커맨드를 쳤을 때 기본으로 들어가겠다는 표시다.<br>
우리는 이미 Ubuntu2204Yeardream4DockerComplet가 있음으로<br>
저 건방진 혐오스런 별이 달린 녀석을 지워버릴 것이다.<br><img alt="Pasted image 20240330195355.png" src="lib\media\pasted-image-20240330195355.png"><br><br>wsl --unregister Ubuntu
복사<br><br>별을 빼앗아 3번 위치에 꾸며줬다.<br><br><img alt="Pasted image 20240330195839.png" src="lib\media\pasted-image-20240330195839.png"><br>
이제 커맨드 창에서 wsl만 입력하고 편해지자.<br>경고여기서 더 편해지면 도둑놈 심보임으로.<br>
그 이상은 안됨.<br>
batch...<br><br><br><br><br><img alt="Pasted image 20240330201351.png" src="lib\media\pasted-image-20240330201351.png"><br>mysql --version
복사<br><br><img alt="Pasted image 20240330201425.png" src="lib\media\pasted-image-20240330201425.png"><br>systemctl status mysql
복사<br>Tipq 키를 눌러서 빠져나온다.<br><br><br><img alt="Pasted image 20240330201557.png" src="lib\media\pasted-image-20240330201557.png"><br>conda --version
복사<br><br><img alt="Pasted image 20240330201629.png" src="lib\media\pasted-image-20240330201629.png"><br>
잘 동작 동작 하고 있다.<br><br><br><img alt="Pasted image 20240330201734.png" src="lib\media\pasted-image-20240330201734.png"><br><br><img alt="Pasted image 20240330201951.png" src="lib\media\pasted-image-20240330201951.png"><br>docker
복사<br>잘 동작 하고 있을지도?<br><br><br>Note음... 해두면 좋다. 안 둬도 상관은 없을까?!?<br>
하지만.. 내 메모린 소중한걸...<br><br><img alt="Pasted image 20240330175413.png" src="lib\media\pasted-image-20240330175413.png"><br>[wsl2]
memory=4GB
processors=4
swap=1GB
localhostForwarding=true
복사<br>
<br>%USERPROFILE% 입력
<br>.wslconfig 파일 생성
<br>번 작성
<br>Note자신의 컴퓨터 사양이 좋지 않다면<br>
memory = 2GB<br>
processors = 2<br>
이렇게 설정해도 됨
사실.. 몇 번 해보고,<br>
이정도면 내 컴퓨터가 죽지 않겠구나 싶을 정도로만 주면 된다.<br><br>wsl --shutdown
복사<br><br><img alt="Pasted image 20240323001212.png" src="lib\media\pasted-image-20240323001212.png"><br>htop 로 확인 결과<br>
<br><a data-tooltip-position="top" aria-label="https://velog.io/@alirz-pixel/wsl2-Vmmem-%EB%A9%94%EB%AA%A8%EB%A6%AC-%EC%A0%90%EC%9C%A0%EC%9C%A8-%ED%95%B4%EA%B2%B0%ED%95%98%EA%B8%B0" rel="noopener" class="external-link" href="https://velog.io/@alirz-pixel/wsl2-Vmmem-%EB%A9%94%EB%AA%A8%EB%A6%AC-%EC%A0%90%EC%9C%A0%EC%9C%A8-%ED%95%B4%EA%B2%B0%ED%95%98%EA%B8%B0" target="_blank">https://velog.io/@alirz-pixel/wsl2-Vmmem-메모리-점유율-해결하기</a>
<br><a rel="noopener" class="external-link" href="https://learn.microsoft.com/ko-kr/windows/wsl/wsl-config" target="_blank">https://learn.microsoft.com/ko-kr/windows/wsl/wsl-config</a>
<br><a data-tooltip-position="top" aria-label="https://velog.io/@devookim/wsl2-%EB%8B%A4%EC%9D%B4%EC%96%B4%ED%8A%B8-%EC%8B%9C%ED%82%A4%EA%B8%B0" rel="noopener" class="external-link" href="https://velog.io/@devookim/wsl2-%EB%8B%A4%EC%9D%B4%EC%96%B4%ED%8A%B8-%EC%8B%9C%ED%82%A4%EA%B8%B0" target="_blank">https://velog.io/@devookim/wsl2-다이어트-시키기</a>
]]></description><link>root\dev\wsl\이어드림스쿨-실습용-wsl-배포-import.html</link><guid isPermaLink="false">root/dev/wsl/이어드림스쿨 실습용 wsl 배포 import.md</guid><pubDate>Mon, 01 Apr 2024 07:59:34 GMT</pubDate><enclosure url="lib\media\pasted-image-20240330172323.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src="lib\media\pasted-image-20240330172323.png"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[wsl 용량 확보하기]]></title><description><![CDATA[ 
 <br>자동화는맨 아래에 있음. 그러니 문제 파악할 때, 혹은 자동화 프로그램이<br>
작동하지 않을 때만 수동으로 처리
가자!<a data-href="#자동화" href="about:blank#자동화" class="internal-link" target="_self" rel="noopener">자동화</a><br><br><img alt="Pasted image 20240809103129.png" src="lib\media\pasted-image-20240809103129.png"><br>용량이 무려173g

<br>wsl은 자동으로 용량을 줄이지 않음
<br>wsl에서 용량 확보를 해도, 그 안에 공기는 그대로
<br>때문에 공기 빼주는 작업을 수동으로 해야함
<br><br><br><br>sudo apt-get install ncdu
복사<br><br>sudo ncdu / --exclude /mnt
복사<br>Info
<br>--exclude: 제외 디렉토리

sudo를 넣지 않으면 권한이 없기 때문에 모든 디렉토리를 순회하지 않는다.<br><img alt="Pasted image 20240809103759.png" src="lib\media\pasted-image-20240809103759.png"><br>94.5 gb원래는 더 많았지만<br>
컨테이너를 지워서 용량이 축소 된 화면<br><br><br><a rel="noopener" class="external-link" href="https://uutopia.tistory.com/70" target="_blank">https://uutopia.tistory.com/70</a><br><br>wsl --shutdown
Run복사<br><br>(Get-ChildItem -Path HKCU:\Software\Microsoft\Windows\CurrentVersion\Lxss | Where-Object {$_.GetValue('DistributionName') -eq 'Ubuntu' }).GetValue('BasePath') + '\ext4.vhdx'
Run복사<br><br>diskpart
Run복사<br>select vdisk file=".vdisk_경로"
attach vdisk readonly
compact vdisk
detach vdisk
복사<br>select vdisk file="S:\wsl\ubuntu\ext4.vhdx"
attach vdisk readonly
compact vdisk
detach vdisk
복사<br><img alt="Pasted image 20240809105041.png" src="lib\media\pasted-image-20240809105041.png"><br><br><br><img alt="Pasted image 20240809105036.png" src="lib\media\pasted-image-20240809105036.png"><br><br><br>더 자세한 메뉴얼은<a data-tooltip-position="top" aria-label="https://github.com/namugach/Compress-VHDX" rel="noopener" class="external-link" href="https://github.com/namugach/Compress-VHDX" target="_blank">여기</a>에서 볼 수 있음<br><img alt="Pasted image 20240811140207.png" src="lib\media\pasted-image-20240811140207.png"><br><br>git clone https://github.com/namugach/Compress-VHDX.git
복사<br><br>
<br>Compress-VHDX.bat 더블 클릭 혹은 우클릭 -&gt; 관리자 모드 실행
]]></description><link>root\dev\wsl\wsl-용량-확보하기.html</link><guid isPermaLink="false">root/dev/wsl/wsl 용량 확보하기.md</guid><pubDate>Sun, 11 Aug 2024 05:36:07 GMT</pubDate><enclosure url="lib\media\pasted-image-20240809103129.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src="lib\media\pasted-image-20240809103129.png"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[wsl note]]></title><description><![CDATA[ 
 <br><br>wsl --install
Run복사<br><br><br><img alt="Pasted image 20240330105616.png" src="lib\media\pasted-image-20240330105616.png"><br>\\wsl$
복사<br><br><br><br>
<br><a data-tooltip-position="top" aria-label="https://kit2013.tistory.com/187" rel="noopener" class="external-link" href="https://kit2013.tistory.com/187" target="_blank">useradd, adduser 차이</a>
<br>sudo usermod username
복사<br><br>[user] default=&lt;username&gt;
복사<br><br><br><br>C:\Users\&lt;유저명&gt;\AppData\Local\Packages\&lt;리눅스이름&gt;\LocalState
복사<br><br>wsl -l -v
복사<br><br>wsl --export Ubuntu F:\0.Users\ubuntu\ubuntu-22-04.tar
복사<br><br>Noteext4.vhdx 파일이 존재하는 디렉토리에는 불러 올 수 없다.<br>wsl --import Ubuntu2204 F:\0.Users\ubuntu\ F:\0.Users\ubuntu\ubuntu-22-04.tar
wsl --import Ubuntu2204Yeardream4 F:\0.Users\ubuntu\Ubuntu2204Yeardream4 F:\0.Users\ubuntu\backup\yeardream4\3.Ubuntu2204Yeardream4DockerComplete.tar
복사<br><br># 모두
wsl --shutdown

# 지정
wsl -t Ubuntu
복사<br><br>wsl -s Ubuntu2204
복사<br><br>wsl --unregister Ubuntu
복사<br>
<br><a rel="noopener" class="external-link" href="https://learn.microsoft.com/ko-kr/windows/wsl/install" target="_blank">https://learn.microsoft.com/ko-kr/windows/wsl/install</a>
<br><a rel="noopener" class="external-link" href="https://lucycle.tistory.com/353" target="_blank">https://lucycle.tistory.com/353</a>
<br><a data-tooltip-position="top" aria-label="https://velog.io/@darktrace1/WSL-%EC%A0%80%EC%9E%A5%EC%86%8C-%EC%9C%84%EC%B9%98-%EC%98%AE%EA%B8%B0%EA%B8%B0" rel="noopener" class="external-link" href="https://velog.io/@darktrace1/WSL-%EC%A0%80%EC%9E%A5%EC%86%8C-%EC%9C%84%EC%B9%98-%EC%98%AE%EA%B8%B0%EA%B8%B0" target="_blank">https://velog.io/@darktrace1/WSL-저장소-위치-옮기기</a>
<br><a rel="noopener" class="external-link" href="https://jooy34.tistory.com/29" target="_blank">https://jooy34.tistory.com/29</a>
<br><br><br><br>[wsl2]
memory=4GB
processors=4
swap=1GB
localhostForwarding=true
복사<br>%USERPROFILE% 에 .wslconfig 파일 생성 및 작성<br>wsl --shutdown
복사<br><br><img alt="Pasted image 20240323001212.png" src="lib\media\pasted-image-20240323001212.png"><br>htop 로 확인 결과<br>
<br><a data-tooltip-position="top" aria-label="https://velog.io/@alirz-pixel/wsl2-Vmmem-%EB%A9%94%EB%AA%A8%EB%A6%AC-%EC%A0%90%EC%9C%A0%EC%9C%A8-%ED%95%B4%EA%B2%B0%ED%95%98%EA%B8%B0" rel="noopener" class="external-link" href="https://velog.io/@alirz-pixel/wsl2-Vmmem-%EB%A9%94%EB%AA%A8%EB%A6%AC-%EC%A0%90%EC%9C%A0%EC%9C%A8-%ED%95%B4%EA%B2%B0%ED%95%98%EA%B8%B0" target="_blank">https://velog.io/@alirz-pixel/wsl2-Vmmem-메모리-점유율-해결하기</a>
<br><a rel="noopener" class="external-link" href="https://learn.microsoft.com/ko-kr/windows/wsl/wsl-config" target="_blank">https://learn.microsoft.com/ko-kr/windows/wsl/wsl-config</a>
<br><a data-tooltip-position="top" aria-label="https://velog.io/@devookim/wsl2-%EB%8B%A4%EC%9D%B4%EC%96%B4%ED%8A%B8-%EC%8B%9C%ED%82%A4%EA%B8%B0" rel="noopener" class="external-link" href="https://velog.io/@devookim/wsl2-%EB%8B%A4%EC%9D%B4%EC%96%B4%ED%8A%B8-%EC%8B%9C%ED%82%A4%EA%B8%B0" target="_blank">https://velog.io/@devookim/wsl2-다이어트-시키기</a>
<br><br><br><a data-href="도커 설치 및 기본 사용법" href="root\dev\docker\도커-설치-및-기본-사용법.html" class="internal-link" target="_self" rel="noopener">도커 설치 및 기본 사용법</a><br>Importantwsl 환경이라 도커 데스크탑 사용하라도 처음에 20초 정도 멈춘다.<br>
무시하자.<br>
<br><a rel="noopener" class="external-link" href="https://netmarble.engineering/docker-on-wsl2-without-docker-desktop/" target="_blank">https://netmarble.engineering/docker-on-wsl2-without-docker-desktop/</a>
<br><br><br><br><br>source ~/anaconda3/etc/profile.d/conda.sh
복사<br>
<br><a rel="noopener" class="external-link" href="https://technical-support.tistory.com/112" target="_blank">https://technical-support.tistory.com/112</a>
]]></description><link>root\dev\wsl\wsl-note.html</link><guid isPermaLink="false">root/dev/wsl/wsl note.md</guid><pubDate>Thu, 18 Apr 2024 15:29:33 GMT</pubDate><enclosure url="lib\media\pasted-image-20240330105616.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src="lib\media\pasted-image-20240330105616.png"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[main]]></title><description><![CDATA[ 
 <br>Note저장 공유용]]></description><link>root\main.html</link><guid isPermaLink="false">root/main.md</guid><pubDate>Thu, 18 Apr 2024 16:46:09 GMT</pubDate></item></channel></rss>