---
tags:
  - kubernetes
  - docker
  - public
create: 2024-06-04 15:56:23
---

```sh
ubuntu@ip-172-31-8-194:~/app$ kubectl get pod
NAME          READY   STATUS      RESTARTS   AGE
hello-world   0/1     Completed   0          21m

ubuntu@ip-172-31-8-194:~/app$ kubectl logs hello-world

Hello from Docker!
This message shows that your installation appears to be working correctly.

To generate this message, Docker took the following steps:
 1. The Docker client contacted the Docker daemon.
 2. The Docker daemon pulled the "hello-world" image from the Docker Hub.
    (amd64)
 3. The Docker daemon created a new container from that image which runs the
    executable that produces the output you are currently reading.
 4. The Docker daemon streamed that output to the Docker client, which sent it
    to your terminal.
```

## 매니페스트

```ymal
apiVersion: v1
kind: Pod
metadata:
  name: nginx01
spec:
  containers:
  - name: nginx-test01
    image: nginx:latest
```


### 적용

- 입력
```sh
kubectl apply -f nginx-test01.yml
```

- 출력
```sh
NAME          READY   STATUS      RESTARTS   AGE
hello-world   0/1     Completed   0          54m
nginx01       1/1     Running     0          9s
```


### 제거

#### 실행
```sh
kubectl delete -f nginx-test01.yml
```

- 출력
```sh
pod "nginx01" delete
```


#### 확인
```sh
kubectl get pod
```

- 출력
```sh
NAME          READY   STATUS      RESTARTS   AGE
hello-world   0/1     Completed   0          58m
```



---

## 디플로이먼트


### 실행
- 입력
```sh
kubectl create deployment deploy-hello --image=hello-world
```

- 출력
```sh
deployment.apps/deploy-hello create
```

### 확인

- 입력
```sh
kubectl get all
# 혹은
kubectl get deployment,replicaset,pod
# 혹은
kubectl get deploy,rs,po
```

- 출력
```sh
NAME                                READY   STATUS             RESTARTS     AGE
pod/deploy-hello-7c478bcd59-279d9   0/1     CrashLoopBackOff   1 (5s ago)   9s
pod/hello-world                     0/1     Completed          0            18h

NAME                 TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE
service/kubernetes   ClusterIP   10.96.0.1    <none>        443/TCP   19h

NAME                           READY   UP-TO-DATE   AVAILABLE   AGE
deployment.apps/deploy-hello   0/1     1            0           9s

NAME                                      DESIRED   CURRENT   READY   AGE
replicaset.apps/deploy-hello-7c478bcd59   1         1         0       9s
```



### 삭제

- 입력
```sh
kubectl delete deployment deploy-hello
```

- 출력

```sh
deployment.apps "deploy-hello" deleted
```


---

## 리플리카셋

### 조정

- 입력
```sh
kubectl create deployment deploy-nginx --image=nginx --replicas=3
```


- 출력
```sh
deployment.apps/deploy-nginx created
```

#### 확인

```sh
ubectl get deploy,rs,po

NAME                           READY   UP-TO-DATE   AVAILABLE   AGE
deployment.apps/deploy-nginx   2/3     3            2           6s

NAME                                      DESIRED   CURRENT   READY   AGE
replicaset.apps/deploy-nginx-7f979874cf   3         3         2       6s

NAME                                READY   STATUS              RESTARTS   AGE
pod/deploy-nginx-7f979874cf-dc94c   0/1     ContainerCreating   0          6s
pod/deploy-nginx-7f979874cf-f9gbh   1/1     Running             0          6s
pod/deploy-nginx-7f979874cf-x6gjl   1/1     Running             0          6s
```

```sh
ubectl get deploy,rs,po -o wide

NAME                           READY   UP-TO-DATE   AVAILABLE   AGE   CONTAINERS   IMAGES   SELECTOR
deployment.apps/deploy-nginx   3/3     3            3           3m    nginx        nginx    app=deploy-nginx

NAME                                      DESIRED   CURRENT   READY   AGE   CONTAINERS   IMAGES   SELECTOR
replicaset.apps/deploy-nginx-7f979874cf   3         3         3       3m    nginx        nginx    app=deploy-nginx,pod-template-hash=7f979874cf

NAME                                READY   STATUS      RESTARTS   AGE   IP               NODE              NOMINATED NODE   READINESS GATES
pod/deploy-nginx-7f979874cf-dc94c   1/1     Running     0          3m    192.168.123.26   ip-172-31-8-194   <none>           <none>
pod/deploy-nginx-7f979874cf-f9gbh   1/1     Running     0          3m    192.168.123.25   ip-172-31-8-194   <none>           <none>
pod/deploy-nginx-7f979874cf-x6gjl   1/1     Running     0          3m    192.168.123.24   ip-172-31-8-194   <none>           <none>
```

### 파드 삭제 후 재생성

- 입력
```sh
kubectl delete pod deploy-nginx-7f979874cf-x6gjl
```

- 출력
```sh
pod "deploy-nginx-7f979874cf-x6gjl" deleted
```

#### 확인
- 입력
```sh
kubectl get deploy,rs,po
```

- 출력
```sh
NAME                           READY   UP-TO-DATE   AVAILABLE   AGE
deployment.apps/deploy-nginx   3/3     3            3           9m9s

NAME                                      DESIRED   CURRENT   READY   AGE
replicaset.apps/deploy-nginx-7f979874cf   3         3         3       9m9s

NAME                                READY   STATUS      RESTARTS   AGE
pod/deploy-nginx-7f979874cf-7fwlg   1/1     Running     0          17s
pod/deploy-nginx-7f979874cf-dc94c   1/1     Running     0          9m9s
pod/deploy-nginx-7f979874cf-f9gbh   1/1     Running     0          9m9s
```

`````ad-note
```sh
NAME                                READY   STATUS      RESTARTS   AGE
pod/deploy-nginx-7f979874cf-7fwlg   1/1     Running     0          17s
```

이 부분 보면 방금 생성 된 것을 알 수 있다.
`````

---
## 매니페스트

### 작성

#### 디렉토리 정리 및 이동
```sh
cd ~/k8s/basic
mkdir manifest
cd manifest
```

#### 열기
```sh
vi deploy-test01.yml
```

#### deploy-test01.yml
```ymal title:deploy-test01.yml
apiVersion: apps/v1
kind: Deployment

metadata:
  name: deploy-test01

spec:
  replicas: 3
  selector:
    matchLabels:
      app: web-deploy
  template:
    metadata:
      labels:
        app: web-deploy
    spec:
      containers:
      - name: nginx
        image: nginx:latest
```


### 실행
- 입력
```sh
kubectl apply -f deploy-test01.yml
```

- 출력
```sh
deployment.apps/deploy-test01 created
```

#### 확인
- 입력
```sh
kubectl get deploy,rs,po
```

- 출력
```sh
NAME                            READY   UP-TO-DATE   AVAILABLE   AGE
deployment.apps/deploy-test01   3/3     3            3           6s

NAME                                       DESIRED   CURRENT   READY   AGE
replicaset.apps/deploy-test01-64b75859c6   3         3         3       6s

NAME                                 READY   STATUS    RESTARTS   AGE
pod/deploy-test01-64b75859c6-68stg   1/1     Running   0          6s
pod/deploy-test01-64b75859c6-8szmz   1/1     Running   0          6s
pod/deploy-test01-64b75859c6-crffs   1/1     Running   0          6s
```


### 추가
#### 파일 복사
```sh
cp deploy-test01.yml deploy-test02.yml
```

#### 수정
```yaml
apiVersion: apps/v1
kind: Deployment

metadata:
  name: deploy-test01

spec:
  replicas: 5
  selector:
    matchLabels:
      app: web-deploy
  template:
    metadata:
      labels:
        app: web-deploy
    spec:
      containers:
      - name: nginx
        image: nginx:latest
```

```ad-note
`replicas: 5` 이 부분 바꾸기
```


#### 적용
- 입력
```sh
kubectl apply -f deploy-test02.yml
```

- 출력
```sh
deployment.apps/deploy-test01 configured
```


#### 확인
- 입력
```sh
kubectl get pod
```

- 출력
```sh
NAME                             READY   STATUS    RESTARTS   AGE
deploy-test01-64b75859c6-68stg   1/1     Running   0          19m
deploy-test01-64b75859c6-8szmz   1/1     Running   0          19m
deploy-test01-64b75859c6-crffs   1/1     Running   0          19m
deploy-test01-64b75859c6-sgkbp   1/1     Running   0          5s
deploy-test01-64b75859c6-vzs4v   1/1     Running   0          5s
```


#### 제거
- 입력
```sh
kubectl delete -f deploy-test02.yml
```


- 출력
```sh
deployment.apps "deploy-test01" deleted
```


---

## 이부분 다시 제목 변경


### 파일 복사
```sh
cp deploy-test01.yml deploy-test03.yml
```


### 수정
```ymal
apiVersion: apps/v1
kind: Deployment

metadata:
  name: deploy-test01

spec:
  replicas: 3
  selector:
    matchLabels:
      app: web-deploy
  template:
    metadata:
      labels:
        app: web-deploy
    spec:
      containers:
      - name: nginx
        image: nginx:1.24
```

```ad-note
`image: nginx:1.24` 수정
```


### 적용
```sh
kubectl apply -f deploy-test03.yml
```

### 확인
- 입력
```sh
kubectl get deploy,rs,pod
```

- 출력
```sh
NAME                            READY   UP-TO-DATE   AVAILABLE   AGE
deployment.apps/deploy-test01   3/3     3            3           36s

NAME                                       DESIRED   CURRENT   READY   AGE
replicaset.apps/deploy-test01-5d4f6f8bfb   3         3         3       36s

NAME                                 READY   STATUS    RESTARTS   AGE
pod/deploy-test01-5d4f6f8bfb-9dk7t   1/1     Running   0          36s
pod/deploy-test01-5d4f6f8bfb-cxw55   1/1     Running   0          36s
pod/deploy-test01-5d4f6f8bfb-mdt48   1/1     Running   0          36s
```


### deployment

```ad-info
문제 생겼을 때 사용
```
#### 확인
- 입력
```sh
 kubectl describe deployment deploy-test01
```

- 출력
```sh
Name:                   deploy-test01
Namespace:              default
CreationTimestamp:      Wed, 05 Jun 2024 02:17:38 +0000
Labels:                 <none>
Annotations:            deployment.kubernetes.io/revision: 1
Selector:               app=web-deploy
Replicas:               3 desired | 3 updated | 3 total | 3 available | 0 unavailable
StrategyType:           RollingUpdate
MinReadySeconds:        0
RollingUpdateStrategy:  25% max unavailable, 25% max surge
Pod Template:
  Labels:  app=web-deploy
  Containers:
   nginx:
    Image:        nginx:1.24
    Port:         <none>
    Host Port:    <none>
    Environment:  <none>
    Mounts:       <none>
  Volumes:        <none>
Conditions:
  Type           Status  Reason
  ----           ------  ------
  Available      True    MinimumReplicasAvailable
  Progressing    True    NewReplicaSetAvailable
OldReplicaSets:  <none>
NewReplicaSet:   deploy-test01-5d4f6f8bfb (3/3 replicas created)
Events:
  Type    Reason             Age   From                   Message
  ----    ------             ----  ----                   -------
  Normal  ScalingReplicaSet  2m2s  deployment-controller  Scaled up replica set deploy-test01-5d4f6f8bfb to 3
```

```ad-note
`Image:        nginx:1.24` 요 부분
```



---

## 롤아웃

```tip
iff deploy-test03.yml deploy-test04.yml 
19c19
<         image: nginx:1.24
\ No newline at end of file
---
>         image: nginx:1.25
\ No newline at end of file
```

```
kubectl apply -f deploy-test04.yml 
deployment.apps/deploy-test01 configured
```

```
kubectl get pod
NAME                             READY   STATUS    RESTARTS   AGE
deploy-test01-689458c8c7-btbf9   1/1     Running   0          78s
deploy-test01-689458c8c7-crkds   1/1     Running   0          69s
deploy-test01-689458c8c7-hvmcw   1/1     Running   0          71s
```


```
kubectl describe deployment deploy-test01
Name:                   deploy-test01
Namespace:              default
CreationTimestamp:      Wed, 05 Jun 2024 02:17:38 +0000
Labels:                 <none>
Annotations:            deployment.kubernetes.io/revision: 2
Selector:               app=web-deploy
Replicas:               3 desired | 3 updated | 3 total | 3 available | 0 unavailable
StrategyType:           RollingUpdate
MinReadySeconds:        0
RollingUpdateStrategy:  25% max unavailable, 25% max surge
Pod Template:
  Labels:  app=web-deploy
  Containers:
   nginx:
    Image:        nginx:1.25
    Port:         <none>
    Host Port:    <none>
    Environment:  <none>
    Mounts:       <none>
  Volumes:        <none>
Conditions:
  Type           Status  Reason
  ----           ------  ------
  Available      True    MinimumReplicasAvailable
  Progressing    True    NewReplicaSetAvailable
OldReplicaSets:  deploy-test01-5d4f6f8bfb (0/0 replicas created)
NewReplicaSet:   deploy-test01-689458c8c7 (3/3 replicas created)
Events:
  Type    Reason             Age   From                   Message
  ----    ------             ----  ----                   -------
  Normal  ScalingReplicaSet  12m   deployment-controller  Scaled up replica set deploy-test01-5d4f6f8bfb to 3
  Normal  ScalingReplicaSet  94s   deployment-controller  Scaled up replica set deploy-test01-689458c8c7 to 1
  Normal  ScalingReplicaSet  87s   deployment-controller  Scaled down replica set deploy-test01-5d4f6f8bfb to 2 from 3
  Normal  ScalingReplicaSet  87s   deployment-controller  Scaled up replica set deploy-test01-689458c8c7 to 2 from 1
  Normal  ScalingReplicaSet  85s   deployment-controller  Scaled down replica set deploy-test01-5d4f6f8bfb to 1 from 2
  Normal  ScalingReplicaSet  85s   deployment-controller  Scaled up replica set deploy-test01-689458c8c7 to 3 from 2
  Normal  ScalingReplicaSet  84s   deployment-controller  Scaled down replica set deploy-test01-5d4f6f8bfb to 0 from 1
```

```ad-note
이름과 AGE가 다르다.
즉, 내렸다가 다시 올린 것.
```


---

## 롤백

```
kubectl rollout undo deployment deploy-test01
deployment.apps/deploy-test01 rolled back
```

```
kubectl get pod
NAME                             READY   STATUS    RESTARTS   AGE
deploy-test01-5d4f6f8bfb-98kb9   1/1     Running   0          6s
deploy-test01-5d4f6f8bfb-fdhjl   1/1     Running   0          8s
deploy-test01-5d4f6f8bfb-wk9qc   1/1     Running   0          7s
```


```
kubectl describe deployment deploy-test01
Name:                   deploy-test01
Namespace:              default
CreationTimestamp:      Wed, 05 Jun 2024 02:17:38 +0000
Labels:                 <none>
Annotations:            deployment.kubernetes.io/revision: 3
Selector:               app=web-deploy
Replicas:               3 desired | 3 updated | 3 total | 3 available | 0 unavailable
StrategyType:           RollingUpdate
MinReadySeconds:        0
RollingUpdateStrategy:  25% max unavailable, 25% max surge
Pod Template:
  Labels:  app=web-deploy
  Containers:
   nginx:
    Image:        nginx:1.24
    Port:         <none>
    Host Port:    <none>
    Environment:  <none>
    Mounts:       <none>
  Volumes:        <none>
Conditions:
  Type           Status  Reason
  ----           ------  ------
  Available      True    MinimumReplicasAvailable
  Progressing    True    NewReplicaSetAvailable
OldReplicaSets:  deploy-test01-689458c8c7 (0/0 replicas created)
NewReplicaSet:   deploy-test01-5d4f6f8bfb (3/3 replicas created)
Events:
  Type    Reason             Age                From                   Message
  ----    ------             ----               ----                   -------
  Normal  ScalingReplicaSet  17m                deployment-controller  Scaled up replica set deploy-test01-5d4f6f8bfb to 3
  Normal  ScalingReplicaSet  7m7s               deployment-controller  Scaled up replica set deploy-test01-689458c8c7 to 1
  Normal  ScalingReplicaSet  7m                 deployment-controller  Scaled down replica set deploy-test01-5d4f6f8bfb to 2 from 3
  Normal  ScalingReplicaSet  7m                 deployment-controller  Scaled up replica set deploy-test01-689458c8c7 to 2 from 1
  Normal  ScalingReplicaSet  6m58s              deployment-controller  Scaled down replica set deploy-test01-5d4f6f8bfb to 1 from 2
  Normal  ScalingReplicaSet  6m58s              deployment-controller  Scaled up replica set deploy-test01-689458c8c7 to 3 from 2
  Normal  ScalingReplicaSet  6m57s              deployment-controller  Scaled down replica set deploy-test01-5d4f6f8bfb to 0 from 1
  Normal  ScalingReplicaSet  18s                deployment-controller  Scaled up replica set deploy-test01-5d4f6f8bfb to 1 from 0
  Normal  ScalingReplicaSet  17s                deployment-controller  Scaled down replica set deploy-test01-689458c8c7 to 2 from 3
  Normal  ScalingReplicaSet  17s                deployment-controller  Scaled up replica set deploy-test01-5d4f6f8bfb to 2 from 1
  Normal  ScalingReplicaSet  15s (x3 over 16s)  deployment-controller  (combined from similar events): Scaled down replica set deploy-test01-689458c8c7 to 0 from 1
```

```
kubectl delete -f deploy-test04.yml
deployment.apps "deploy-test01" deleted
```

```
kubectl get deploy,rs,po
No resources found in default namespace.
```


---

## 서비스

### 작성
```yaml
apiVersion: v1
kind: Service
metadata:
  name: web-serivce
spec:
  selector:
    app: web-deploy
  type: ClusterIP
  ports:
  - protocol: TCP
    port: 80
```

### deploy  적용
```sh
kubectl apply -f deploy-test01.yml 
deployment.apps/deploy-test01 created
```


### service 적용
```
kubectl apply -f service-test01.yml
service/web-serivce created
```

```
kubectl get all
NAME                                 READY   STATUS    RESTARTS   AGE
pod/deploy-test01-64b75859c6-44qr7   1/1     Running   0          25s
pod/deploy-test01-64b75859c6-bt4nh   1/1     Running   0          25s
pod/deploy-test01-64b75859c6-g8cws   1/1     Running   0          25s

NAME                  TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)   AGE
service/kubernetes    ClusterIP   10.96.0.1        <none>        443/TCP   22h
service/web-serivce   ClusterIP   10.101.102.172   <none>        80/TCP    10s

NAME                            READY   UP-TO-DATE   AVAILABLE   AGE
deployment.apps/deploy-test01   3/3     3            3           25s

NAME                                       DESIRED   CURRENT   READY   AGE
replicaset.apps/deploy-test01-64b75859c6   3         3         3       25s
```

```sh
kubectl describe service web-serivce
Name:              web-serivce
Namespace:         default
Labels:            <none>
Annotations:       <none>
Selector:          app=web-deploy
Type:              ClusterIP
IP Family Policy:  SingleStack
IP Families:       IPv4
IP:                10.101.102.172
IPs:               10.101.102.172
Port:              <unset>  80/TCP
TargetPort:        80/TCP
Endpoints:         192.168.123.42:80,192.168.123.43:80,192.168.123.44:80
Session Affinity:  None
Events:            <none>
```

```ad-note
Selector:          app=web-deploy
Type:              ClusterIP
Endpoints:         192.168.123.42:80,192.168.123.43:80,192.168.123.44:80
```

```ad-info
title: Endpoints
pod 아이피

kubectl get pod -o wide
NAME                             READY   STATUS    RESTARTS   AGE     IP               NODE              NOMINATED NODE   READINESS GATES
deploy-test01-64b75859c6-44qr7   1/1     Running   0          5m43s   192.168.123.43   ip-172-31-8-194   <none>           <none>
deploy-test01-64b75859c6-bt4nh   1/1     Running   0          5m43s   192.168.123.42   ip-172-31-8-194   <none>           <none>
deploy-test01-64b75859c6-g8cws   1/1     Running   0          5m43s   192.168.123.44   ip-172-31-8-194   <none>           <none>
```


```sh
kubectl get all

NAME                                 READY   STATUS    RESTARTS   AGE
pod/deploy-test01-64b75859c6-44qr7   1/1     Running   0          6m57s
pod/deploy-test01-64b75859c6-bt4nh   1/1     Running   0          6m57s
pod/deploy-test01-64b75859c6-g8cws   1/1     Running   0          6m57s
pod/nginx01                          1/1     Running   0          8s

NAME                  TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)   AGE
service/kubernetes    ClusterIP   10.96.0.1        <none>        443/TCP   22h
service/web-serivce   ClusterIP   10.101.102.172   <none>        80/TCP    6m42s

NAME                            READY   UP-TO-DATE   AVAILABLE   AGE
deployment.apps/deploy-test01   3/3     3            3           6m57s
```

### 접속
```
kubectl exec -it nginx01 -- /bin/bash
root@nginx01:/# 
root@nginx01:/# curl "10.101.102.172:80"
```

- 출력
```html
<!DOCTYPE html>
<html>
<head>
<title>Welcome to nginx!</title>
<style>
html { color-scheme: light dark; }
body { width: 35em; margin: 0 auto;
font-family: Tahoma, Verdana, Arial, sans-serif; }
</style>
</head>
<body>
<h1>Welcome to nginx!</h1>
<p>If you see this page, the nginx web server is successfully installed and
working. Further configuration is required.</p>

<p>For online documentation and support please refer to
<a href="http://nginx.org/">nginx.org</a>.<br/>
Commercial support is available at
<a href="http://nginx.com/">nginx.com</a>.</p>

<p><em>Thank you for using nginx.</em></p>
</body>
</html>
```

### 종료

```
kubectl delete -f service-test01.yml
service "web-service" deleted

kubectl delete -f nginx-test01.yml
pod "nginx01" deleted

kubectl delete -f deploy-test01.yml
deployment.apps "deploy-test01" deleted

kubectl get pod
No resources found in default namespace.

```


---
## NodePort

### ec2 인바운드
- 포트: 31001
- 소스: 내 아이피


### service-test02.yml  작성
```yaml
apiVersion: v1
kind: Service
metadata:
  name: web-service-nodeport
spec:
  selector:
    app: web-deploy
  type: NodePort
  ports:
  - protocol: TCP
    nodePort: 31001
    port: 80
    targetPort: 80
```

### 실행
```sh
kubectl apply -f deploy-test01.yml
deployment.apps/deploy-test01 created
```

```sh
kubectl apply -f service-test02.yml 
service/web-service-nodeport created
```

```sh
kubectl get all
NAME          READY   STATUS    RESTARTS   AGE
pod/nginx01   1/1     Running   0          19m

NAME                           TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)        AGE
service/kubernetes             ClusterIP   10.96.0.1      <none>        443/TCP        22h
service/web-service-nodeport   NodePort    10.103.10.28   <none>        80:31001/TCP   8s
```
```ad-check
`NodePort`
80:31001/TCP
```


### 확인

```ad-note
브라우저에서
`http://43.203.77.126:31001/`
접근하면 쿠버의 80번 포트를 통해 nginx로 진입함

`최종 출력`
# Welcome to nginx!

If you see this page, the nginx web server is successfully installed and working. Further configuration is required.

For online documentation and support please refer to [nginx.org](http://nginx.org/).  
Commercial support is available at [nginx.com](http://nginx.com/).

_Thank you for using nginx._
```



### 종료
```
kubectl delete -f deploy-test01.yml 
deployment.apps "deploy-test01" deleted
```

```
kubectl delete -f service-test02.yml 
service "web-service-nodeport" deleted
```

```
kubectl get all
NAME                 TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE
service/kubernetes   ClusterIP   10.96.0.1    <none>        443/TCP   23h
```

---
## LoadBalncer

```ad-note
이건 개념만
```


---

## 스토리지 볼륨

### volume-test01.yml  작성
```yaml
apiVersion: v1
kind: Pod
metadata:
  name: nginx-volume-01
spec:
  containers:
  - name: nginx-test01
    image: nginx:latest
    volumeMounts:
    - name: empty-test01
      mountPath: /mount01
  volumes:
  - name: empty-test01
    emptyDir: {}

```

```
kubectl apply -f volume-test01.yml 
pod/nginx-volume-01 created
```

```
kubectl get pod
NAME              READY   STATUS    RESTARTS   AGE
nginx-volume-01   1/1     Running   0          44s
```


```sh
kubectl exec -it nginx-volume-01 -- /bin/bash

ls

bin   docker-entrypoint.d   home   media    opt   run   sys  var
boot  docker-entrypoint.sh  lib    mnt      proc  sbin  tmp
dev   etc                   lib64  mount01  root  srv   usr
```


```sh
cd mount01/
echo "hello yeardream!" > ./test.txt
cat test.txt 
hello yeardream!
exit
```


```ad-note
pod가 없어지면 volum의 데이터도 없어진다.
```
```sh
ls
deploy-test01.yml  deploy-test04.yml  service-test01.yml  vim
deploy-test02.yml  manifest           service-test02.yml  volume-test01.yml
deploy-test03.yml  nginx-test01.yml   ubuntu-test01.yml

kubectl get pod
NAME              READY   STATUS    RESTARTS   AGE
nginx-volume-01   1/1     Running   0          8m58s

kubectl delete -f volume-test01.yml
pod "nginx-volume-01" deleted

kubectl get pod
No resources found in default namespace.

kubectl apply -f volume-test01.yml
pod/nginx-volume-01 created

kubectl get pod
NAME              READY   STATUS    RESTARTS   AGE
nginx-volume-01   1/1     Running   0          6s

kubectl exec -it nginx-volume-01 -- /bin/bash
cd mount01/
ls
exit
```

### 종료
```sh
kubectl delete -f volume-test01.yml
pod "nginx-volume-01" deleted
kubectl get pod
No resources found in default namespace.
```

---
## hostPath

```ad-fail
이 부분 잘 안됐음
```

### 확인

```sh
kubectl get nodes --show-labels

NAME              STATUS   ROLES           AGE   VERSION   LABELS
ip-172-31-8-194   Ready    control-plane   23h   v1.29.5   beta.kubernetes.io/arch=amd64,beta.kubernetes.io/os=linux,kubernetes.io/arch=amd64,kubernetes.io/hostname=ip-172-31-8-194,kubernetes.io/os=linux,node-role.kubernetes.io/control-plane=,node.kubernetes.io/exclude-from-external-load-balancers=
```

```ad-note
`hostname=ip-172-31-8-194`
자신의 private ip와 같은지 확인
```

### 디렉토리

```sh
mkdir volhost01
cd volhost01/
pwd
/home/ubuntu/work/k8s/basic/volhost01
cd ..
```

```ad-note
title: 유념
`ip-172-31-8-194`
`/home/ubuntu/work/k8s/basic/volhost01`
```


### 작성

```sh
 vi volume-test02.yml
```

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: nginx-volume-02
spec:
  nodeSelector:
    kubernetes.io/hostname: ip-172-31-8-194
  containers:
  - name: nginx-test01
    image: nginx:latest
    volumeMounts:
    - name: hostpath-test01
      mountPath: /mount01
  volumes:
  - name: hostpath-test01
    hostPath:
      path: /home/ubuntu/work/k8s/basic/volhost01
      type: DirectoryOrCreate
```

### 실행

```sh
kubectl get pod
NAME              READY   STATUS    RESTARTS   AGE
nginx-volume-02   1/1     Running   0          7s
```

```sh
kubectl exec -it nginx-volume-02 -- /bin/bash
ls
bin   docker-entrypoint.d   home   media    opt   run   sys  var
boot  docker-entrypoint.sh  lib    mnt      proc  sbin  tmp
dev   etc                   lib64  mount01  root  srv   usr
cd mount01/
```


```sh
echo "hello yeardream" >./test01.txt

ls
test01.txt

cat test01.txt 
hello yeardream

exit
```


### 종료
```sh
ubuntu@ip-172-31-8-194:~/work/k8s/basic$ kubectl delete -f volume-test02.yml
pod "nginx-volume-02" deleted
ubuntu@ip-172-31-8-194:~/work/k8s/basic$ kubectl get pod
No resources found in default namespace.
ubuntu@ip-172-31-8-194:~/work/k8s/basic$ kubectl get all
NAME                 TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE
service/kubernetes   ClusterIP   10.96.0.1    <none>        443/TCP   24h
```

---

## PersistentVolume

### 디렉토리 생성

```
ubuntu@ip-172-31-8-194:~$ sudo -i
root@ip-172-31-8-194:~# cd /tmp/
root@ip-172-31-8-194:/tmp# ls
code-1c77821e-c114-45ac-80da-acf86198216a
snap-private-tmp
systemd-private-0169308c496c46a59c932439e54822cb-ModemManager.service-OKICBG
systemd-private-0169308c496c46a59c932439e54822cb-chrony.service-FtI0Pb
systemd-private-0169308c496c46a59c932439e54822cb-polkit.service-zn0PYQ
systemd-private-0169308c496c46a59c932439e54822cb-systemd-logind.service-l2pOPZ
systemd-private-0169308c496c46a59c932439e54822cb-systemd-resolved.service-6Ru3eP
root@ip-172-31-8-194:/tmp# mkdir k8spv
root@ip-172-31-8-194:/tmp# ls
code-1c77821e-c114-45ac-80da-acf86198216a
k8spv
snap-private-tmp
systemd-private-0169308c496c46a59c932439e54822cb-ModemManager.service-OKICBG
systemd-private-0169308c496c46a59c932439e54822cb-chrony.service-FtI0Pb
systemd-private-0169308c496c46a59c932439e54822cb-polkit.service-zn0PYQ
systemd-private-0169308c496c46a59c932439e54822cb-systemd-logind.service-l2pOPZ
systemd-private-0169308c496c46a59c932439e54822cb-systemd-resolved.service-6Ru3eP
root@ip-172-31-8-194:/tmp# exit
logout
```

### 설치

```sh
 sudo apt install nfs-common
 sudo apt install nfs-kernel-server
```


### 확인

```sh
sudo apt install nfs-kernel-server

---
Reading package lists... Done
Building dependency tree... Done
Reading state information... Done
The following NEW packages will be installed:
  nfs-kernel-server
0 upgraded, 1 newly installed, 0 to remove and 17 not upgraded.
Need to get 169 kB of archives.
After this operation, 606 kB of additional disk space will be used.
Get:1 http://ap-northeast-2.ec2.archive.ubuntu.com/ubuntu noble/main amd64 nfs-kernel-server amd64 1:2.6.4-3ubuntu5 [169 kB]
Fetched 169 kB in 0s (7007 kB/s)          
Selecting previously unselected package nfs-kernel-server.
(Reading database ... 82822 files and directories currently installed.)
Preparing to unpack .../nfs-kernel-server_1%3a2.6.4-3ubuntu5_amd64.deb ...
Unpacking nfs-kernel-server (1:2.6.4-3ubuntu5) ...
Setting up nfs-kernel-server (1:2.6.4-3ubuntu5) ...
Created symlink /etc/systemd/system/nfs-mountd.service.requires/fsidd.service → /usr/lib/systemd/system/fsidd.service.
Created symlink /etc/systemd/system/nfs-server.service.requires/fsidd.service → /usr/lib/systemd/system/fsidd.service.
Created symlink /etc/systemd/system/nfs-client.target.wants/nfs-blkmap.service → /usr/lib/systemd/system/nfs-blkmap.service.
Created symlink /etc/systemd/system/multi-user.target.wants/nfs-server.service → /usr/lib/systemd/system/nfs-server.service.
nfs-mountd.service is a disabled or a static unit, not starting it.
nfsdcld.service is a disabled or a static unit, not starting it.

Creating config file /etc/exports with new version

Creating config file /etc/default/nfs-kernel-server with new version
Processing triggers for man-db (2.12.0-4build2) ...
Scanning processes...                                                                           
Scanning linux images...                                                                        

Running kernel seems to be up-to-date.

No services need to be restarted.

No containers need to be restarted.

No user sessions are running outdated binaries.

No VM guests are running outdated hypervisor (qemu) binaries on this host.
ubuntu@ip-172-31-8-194:~$ systemctl status nfs-server.service
● nfs-server.service - NFS server and services
     Loaded: loaded (/usr/lib/systemd/system/nfs-server.service; enabled; preset: enabled)
     Active: active (exited) since Wed 2024-06-05 06:15:46 UTC; 1min 27s ago
   Main PID: 98259 (code=exited, status=0/SUCCESS)
        CPU: 16ms
```


### 권한 설정

#### exports

##### 만들고 열기
```sh
sudo vim /etc/exports
```

##### 작성
```vi
/tmp/k8spv 172.31.8.194(rw,no_root_squash)
```

##### 적용
```sh
sudo systemctl restart nfs-server
systemctl status nfs-server.service
```



#### pv) volume-test04-1-pv.yml 작성

```yaml
apiVersion: v1
kind: PersistentVolume
metadata:
  name: pv-01
spec:
  accessModes:
  - ReadWriteOnce
  capacity:
    storage: 100Mi
  persistentVolumeReclaimPolicy: Retain
  storageClassName: pv-test-01
  nfs:
    server: 172.31.8.19
    path: /tmp/k8spv
```

#### pvc (요청서) volume-test04-2-pvc.yml 작성

```yaml
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: pvc-01
spec:
  accessModes:
  - ReadWriteOnce
  resources:
    requests:
      storage: 30Mi
  storageClassName: pv-test-01

```


#### pod) volume-test04-3-pod.yml 작성

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: nginx-volume-04
spec:
  containers:
  - name: nginx-test01
    image: nginx:latest
    volumeMounts:
    - name: nfs-pv-01
      mountPath: /mount01
  volumes:
  - name: nfs-pv-01
    persistentVolumeClaim:
      claimName: pvc-01
```

#### pv 실행
```
ubectl apply -f volume-test04-1-pv.yml

persistentvolume/pv-01 created

ubuntu@ip-172-31-8-194:~/work/k8s/basic$ kubectl get pv

NAME    CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS      CLAIM   STORAGECLASS   VOLUMEATTRIBUTESCLASS   REASON   AGE
pv-01   100Mi      RWO            Retain           Available           pv-test-01     <unset>                          18s
```


#### pvc 실행
```
kubectl apply -f volume-test04-2-pvc.yml

kubectl get pvc

NAME     STATUS   VOLUME   CAPACITY   ACCESS MODES   STORAGECLASS   VOLUMEATTRIBUTESCLASS   AGE
pvc-01   Bound    pv-01    100Mi      RWO            pv-test-01     <unset>                 9s
```

- page 113
```ad-fail
pod 부분에서 안됨
```


### 제거
```sh
ubuntu@ip-172-31-2-228:~/work/k8s/basic$ kubectl delete -f volume-test04-3-pod.yml
pod "nginx-volume-04" deleted
ubuntu@ip-172-31-2-228:~/work/k8s/basic$ kubectl delete -f volume-test04-2-pvc.yml
persistentvolumeclaim "pvc-01" deleted
ubuntu@ip-172-31-2-228:~/work/k8s/basic$ kubectl delete -f volume-test04-1-pv.yml
persistentvolume "pv-01" deleted

No resources found
```



---

## 스테이트풀셋

```ad-note
pass
```


---

## 인그래스 (ingress)


### helm
#### 디렉토리 이동

```sh
cd ~/app
```
#### 다운
```sh
curl -fsSL -o get_helm.sh https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3

ls
get_helm.sh
```

#### 권한
```sh
chmod 700 get_helm.sh

-rwx------  1 ubuntu ubuntu 11694 Jun  5 07:18 get_helm.sh
```


#### 설치

```sh
./get_helm.sh 

Downloading https://get.helm.sh/helm-v3.15.1-linux-amd64.tar.gz
Verifying checksum... Done.
Preparing to install helm into /usr/local/bin
helm installed into /usr/local/bin/helm
```

#### 확인

```sh
helm version

version.BuildInfo{Version:"v3.15.1", GitCommit:"e211f2aa62992bd72586b395de50979e31231829", GitTreeState:"clean", GoVersion:"go1.22.3"}
```

#### 레포지토리
##### 추가
```sh
helm repo add bitnami https://charts.bitnami.com/bitnami
"bitnami" has been added to your repositories
```

##### 확인
```sh
helm repo update

Hang tight while we grab the latest from your chart repositories...
...Successfully got an update from the "bitnami" chart repository
Update Complete. ⎈Happy Helming!⎈
```


### nginx-controller-ingress
#### 찾기
```
helm search repo nginx

NAME                                    CHART VERSION   APP VERSION     DESCRIPTION                                       
bitnami/nginx                           17.3.2          1.26.1          NGINX Open Source is a web server that can be a...
bitnami/nginx-ingress-controller        11.3.2          1.10.1          NGINX Ingress Controller is an Ingress controll...
bitnami/nginx-intel                     2.1.15          0.4.9           DEPRECATED NGINX Open Source for Intel is a lig...
```


#### 받기
```sh
helm pull bitnami/nginx-ingress-controller
```

#### 확인
```sh
ls

get_helm.sh  nginx-ingress-controller-11.3.2.tgz
```


#### 압축 풀기
```sh
tar xvfz nginx-ingress-controller-11.3.2.tgz
```

#### 이름 변경
```
mv nginx-ingress-controller nginx-ingress-controller-11.3.2
```


#### values.yaml 복사

```sh
cd nginx-ingress-controller-11.3.2/
ls
Chart.lock  Chart.yaml  README.md  charts  templates  values.yaml
cp values.yaml my-values.yaml
```

```ad-attention
항상 values.yaml를 복사해서 원복을 훼손하지 말 것.
```


### namespace

#### 확인

```sh
kubectl get namespace

NAME               STATUS   AGE
calico-apiserver   Active   25h
calico-system      Active   25h
default            Active   25h
kube-node-lease    Active   25h
kube-public        Active   25h
kube-system        Active   25h
tigera-operator    Active   25h
```

#### 생성
- 입력
```sh
kubectl create namespace mynginx

namespace/mynginx created
```

- 확인
```sh
kubectl get namespace
NAME               STATUS   AGE
calico-apiserver   Active   25h
calico-system      Active   25h
default            Active   25h
kube-node-lease    Active   25h
kube-public        Active   25h
kube-system        Active   25h
mynginx            Active   14s # 여기 생성
tigera-operator    Active   25h
```


### namesapce에 설치
- p: 149


- 입력
```sh
helm install --namespace mynginx --generate-name bitnami/nginx-ingress-controller -f my-values.yaml
```

- 출력
```sh
 --generate-name bitnami/nginx-ingress-controller -f my-values.yaml
NAME: nginx-ingress-controller-1717573067
LAST DEPLOYED: Wed Jun  5 07:37:50 2024
NAMESPACE: mynginx
STATUS: deployed
REVISION: 1
TEST SUITE: None
NOTES:
CHART NAME: nginx-ingress-controller
CHART VERSION: 11.3.2
APP VERSION: 1.10.1

** Please be patient while the chart is being deployed **

The nginx-ingress controller has been installed.

Get the application URL by running these commands:

 NOTE: It may take a few minutes for the LoadBalancer IP to be available.
        You can watch its status by running 'kubectl get --namespace mynginx svc -w nginx-ingress-controller-1717573067'

    export SERVICE_IP=$(kubectl get svc --namespace mynginx nginx-ingress-controller-1717573067 -o jsonpath='{.status.loadBalancer.ingress[0].ip}')
    echo "Visit http://${SERVICE_IP} to access your application via HTTP."
    echo "Visit https://${SERVICE_IP} to access your application via HTTPS."

An example Ingress that makes use of the controller:

  apiVersion: networking.k8s.io/v1
  kind: Ingress
  metadata:
    name: example
    namespace: mynginx
  spec:
    ingressClassName: nginx
    rules:
      - host: www.example.com
        http:
          paths:
            - backend:
                service:
                  name: example-service
                  port:
                    number: 80
              path: /
              pathType: Prefix
    # This section is only required if TLS is to be enabled for the Ingress
    tls:
        - hosts:
            - www.example.com
          secretName: example-tls

If TLS is enabled for the Ingress, a Secret containing the certificate and key must also be provided:

  apiVersion: v1
  kind: Secret
  metadata:
    name: example-tls
    namespace: mynginx
  data:
    tls.crt: <base64 encoded cert>
    tls.key: <base64 encoded key>
  type: kubernetes.io/tls

WARNING: There are "resources" sections in the chart not set. Using "resourcesPreset" is not recommended for production. For production installations, please set the following values according to your workload needs:
  - defaultBackend.resources
  - resources
+info https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/
```


#### 확인
```sh
helm ls --namespace mynginx

NAME                                    NAMESPACE       REVISION        UPDATED                                       STATUS          CHART                           APP VERSION
nginx-ingress-controller-1717573067     mynginx         1               2024-06-05 07:37:50.718429183 +0000 UTC       deployed        nginx-ingress-controller-11.3.2 1.10.1  
```


```sh
ubectl get all --namespace mynginx

NAME                                                                  READY   STATUS    RESTARTS   AGE
pod/nginx-ingress-controller-1717573067-7cdb6cdd94-fcq5f              1/1     Running   0          2m43s
pod/nginx-ingress-controller-1717573067-default-backend-776648m7hqx   1/1     Running   0          2m43s

NAME                                                          TYPE           CLUSTER-IP       EXTERNAL-IP   PORT(S)                      AGE
service/nginx-ingress-controller-1717573067                   LoadBalancer   10.102.206.3     <pending>     80:31628/TCP,443:31052/TCP   2m43s
service/nginx-ingress-controller-1717573067-default-backend   ClusterIP      10.105.185.146   <none>        80/TCP                       2m43s

NAME                                                                  READY   UP-TO-DATE   AVAILABLE   AGE
deployment.apps/nginx-ingress-controller-1717573067                   1/1     1            1           2m43s
deployment.apps/nginx-ingress-controller-1717573067-default-backend   1/1     1            1           2m43s

NAME                                                                             DESIRED   CURRENT   READY   AGE
replicaset.apps/nginx-ingress-controller-1717573067-7cdb6cdd94                   1         1         1       2m43s
replicaset.apps/nginx-ingress-controller-1717573067-default-backend-7766484699   1         1         1       2m43s
```

```ad-note
STATUS Runnig 확인
```


---


## metaILB

### strictARP 확인
- 입력
```sh
kubectl get configmap kube-proxy -n kube-system -o yaml | grep strictARP
```

- 출력
```sh
strictARP: false
```

```ad-note
strictARP이 false 인 것을 확인
```


### strictARP True 변경

- 입력
```sh
kubectl get configmap kube-proxy -n kube-system -o yaml | \
sed -e "s/strictARP: false/strictARP: true/" | \
kubectl apply -f - -n kube-system
```

- 출력
```sh
Warning: resource configmaps/kube-proxy is missing the kubectl.kubernetes.io/last-applied-configuration annotation which is required by kubectl apply. kubectl apply should only be used on resources created declaratively by either kubectl create --save-config or kubectl apply. The missing annotation will be patched automatically.
configmap/kube-proxy configured
```

#### 확인
- 입력
```sh
kubectl get configmap kube-proxy -n kube-system -o yaml | grep strictARP
```

- 출력
```sh
      strictARP: true
      {"apiVersion":"v1","data":{"config.conf":"apiVersion: kubeproxy.config.k8s.io/v1alpha1\nbindAddress: 0.0.0.0\nbindAddressHardFail: false\nclientConnection:\n  acceptContentTypes: \"\"\n  burst: 0\n  contentType: \"\"\n  kubeconfig: /var/lib/kube-proxy/kubeconfig.conf\n  qps: 0\nclusterCIDR: 192.168.0.0/16\nconfigSyncPeriod: 0s\nconntrack:\n  maxPerCore: null\n  min: null\n  tcpBeLiberal: false\n  tcpCloseWaitTimeout: null\n  tcpEstablishedTimeout: null\n  udpStreamTimeout: 0s\n  udpTimeout: 0s\ndetectLocal:\n  bridgeInterface: \"\"\n  interfaceNamePrefix: \"\"\ndetectLocalMode: \"\"\nenableProfiling: false\nhealthzBindAddress: \"\"\nhostnameOverride: \"\"\niptables:\n  localhostNodePorts: null\n  masqueradeAll: false\n  masqueradeBit: null\n  minSyncPeriod: 0s\n  syncPeriod: 0s\nipvs:\n  excludeCIDRs: null\n  minSyncPeriod: 0s\n  scheduler: \"\"\n  strictARP: true\n  syncPeriod: 0s\n  tcpFinTimeout: 0s\n  tcpTimeout: 0s\n  udpTimeout: 0s\nkind: KubeProxyConfiguration\nlogging:\n  flushFrequency: 0\n  options:\n    json:\n      infoBufferSize: \"0\"\n  verbosity: 0\nmetricsBindAddress: \"\"\nmode: \"\"\nnftables:\n  masqueradeAll: false\n  masqueradeBit: null\n  minSyncPeriod: 0s\n  syncPeriod: 0s\nnodePortAddresses: null\noomScoreAdj: null\nportRange: \"\"\nshowHiddenMetricsForVersion: \"\"\nwinkernel:\n  enableDSR: false\n  forwardHealthCheckVip: false\n  networkName: \"\"\n  rootHnsEndpointName: \"\"\n  sourceVip: \"\"","kubeconfig.conf":"apiVersion: v1\nkind: Config\nclusters:\n- cluster:\n    certificate-authority: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt\n    server: https://172.31.8.194:6443\n  name: default\ncontexts:\n- context:\n    cluster: default\n    namespace: default\n    user: default\n  name: default\ncurrent-context: default\nusers:\n- name: default\n  user:\n    tokenFile: /var/run/secrets/kubernetes.io/serviceaccount/token"},"kind":"ConfigMap","metadata":{"annotations":{"kubeadm.kubernetes.io/component-config.hash":"sha256:092ec924dfe74025c759063274668834178cdc79b06aa8e7d644a43d9fc98eec"},"creationTimestamp":"2024-06-04T05:37:57Z","labels":{"app":"kube-proxy"},"name":"kube-proxy","namespace":"kube-system","resourceVersion":"267","uid":"d6ce53fa-2820-410c-ae59-b5d6123b9909"}}
```


### 설치

#### repo add
```sh
helm repo add metallb https://metallb.github.io/metallb
"metallb" has been added to your repositories
```

#### repo update
```sh
helm repo update
Hang tight while we grab the latest from your chart repositories...
...Successfully got an update from the "metallb" chart repository
...Successfully got an update from the "bitnami" chart repository
Update Complete. ⎈Happy Helming!⎈
```

#### search repo
```sh
helm search repo metallb

NAME            CHART VERSION   APP VERSION     DESCRIPTION                                       
bitnami/metallb 6.3.3           0.14.5          MetalLB is a load-balancer implementation for b...
metallb/metallb 0.14.5          v0.14.5         A network load-balancer implementation for Kube...
```

#### helm pull
```sh
helm pull metallb/metallb
```

#### 압축 풀기
```sh
ls

custom-resources.yaml  metallb-0.14.5.tgz               nginx-ingress-controller-11.3.2.tgz
get_helm.sh            nginx-ingress-controller-11.3.2
```

```sh
tar xvfz metallb-0.14.5.tgz

metallb/Chart.yaml
metallb/Chart.lock
metallb/values.yaml
metallb/values.schema.json
metallb/templates/NOTES.txt
metallb/templates/_helpers.tpl
metallb/templates/controller.yaml
metallb/templates/deprecated_configInline.yaml
metallb/templates/exclude-l2-config.yaml
metallb/templates/podmonitor.yaml
metallb/templates/prometheusrules.yaml
metallb/templates/rbac.yaml
metallb/templates/service-accounts.yaml
metallb/templates/servicemonitor.yaml
metallb/templates/speaker.yaml
metallb/templates/webhooks.yaml
metallb/.helmignore
metallb/README.md
metallb/policy/controller.rego
metallb/policy/rbac.rego
metallb/policy/speaker.rego
metallb/charts/crds/Chart.yaml
metallb/charts/crds/templates/crds.yaml
metallb/charts/crds/.helmignore
metallb/charts/crds/README.md
metallb/charts/frr-k8s/Chart.yaml
metallb/charts/frr-k8s/Chart.lock
metallb/charts/frr-k8s/values.yaml
metallb/charts/frr-k8s/values.schema.json
metallb/charts/frr-k8s/templates/NOTES.txt
metallb/charts/frr-k8s/templates/_helpers.tpl
metallb/charts/frr-k8s/templates/controller.yaml
metallb/charts/frr-k8s/templates/rbac.yaml
metallb/charts/frr-k8s/templates/service-accounts.yaml
metallb/charts/frr-k8s/templates/service-monitor.yaml
metallb/charts/frr-k8s/templates/webhooks.yaml
metallb/charts/frr-k8s/.helmignore
metallb/charts/frr-k8s/README.md
metallb/charts/frr-k8s/charts/crds/Chart.yaml
metallb/charts/frr-k8s/charts/crds/templates/frrk8s.metallb.io_frrconfigurations.yaml
metallb/charts/frr-k8s/charts/crds/templates/frrk8s.metallb.io_frrnodestates.yaml
metallb/charts/frr-k8s/charts/crds/.helmignore
metallb/charts/frr-k8s/charts/crds/README.md
```


#### 전처리
```sh
mv metallb metallb-0.14.5
cd metallb-0.14.5
cp values.yaml my-values.yaml
```


#### 네임스페이스 생성
```sh
kubectl create namespace mymetallb
namespace/mymetallb created


kubectl get namespace

NAME               STATUS   AGE
calico-apiserver   Active   2d22h
calico-system      Active   2d22h
default            Active   2d23h
kube-node-lease    Active   2d23h
kube-public        Active   2d23h
kube-system        Active   2d23h
mymetallb          Active   71s
mynginx            Active   45h
tigera-operator    Active   2d22h
```

```sh
helm install --namespace mymetallb --generate-name metallb/metallb -f my-values.yaml


NAME: metallb-1717736694
LAST DEPLOYED: Fri Jun  7 05:04:54 2024
NAMESPACE: mymetallb
STATUS: deployed
REVISION: 1
TEST SUITE: None
NOTES:
MetalLB is now running in the cluster.

Now you can configure it via its CRs. Please refer to the metallb official docs
on how to use the CRs.

```


```sh
kubectl get all --namespace mymetallb
NAME                                               READY   STATUS    RESTARTS   AGE
pod/metallb-1717736694-controller-d686bb4f-lvs6h   1/1     Running   0          63s
pod/metallb-1717736694-speaker-hprv4               4/4     Running   0          63s

NAME                              TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)   AGE
service/metallb-webhook-service   ClusterIP   10.111.176.187   <none>        443/TCP   63s

NAME                                        DESIRED   CURRENT   READY   UP-TO-DATE   AVAILABLE   NODE SELECTOR            AGE
daemonset.apps/metallb-1717736694-speaker   1         1         1       1            1           kubernetes.io/os=linux   63s

NAME                                            READY   UP-TO-DATE   AVAILABLE   AGE
deployment.apps/metallb-1717736694-controller   1/1     1            1           63s

NAME                                                     DESIRED   CURRENT   READY   AGE
replicaset.apps/metallb-1717736694-controller-d686bb4f   1         1         1       63s
```


### 작성
```sh
vi vim my-config.yaml
```

```ymal
---
apiVersion: metallb.io/v1beta1
kind: IPAddressPool
metadata:
  name: my-metallb-config
  namespace: mymetallb
spec:
  addresses:
  - 172.31.46.220-172.31.46.230
  autoAssign: true
---
apiVersion: metallb.io/v1beta1
kind: L2Advertisement
metadata:
  name: my-metallb-config
  namespace: mymetallb
spec:
  ipAddressPools:
    - my-metallb-config
```
```ad-note
spec:
  addresses:
  - 172.31.46.220-172.31.46.230

요 부분을 내 아이피 대역으로 바꿔야 한다
```


- 입력
```
kubectl get validatingwebhookconfigurations
```

- 출력
```
kubectl get validatingwebhookconfigurations
NAME                            WEBHOOKS   AGE
metallb-webhook-configuration   6          12m
```

- 입력
```sh
kubectl delete validatingwebhookconfigurations metallb-webhook-configuration

kubectl get validatingwebhookconfigurations
```

- 출력
```sh
No resources found
```


#### 적용

```sh
ubectl apply -f my-config.yaml

ipaddresspool.metallb.io/my-metallb-config created
l2advertisement.metallb.io/my-metallb-config create
```

```sh
kubectl get ipaddresspool.metallb.io --namespace mymetallb

NAME                AUTO ASSIGN   AVOID BUGGY IPS   ADDRESSES
my-metallb-config   true          false             ["172.31.134.0-172.31.134.10"]
```


```sh
kubectl describe ipaddresspool.metallb.io my-metallb-config --namespace mymetallb
```


#### 적용 확인

```sh
kubectl describe ipaddresspool.metallb.io my-metallb-config --namespace mymetallb


Name:         my-metallb-config
Namespace:    mymetallb
Labels:       <none>
Annotations:  <none>
API Version:  metallb.io/v1beta1
Kind:         IPAddressPool
Metadata:
  Creation Timestamp:  2024-06-07T05:20:04Z
  Generation:          1
  Resource Version:    239615
  UID:                 d2588db8-e3b6-4d60-b9d6-eb1b876a1fe7
Spec:
  Addresses:
    172.31.134.0-172.31.134.10
  Auto Assign:       true
  Avoid Buggy I Ps:  false
```


```sh
kubectl get all --namespace mynginx
NAME                                                                  READY   STATUS    RESTARTS        AGE
pod/nginx-ingress-controller-1717573067-7cdb6cdd94-fcq5f              1/1     Running   2 (4h35m ago)   45h
pod/nginx-ingress-controller-1717573067-default-backend-776648m7hqx   1/1     Running   2 (4h35m ago)   45h

NAME                                                          TYPE           CLUSTER-IP       EXTERNAL-IP    PORT(S)                      AGE
service/nginx-ingress-controller-1717573067                   LoadBalancer   10.102.206.3     172.31.134.0   80:31628/TCP,443:31052/TCP   45h
service/nginx-ingress-controller-1717573067-default-backend   ClusterIP      10.105.185.146   <none>         80/TCP                       45h

NAME                                                                  READY   UP-TO-DATE   AVAILABLE   AGE
deployment.apps/nginx-ingress-controller-1717573067                   1/1     1            1           45h
deployment.apps/nginx-ingress-controller-1717573067-default-backend   1/1     1            1           45h

NAME                                                                             DESIRED   CURRENT   READY   AGE
replicaset.apps/nginx-ingress-controller-1717573067-7cdb6cdd94                   1         1         1       45h
replicaset.apps/nginx-ingress-controller-1717573067-default-backend-7766484699   1         1         1       45h
```


---

## 인그레스 배포

### deploy
```sh
vim ingress01-deploy.yml
```

```sh
apiVersion: apps/v1
kind: Deployment
metadata:
  name: ingress-deploy-test01
spec:
  replicas: 3
  selector:
    matchLabels:
      app: web-deploy01
  template:
    metadata:
      labels:
        app: web-deploy01
    spec:
      containers:
        - name: nginx
          image: nginx:1.25
```


### service
```sh
vim ingress01-service.yml
```

```sh
apiVersion: v1
kind: Service
metadata:
  name: ingress-service-test01
spec:
  selector:
    app: web-deploy01
  type: ClusterIP
  ports:
    - protocol: TCP
      port: 80
      targetPort: 80
```


### ingress
```sh
 vim ingress01-ingress.yml
```

```sh
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: ingress-test01
  annotations:
    nginx.ingress.kubernetes.io/rewrite-target: /
spec:
  ingressClassName: nginx
  rules:
    - http:
        paths:
          - path: /test01
            pathType: Prefix
            backend:
              service:
                name: ingress-service-test01
                port:
                  number: 80

```


### 생성
```sh
kubectl apply -f ingress01-deploy.yml
deployment.apps/ingress-deploy-test01 created

kubectl apply -f ingress01-service.yml
service/ingress-service-test01 created

kubectl apply -f ingress01-ingress.yml
ingress.networking.k8s.io/ingress-test01 created
```


### 확인
```sh
kubectl get all


NAME                                         READY   STATUS    RESTARTS   AGE
pod/ingress-deploy-test01-796d5b8df4-5pndl   1/1     Running   0          52s
pod/ingress-deploy-test01-796d5b8df4-97q6v   1/1     Running   0          52s
pod/ingress-deploy-test01-796d5b8df4-xvnq5   1/1     Running   0          52s

NAME                             TYPE        CLUSTER-IP    EXTERNAL-IP   PORT(S)   AGE
service/ingress-service-test01   ClusterIP   10.107.65.7   <none>        80/TCP    46s
service/kubernetes               ClusterIP   10.96.0.1     <none>        443/TCP   3d

NAME                                    READY   UP-TO-DATE   AVAILABLE   AGE
deployment.apps/ingress-deploy-test01   3/3     3            3           52s

NAME                                               DESIRED   CURRENT   READY   AGE
replicaset.apps/ingress-deploy-test01-796d5b8df4   3         3         3       52s
```


```sh
kubectl get ingress

NAME             CLASS   HOSTS   ADDRESS        PORTS   AGE
ingress-test01   nginx   *       172.31.8.194   80      67s
```

## nginx

### 설치

```sh
sudo apt-get update
```

```sh
sudo apt-get install nginx

sudo systemctl status nginx
```

### 포트포워딩
```sh
sudo -i
cd /etc/nginx/sites-enabled/

ls
default

sudo vi default 
```


- EXTERNAL-IP 확인

```sh
kubectl get all --namespace mynginx

NAME                                                                  READY   STATUS    RESTARTS        AGE
pod/nginx-ingress-controller-1717573067-7cdb6cdd94-fcq5f              1/1     Running   2 (5h29m ago)   46h
pod/nginx-ingress-controller-1717573067-default-backend-776648m7hqx   1/1     Running   2 (5h29m ago)   46h

NAME                                                          TYPE           CLUSTER-IP       EXTERNAL-IP  
service/nginx-ingress-controller-1717573067                   LoadBalancer   10.102.206.3     172.31.134.0 # 이거
```

```sh
ubuntu@ip-172-31-8-194:~/work/k8s/basic$ sudo -i
root@ip-172-31-8-194:~# cd /etc/nginx/sites-enabled/
root@ip-172-31-8-194:/etc/nginx/sites-enabled# ls
default
root@ip-172-31-8-194:/etc/nginx/sites-enabled# sudo vi default 
```



```sh
location / {
	# First attempt to serve request as file, then
	# as directory, then fall back to displaying a 404.
	# try_files $uri $uri/ =404; # 이거 주석
	proxy_pass http://172.31.134.0:80; # 이거  EXTERNAL-IP 넣기
}
```

- nginx 재시작
```sh
status nginx
● nginx.service - A high performance web server and a reverse proxy server
     Loaded: loaded (/usr/lib/systemd/system/nginx.service; enabled; preset: enabled)
     Active: active (running) since Fri 2024-06-07 06:21:04 UTC; 8s ago
```

`````ad-note
```sh
http://내_public_ip/test01
```
위로 접속하면 nginx의 welcome to nginx가 뜨면 성공
`````



### 실습 종료

``````ad-check
#### ingress
```
kubectl delete -f ingress01-ingress.yml
```
ingress.networking.k8s.io "ingress-test01" deleted


#### service
```
kubectl delete -f ingress01-service.yml
```
service "ingress-service-test01" deleted


#### deploy
```
kubectl delete -f ingress01-deploy.yml
```
deployment.apps "ingress-deploy-test01" deleted


#### 확인
```
kubectl get all
```
NAME                 TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE
service/kubernetes   ClusterIP   10.96.0.1    <none>        443/TCP   3d
``````


---

## 인그래스 배포2

### deploy
```sh
vim ingress02-deploy.yml
```

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: ingress-deploy-test02
spec:
  replicas: 3
  selector:
    matchLabels:
      app: web-deploy02
  template:
    metadata:
      labels:
        app: web-deploy02
    spec:
      containers:
        - name: nginx
          image: nginx:1.25

```


### service
```sh
vim ingress02-service.yml
```

```yaml
apiVersion: v1
kind: Service
metadata:
  name: ingress-service-test02
spec:
  selector:
    app: web-deploy02
  type: ClusterIP
  ports:
    - protocol: TCP
      port: 80
      targetPort: 80

```


### ingress

```sh
vim ingress02-ingress.yml
```

```yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: ingress-test02
  annotations:
    nginx.ingress.kubernetes.io/rewrite-target: /
spec:
  ingressClassName: nginx
  rules:
    - http:
        paths:
          - path: /test01
            pathType: Prefix
            backend:
              service:
                name: ingress-service-test01
                port:
                  number: 80
          - path: /test02
            pathType: Prefix
            backend:
              service:
                name: ingress-service-test02
                port:
                  number: 80

```

### 실행

``````ad-note
#### ingress01
```sh
kubectl apply -f ingress01-deploy.yml
```
deployment.apps/ingress-deploy-test01 created

```sh
kubectl apply -f ingress01-service.yml
```
service/ingress-service-test01 created

#### ingress02
```sh
kubectl apply -f ingress02-deploy.yml
```
deployment.apps/ingress-deploy-test02 created

```sh
kubectl apply -f ingress02-service.yml
```
service/ingress-service-test02 created

#### start
```sh
kubectl apply -f ingress02-ingress.yml
```
ingress.networking.k8s.io/ingress-test02 created
``````

### 확인

```sh
kubectl get all

NAME                                         READY   STATUS    RESTARTS   AGE
pod/ingress-deploy-test01-796d5b8df4-5w2fk   1/1     Running   0          62s
pod/ingress-deploy-test01-796d5b8df4-fslj6   1/1     Running   0          62s
pod/ingress-deploy-test01-796d5b8df4-qjtj5   1/1     Running   0          62s
pod/ingress-deploy-test02-679c4755c5-d9fnk   1/1     Running   0          53s
pod/ingress-deploy-test02-679c4755c5-xhxbw   1/1     Running   0          53s
pod/ingress-deploy-test02-679c4755c5-z59zm   1/1     Running   0          53s

NAME                             TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)   AGE
service/ingress-service-test01   ClusterIP   10.108.168.160   <none>        80/TCP    57s
service/ingress-service-test02   ClusterIP   10.97.21.105     <none>        80/TCP    49s
service/kubernetes               ClusterIP   10.96.0.1        <none>        443/TCP   3d1h

NAME                                    READY   UP-TO-DATE   AVAILABLE   AGE
deployment.apps/ingress-deploy-test01   3/3     3            3           62s
deployment.apps/ingress-deploy-test02   3/3     3            3           53s

NAME                                               DESIRED   CURRENT   READY   AGE
replicaset.apps/ingress-deploy-test01-796d5b8df4   3         3         3       62s
replicaset.apps/ingress-deploy-test02-679c4755c5   3         3         3       53s
```



`````ad-note
```sh
http://내_public_ip/test02
```
위로 접속하면 nginx의 welcome to nginx가 뜨면 성공
`````


### 실습 종료

``````ad-note
```sh
kubectl delete -f ingress02-ingress.yml
```
ingress.networking.k8s.io "ingress-test02" deleted

```sh
kubectl delete -f ingress02-service.yml
```
service "ingress-service-test02" deleted

```sh
kubectl delete -f ingress02-deploy.yml
```
deployment.apps "ingress-deploy-test02" deleted

```sh
kubectl delete -f ingress01-service.yml
```
service "ingress-service-test01" deleted

```sh
kubectl delete -f ingress01-deploy.yml
```
deployment.apps "ingress-deploy-test01" deleted

```sh
kubectl get all
```
NAME                 TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE

service/kubernetes   ClusterIP   10.96.0.1    <none>        443/TCP   3d1h
``````

---

## job

### 파일 생성

```sh
vim job-cronjob01.yml
```

```ymal
apiVersion: batch/v1
kind: Job
metadata:
  name: job-test01
spec:
  template:
    spec:
      containers:
        - name: nginx-test01
          image: nginx:1.25
          command: ["echo", "Hello, Kubernetes!"]
      restartPolicy: Never
  backoffLimit: 3

```

### 실행
```sh
kubectl apply -f job-cronjob01.yml

job.batch/job-test01 created


kubectl get job

NAME         COMPLETIONS   DURATION   AGE
job-test01   1/1           3s         15s
```


```sh
kubectl describe job job-test01


Name:             job-test01
Namespace:        default
Selector:         batch.kubernetes.io/controller-uid=d2c6efd7-68ab-4160-ba27-8bf6af72e019
Labels:           batch.kubernetes.io/controller-uid=d2c6efd7-68ab-4160-ba27-8bf6af72e019
                  batch.kubernetes.io/job-name=job-test01
                  controller-uid=d2c6efd7-68ab-4160-ba27-8bf6af72e019
                  job-name=job-test01
Annotations:      <none>
Parallelism:      1
Completions:      1
Completion Mode:  NonIndexed
Start Time:       Fri, 07 Jun 2024 07:28:10 +0000
Completed At:     Fri, 07 Jun 2024 07:28:13 +0000
Duration:         3s
Pods Statuses:    0 Active (0 Ready) / 1 Succeeded / 0 Failed
Pod Template:
  Labels:  batch.kubernetes.io/controller-uid=d2c6efd7-68ab-4160-ba27-8bf6af72e019
           batch.kubernetes.io/job-name=job-test01
           controller-uid=d2c6efd7-68ab-4160-ba27-8bf6af72e019
           job-name=job-test01
  Containers:
   nginx-test01:
    Image:      nginx:1.25
    Port:       <none>
    Host Port:  <none>
    Command:
      echo
      Hello, Kubernetes!
    Environment:  <none>
    Mounts:       <none>
  Volumes:        <none>
Events:
  Type    Reason            Age   From            Message
  ----    ------            ----  ----            -------
  Normal  SuccessfulCreate  60s   job-controller  Created pod: job-test01-q6fqx
  Normal  Completed         57s   job-controller  Job completed
```


``````ad-check
```sh
kubectl get pods
```
NAME               READY   STATUS      RESTARTS   AGE
job-test01-q6fqx   0/1     Completed   0          91s

```sh
kubectl logs job-test01-q6fqx
```
Hello, Kubernetes!
``````


### 종료

`````ad-check
```sh
kubectl delete -f job-cronjob01.yml
```
job.batch "job-test01" deleted
```sh
kubectl get pod
```
No resources found in default namespace.
```sh
kubectl get job
```
No resources found in default namespace.
`````

---
## cronejob

### 파일 생성

```sh
vim job-cronjob02.yml
```

```yaml
apiVersion: batch/v1
kind: CronJob
metadata:
  name: cronjob-test02
spec:
  schedule: "*/1 * * * *"
  jobTemplate:
    spec:
      template:
        spec:
          containers:
            - name: nginx-test02
              image: nginx:1.25
              command:
                - /bin/sh
                - -c
                - echo Hello Kubernetes!
          restartPolicy: Never

```

### 실행

```
ubuntu@ip-172-31-8-194:~/work/k8s/basic$ kubectl apply -f job-cronjob02.yml
cronjob.batch/cronjob-test02 created
ubuntu@ip-172-31-8-194:~/work/k8s/basic$  kubectl get cronjob
NAME             SCHEDULE      SUSPEND   ACTIVE   LAST SCHEDULE   AGE
cronjob-test02   */1 * * * *   False     0        <none>          5s
```

```
kubectl describe cronjob cronjob-test02
Name:                          cronjob-test02
Namespace:                     default
Labels:                        <none>
Annotations:                   <none>
Schedule:                      */1 * * * *
Concurrency Policy:            Allow
Suspend:                       False
Successful Job History Limit:  3
Failed Job History Limit:      1
Starting Deadline Seconds:     <unset>
Selector:                      <unset>
Parallelism:                   <unset>
Completions:                   <unset>
Pod Template:
  Labels:  <none>
  Containers:
   nginx-test02:
    Image:      nginx:1.25
    Port:       <none>
    Host Port:  <none>
    Command:
      /bin/sh
      -c
      echo Hello Kubernetes!
    Environment:     <none>
    Mounts:          <none>
  Volumes:           <none>
Last Schedule Time:  Fri, 07 Jun 2024 07:37:00 +0000
Active Jobs:         <none>
Events:
  Type    Reason            Age   From                Message
  ----    ------            ----  ----                -------
  Normal  SuccessfulCreate  17s   cronjob-controller  Created job cronjob-test02-28629097
  Normal  SawCompletedJob   14s   cronjob-controller  Saw completed job: cronjob-test02-28629097, status: Complete
```
```

```


### 종료

``````ad-note
```sh
kubectl delete -f job-cronjob02.yml
```
cronjob.batch "cronjob-test02" deleted
```sh
kubectl get cronjob
```
No resources found in default namespace.
```sh
kubectl get pods
```
No resources found in default namespace.
``````

